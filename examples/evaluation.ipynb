{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ArGen GRPO Fine-Tuning Evaluation\n",
    "\n",
    "This notebook demonstrates how to evaluate a fine-tuned model against the base model using the Dharmic ethical principles (Ahimsa, Satya, Dharma)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's install the required packages and import the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -e ..\n",
    "!pip install predibase matplotlib pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import predibase as pb\n",
    "from src.reward_functions import ahimsa_reward, satya_reward, dharma_reward\n",
    "from src.data_utils.dataset import load_jsonl_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication\n",
    "\n",
    "Authenticate with Predibase using your API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your Predibase API key\n",
    "# You can also set this as an environment variable: export PREDIBASE_API_KEY=your_api_key\n",
    "os.environ[\"PREDIBASE_API_KEY\"] = \"your_api_key_here\"\n",
    "\n",
    "# Initialize the Predibase client\n",
    "pb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Cases\n",
    "\n",
    "Load the test cases for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test cases\n",
    "test_cases_path = \"../data/healthcare_examples.jsonl\"\n",
    "test_cases = load_jsonl_dataset(test_cases_path)\n",
    "\n",
    "# Display a sample\n",
    "test_cases[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Models\n",
    "\n",
    "Set up the base model and the fine-tuned model for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model IDs\n",
    "base_model_id = \"microsoft/phi-3-mini-4k-instruct\"  # Base model\n",
    "ft_model_id = \"your_fine_tuned_model_id_here\"  # Fine-tuned model (from previous notebook)\n",
    "\n",
    "# Create deployments\n",
    "base_deployment = pb.deployments.create(\n",
    "    name=\"phi-3-mini-base-eval\",\n",
    "    model=base_model_id,\n",
    "    description=\"Base Phi-3 Mini model for evaluation\"\n",
    ")\n",
    "\n",
    "ft_deployment = pb.deployments.create(\n",
    "    name=\"argen-healthcare-eval\",\n",
    "    adapter=ft_model_id,\n",
    "    description=\"ArGen healthcare model for evaluation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Evaluation Function\n",
    "\n",
    "Define a function to evaluate the models using the Dharmic reward functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(deployment, test_cases, num_samples=10):\n",
    "    \"\"\"\n",
    "    Evaluate a model using the Dharmic reward functions.\n",
    "    \n",
    "    Args:\n",
    "        deployment: Predibase deployment\n",
    "        test_cases: List of test cases\n",
    "        num_samples: Number of test cases to evaluate\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with evaluation results\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Limit the number of test cases if needed\n",
    "    if num_samples < len(test_cases):\n",
    "        test_cases = test_cases[:num_samples]\n",
    "    \n",
    "    for i, test_case in enumerate(test_cases):\n",
    "        prompt = test_case[\"prompt\"]\n",
    "        \n",
    "        # Generate a response\n",
    "        response = deployment.generate(\n",
    "            prompt=prompt,\n",
    "            max_tokens=500,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        # Calculate rewards\n",
    "        ahimsa_score = ahimsa_reward(prompt, response.text, test_case)\n",
    "        satya_score = satya_reward(prompt, response.text, test_case)\n",
    "        dharma_score = dharma_reward(prompt, response.text, test_case)\n",
    "        total_score = (ahimsa_score + satya_score + dharma_score) / 3\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            \"prompt\": prompt,\n",
    "            \"response\": response.text,\n",
    "            \"ahimsa\": ahimsa_score,\n",
    "            \"satya\": satya_score,\n",
    "            \"dharma\": dharma_score,\n",
    "            \"total\": total_score\n",
    "        })\n",
    "        \n",
    "        # Print progress\n",
    "        print(f\"Evaluated {i+1}/{len(test_cases)} test cases\")\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Models\n",
    "\n",
    "Evaluate both the base model and the fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the base model\n",
    "print(\"Evaluating base model...\")\n",
    "base_results = evaluate_model(base_deployment, test_cases, num_samples=5)\n",
    "\n",
    "# Evaluate the fine-tuned model\n",
    "print(\"\\nEvaluating fine-tuned model...\")\n",
    "ft_results = evaluate_model(ft_deployment, test_cases, num_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Results\n",
    "\n",
    "Compare the results of the base model and the fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average scores\n",
    "base_avg = base_results[[\"ahimsa\", \"satya\", \"dharma\", \"total\"]].mean()\n",
    "ft_avg = ft_results[[\"ahimsa\", \"satya\", \"dharma\", \"total\"]].mean()\n",
    "\n",
    "# Display average scores\n",
    "print(\"Base Model Average Scores:\")\n",
    "for key, value in base_avg.items():\n",
    "    print(f\"  {key}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nFine-tuned Model Average Scores:\")\n",
    "for key, value in ft_avg.items():\n",
    "    print(f\"  {key}: {value:.4f}\")\n",
    "\n",
    "# Calculate improvement\n",
    "improvement = (ft_avg - base_avg) / base_avg * 100\n",
    "\n",
    "print(\"\\nImprovement (%)\")\n",
    "for key, value in improvement.items():\n",
    "    print(f\"  {key}: {value:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results\n",
    "\n",
    "Visualize the comparison between the base model and the fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the figure\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Set up the data\n",
    "categories = [\"Ahimsa\", \"Satya\", \"Dharma\", \"Total\"]\n",
    "base_scores = base_avg.values\n",
    "ft_scores = ft_avg.values\n",
    "\n",
    "# Set up the bar positions\n",
    "x = range(len(categories))\n",
    "width = 0.35\n",
    "\n",
    "# Create the bars\n",
    "ax.bar([i - width/2 for i in x], base_scores, width, label=\"Base Model\")\n",
    "ax.bar([i + width/2 for i in x], ft_scores, width, label=\"Fine-tuned Model\")\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_ylabel(\"Score\")\n",
    "ax.set_title(\"Comparison of Base Model and Fine-tuned Model\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(categories)\n",
    "ax.legend()\n",
    "\n",
    "# Set y-axis limits\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "# Add value labels on top of bars\n",
    "for i, v in enumerate(base_scores):\n",
    "    ax.text(i - width/2, v + 0.02, f\"{v:.2f}\", ha=\"center\")\n",
    "    \n",
    "for i, v in enumerate(ft_scores):\n",
    "    ax.text(i + width/2, v + 0.02, f\"{v:.2f}\", ha=\"center\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Comparison\n",
    "\n",
    "Compare the responses of the base model and the fine-tuned model for a specific test case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a test case\n",
    "test_case_idx = 0  # Change this to compare different test cases\n",
    "\n",
    "# Get the prompt and responses\n",
    "prompt = base_results.iloc[test_case_idx][\"prompt\"]\n",
    "base_response = base_results.iloc[test_case_idx][\"response\"]\n",
    "ft_response = ft_results.iloc[test_case_idx][\"response\"]\n",
    "\n",
    "# Get the scores\n",
    "base_scores = base_results.iloc[test_case_idx][[\"ahimsa\", \"satya\", \"dharma\", \"total\"]]\n",
    "ft_scores = ft_results.iloc[test_case_idx][[\"ahimsa\", \"satya\", \"dharma\", \"total\"]]\n",
    "\n",
    "# Display the comparison\n",
    "print(f\"Prompt: {prompt}\\n\")\n",
    "\n",
    "print(\"Base Model Response:\")\n",
    "print(f\"{base_response}\\n\")\n",
    "print(\"Base Model Scores:\")\n",
    "for key, value in base_scores.items():\n",
    "    print(f\"  {key}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nFine-tuned Model Response:\")\n",
    "print(f\"{ft_response}\\n\")\n",
    "print(\"Fine-tuned Model Scores:\")\n",
    "for key, value in ft_scores.items():\n",
    "    print(f\"  {key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results\n",
    "\n",
    "Save the evaluation results for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results\n",
    "base_results.to_csv(\"../data/base_model_evaluation.csv\", index=False)\n",
    "ft_results.to_csv(\"../data/fine_tuned_model_evaluation.csv\", index=False)\n",
    "\n",
    "# Save the average scores\n",
    "avg_scores = pd.DataFrame({\n",
    "    \"base_model\": base_avg,\n",
    "    \"fine_tuned_model\": ft_avg,\n",
    "    \"improvement_percent\": improvement\n",
    "})\n",
    "\n",
    "avg_scores.to_csv(\"../data/average_scores.csv\")\n",
    "\n",
    "print(\"Results saved to data directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we evaluated the fine-tuned model against the base model using the Dharmic ethical principles (Ahimsa, Satya, Dharma). We showed how to:\n",
    "\n",
    "1. Set up the base model and the fine-tuned model for evaluation\n",
    "2. Define an evaluation function using the Dharmic reward functions\n",
    "3. Evaluate both models on a set of test cases\n",
    "4. Compare and visualize the results\n",
    "5. Perform a detailed comparison of specific test cases\n",
    "6. Save the evaluation results for future reference\n",
    "\n",
    "The evaluation demonstrates the effectiveness of GRPO fine-tuning with Dharmic ethical principles in improving the model's alignment with these principles in a healthcare context."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
