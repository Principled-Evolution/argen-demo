zsh: command not found: --save_total_limit
--save_total_limit: command not found
zsh: command not found: --save_total_limit
zsh: command not found: --save_total_limit
2025-05-10 17:43:30,975 - __main__ - INFO - Console and File logging initialized. Log file: logs/train_grpo_20250510_174330.log
2025-05-10 17:43:30,980 - __main__ - INFO - Console and File logging initialized. Log file: logs/train_grpo_20250510_174330.log
2025-05-10 17:43:33,006 - datasets - INFO - PyTorch version 2.7.0 available.
2025-05-10 17:43:33,007 - datasets - INFO - PyTorch version 2.7.0 available.
2025-05-10 17:43:36,087 - __main__ - INFO - --- Starting GRPO Training Run ---
2025-05-10 17:43:36,087 - __main__ - INFO - Script: /home/kapil/argen-demo/examples/train_grpo.py
2025-05-10 17:43:36,088 - __main__ - INFO - Timestamp: 20250510_174330
2025-05-10 17:43:36,088 - __main__ - INFO - Command Line Arguments: {'model': 'meta-llama/Llama-3.2-1B-Instruct', 'scenarios': 'data/final-2025-05-10/grpo_training_20250510_145354-cleanprep.jsonl', 'output_dir': '/mnt/checkpoints/grpo_run_v2', 'num_train_epochs': 8, 'learning_rate': 3e-06, 'wandb_project': 'argen-grpo', 'wandb_run_name': 'llama3-grpo-a100-spot-2', 'use_basic_prompt': False, 'use_separate_rewards': False, 'num_generations': 6, 'resume_from_checkpoint': None, 'kl_beta_start': 0.1, 'save_strategy': 'steps', 'save_steps': 100, 'save_total_limit': 6, 'per_device_train_batch_size': 4, 'gradient_accumulation_steps': 3, 'lr_scheduler_type': 'cosine', 'warmup_steps': 200, 'max_grad_norm': 1.0, 'bf16': True, 'gradient_checkpointing': True, 'kl_beta_end': 0.1, 'beta_schedule': 'constant', 'logging_steps': 25, 'report_to': ['wandb'], 'seed': 42}
torch, transformers, and trl libraries found.
2025-05-10 17:43:36,089 - __main__ - INFO - --- Starting GRPO Training Run ---
2025-05-10 17:43:36,089 - __main__ - INFO - Script: /home/kapil/argen-demo/examples/train_grpo.py
2025-05-10 17:43:36,089 - __main__ - INFO - Timestamp: 20250510_174330
2025-05-10 17:43:36,089 - __main__ - INFO - Command Line Arguments: {'model': 'meta-llama/Llama-3.2-1B-Instruct', 'scenarios': 'data/final-2025-05-10/grpo_training_20250510_145354-cleanprep.jsonl', 'output_dir': '/mnt/checkpoints/grpo_run_v2', 'num_train_epochs': 8, 'learning_rate': 3e-06, 'wandb_project': 'argen-grpo', 'wandb_run_name': 'llama3-grpo-a100-spot-2', 'use_basic_prompt': False, 'use_separate_rewards': False, 'num_generations': 6, 'resume_from_checkpoint': None, 'kl_beta_start': 0.1, 'save_strategy': 'steps', 'save_steps': 100, 'save_total_limit': 6, 'per_device_train_batch_size': 4, 'gradient_accumulation_steps': 3, 'lr_scheduler_type': 'cosine', 'warmup_steps': 200, 'max_grad_norm': 1.0, 'bf16': True, 'gradient_checkpointing': True, 'kl_beta_end': 0.1, 'beta_schedule': 'constant', 'logging_steps': 25, 'report_to': ['wandb'], 'seed': 42}
torch, transformers, and trl libraries found.
CUDA is available. GPU: NVIDIA A100-SXM4-40GB
2025-05-10 17:43:36,341 - __main__ - INFO - Loading scenarios from data/final-2025-05-10/grpo_training_20250510_145354-cleanprep.jsonl...
CUDA is available. GPU: NVIDIA A100-SXM4-40GB
2025-05-10 17:43:36,346 - __main__ - INFO - Loading scenarios from data/final-2025-05-10/grpo_training_20250510_145354-cleanprep.jsonl...
2025-05-10 17:43:36,396 - __main__ - INFO - Base GRPO Config: {'output_dir': 'output/Llama-3.2-1B-Instruct-grpo', 'beta': 0.1, 'learning_rate': 3.2e-06, 'num_train_epochs': 8, 'num_iterations': 40, 'num_generations': 6, 'apply_training_severity_penalty': False, 'per_device_train_batch_size': 12, 'gradient_accumulation_steps': 1, 'max_prompt_length': 512, 'max_completion_length': 512, 'disable_dropout': True, 'bf16': True, 'warmup_steps': 5, 'logging_steps': 25, 'save_strategy': 'epoch', 'save_total_limit': 4}
2025-05-10 17:43:36,396 - __main__ - INFO - Base GRPO Config: {'output_dir': 'output/Llama-3.2-1B-Instruct-grpo', 'beta': 0.1, 'learning_rate': 3.2e-06, 'num_train_epochs': 8, 'num_iterations': 40, 'num_generations': 6, 'apply_training_severity_penalty': False, 'per_device_train_batch_size': 12, 'gradient_accumulation_steps': 1, 'max_prompt_length': 512, 'max_completion_length': 512, 'disable_dropout': True, 'bf16': True, 'warmup_steps': 5, 'logging_steps': 25, 'save_strategy': 'epoch', 'save_total_limit': 4}
2025-05-10 17:43:36,397 - __main__ - INFO - Effective GRPO Config (after CLI overrides): {'output_dir': '/mnt/checkpoints/grpo_run_v2', 'beta': 0.1, 'learning_rate': 3e-06, 'num_train_epochs': 8, 'num_iterations': 40, 'num_generations': 6, 'apply_training_severity_penalty': False, 'per_device_train_batch_size': 4, 'gradient_accumulation_steps': 3, 'max_prompt_length': 512, 'max_completion_length': 512, 'disable_dropout': True, 'bf16': True, 'warmup_steps': 5, 'logging_steps': 25, 'save_strategy': 'epoch', 'save_total_limit': 4}
2025-05-10 17:43:36,397 - __main__ - INFO - Effective GRPO Config (after CLI overrides): {'output_dir': '/mnt/checkpoints/grpo_run_v2', 'beta': 0.1, 'learning_rate': 3e-06, 'num_train_epochs': 8, 'num_iterations': 40, 'num_generations': 6, 'apply_training_severity_penalty': False, 'per_device_train_batch_size': 4, 'gradient_accumulation_steps': 3, 'max_prompt_length': 512, 'max_completion_length': 512, 'disable_dropout': True, 'bf16': True, 'warmup_steps': 5, 'logging_steps': 25, 'save_strategy': 'epoch', 'save_total_limit': 4}
wandb: Currently logged in as: principledevolution (principled-evolution) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: principledevolution (principled-evolution) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /home/kapil/argen-demo/wandb/run-20250510_174337-5sbln6xw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run llama3-grpo-a100-spot-2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/principled-evolution/argen-grpo
wandb: üöÄ View run at https://wandb.ai/principled-evolution/argen-grpo/runs/5sbln6xw
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /home/kapil/argen-demo/wandb/run-20250510_174337-cu06fpof
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run llama3-grpo-a100-spot-2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/principled-evolution/argen-grpo
wandb: üöÄ View run at https://wandb.ai/principled-evolution/argen-grpo/runs/cu06fpof
2025-05-10 17:43:39,069 - __main__ - INFO - Defined W&B step metric to use train/global_step.
2025-05-10 17:43:39,069 - __main__ - INFO - Defined W&B step metric to use train/global_step.
2025-05-10 17:43:39,145 - __main__ - INFO - Explicitly set model_init_kwargs with torch_dtype=torch.bfloat16 on trl_config based on effective grpo_config['bf16']=True
2025-05-10 17:43:39,301 - __main__ - INFO - Explicitly set model_init_kwargs with torch_dtype=torch.bfloat16 on trl_config based on effective grpo_config['bf16']=True
2025-05-10 17:43:39,803 - __main__ - INFO - System Prompt Type: ENHANCED
2025-05-10 17:43:39,803 - __main__ - INFO - [0] Initializing GRPOTrainer for model meta-llama/Llama-3.2-1B-Instruct...
2025-05-10 17:43:39,864 - __main__ - INFO - System Prompt Type: ENHANCED
2025-05-10 17:43:39,865 - __main__ - INFO - [1] Initializing GRPOTrainer for model meta-llama/Llama-3.2-1B-Instruct...
2025-05-10 17:43:42,921 - __main__ - INFO - Added CustomWandbLoggingCallback and LogEvalCommandCallback.
2025-05-10 17:43:42,921 - __main__ - INFO - Starting GRPO training...
2025-05-10 17:43:43,095 - __main__ - INFO - Added CustomWandbLoggingCallback and LogEvalCommandCallback.
2025-05-10 17:43:43,095 - __main__ - INFO - Starting GRPO training...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 17:44:11,996 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.50625, 'avg_raw_dharma_score': 0.6291666666666667, 'avg_raw_helpfulness_score': 0.49166666666666664, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5510416666666668}
2025-05-10 17:44:12,696 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.45416666666666666, 'avg_raw_dharma_score': 0.6333333333333333, 'avg_raw_helpfulness_score': 0.40833333333333327, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5120833333333333}
2025-05-10 17:45:05,482 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.40208333333333335, 'avg_raw_dharma_score': 0.575, 'avg_raw_helpfulness_score': 0.3833333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.4656249999999999}
2025-05-10 17:45:05,903 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6166666666666666, 'avg_raw_dharma_score': 0.8583333333333334, 'avg_raw_helpfulness_score': 0.6166666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7133333333333333}
2025-05-10 17:45:58,683 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.325, 'avg_raw_dharma_score': 0.5625, 'avg_raw_helpfulness_score': 0.5083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.47500000000000003}
2025-05-10 17:46:00,038 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4375, 'avg_raw_dharma_score': 0.6083333333333333, 'avg_raw_helpfulness_score': 0.44166666666666665, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5070833333333334}
  warnings.warn(
2025-05-10 17:47:05,803 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.39999999999999997, 'avg_raw_dharma_score': 0.525, 'avg_raw_helpfulness_score': 0.5166666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.48500000000000004}
2025-05-10 17:47:06,438 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.2555555555555556, 'avg_raw_dharma_score': 0.39999999999999997, 'avg_raw_helpfulness_score': 0.525, 'avg_penalty': 0.0, 'avg_combined_reward': 0.3941666666666667}
  1%|          | 121/24000 [03:22<61:58:10,  9.34s/it]  1%|          | 122/24000 [03:23<44:37:59,  6.73s/it]  1%|          | 123/24000 [03:23<32:29:58,  4.90s/it]  1%|          | 124/24000 [03:24<24:00:23,  3.62s/it]  1%|          | 125/24000 [03:25<18:03:43,  2.72s/it]                                                      {'loss': -0.0882, 'grad_norm': 3.21875, 'learning_rate': 1.86e-06, 'kl': 0.008272405145689846, 'clip_ratio/low_mean': 0.0514089443278499, 'clip_ratio/low_min': 0.031073287872908015, 'clip_ratio/high_mean': 0.06402663249289617, 'clip_ratio/high_max': 0.06732181853149086, 'clip_ratio/region_mean': 0.11543557431626444, 'num_tokens': 36795.0, 'completions/mean_length': 349.625, 'completions/min_length': 38.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.29166666666666663, 'completions/mean_terminated_length': 282.76470947265625, 'completions/min_terminated_length': 38.0, 'completions/max_terminated_length': 482.0, 'rewards/combined_reward_trl/mean': 0.43958333134651184, 'rewards/combined_reward_trl/std': 0.25287869572639465, 'reward': 0.43958336114883423, 'reward_std': 0.2649003267288208, 'epoch': 0.04}
2025-05-10 17:47:57,914 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.31875000000000003, 'avg_raw_dharma_score': 0.625, 'avg_raw_helpfulness_score': 0.525, 'avg_penalty': 0.0, 'avg_combined_reward': 0.503125}
2025-05-10 17:48:01,697 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4500000000000001, 'avg_raw_dharma_score': 0.7833333333333333, 'avg_raw_helpfulness_score': 0.55, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6133333333333334}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 17:48:55,165 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.47708333333333347, 'avg_raw_dharma_score': 0.6999999999999998, 'avg_raw_helpfulness_score': 0.5750000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.595625}
2025-05-10 17:49:08,366 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5708333333333334, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.6583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7020833333333333}
2025-05-10 17:49:59,738 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.37083333333333335, 'avg_raw_dharma_score': 0.5833333333333334, 'avg_raw_helpfulness_score': 0.5833333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5195833333333334}
2025-05-10 17:49:59,974 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4125000000000001, 'avg_raw_dharma_score': 0.6083333333333333, 'avg_raw_helpfulness_score': 0.575, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5395833333333333}
2025-05-10 17:50:49,737 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5375, 'avg_raw_dharma_score': 0.6333333333333333, 'avg_raw_helpfulness_score': 0.55, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5795833333333333}
2025-05-10 17:50:50,622 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8041666666666667, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.775, 'avg_penalty': 0.0, 'avg_combined_reward': 0.82375}
  warnings.warn(
2025-05-10 17:51:53,619 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4624999999999999, 'avg_raw_dharma_score': 0.5, 'avg_raw_helpfulness_score': 0.6, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5187500000000002}
2025-05-10 17:51:55,655 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6375000000000001, 'avg_raw_dharma_score': 0.8583333333333334, 'avg_raw_helpfulness_score': 0.7166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7495833333333333}
  1%|‚ñè         | 321/24000 [08:11<58:53:12,  8.95s/it]  1%|‚ñè         | 322/24000 [08:12<42:27:48,  6.46s/it]  1%|‚ñè         | 323/24000 [08:12<30:58:07,  4.71s/it]  1%|‚ñè         | 324/24000 [08:13<22:55:24,  3.49s/it]  1%|‚ñè         | 325/24000 [08:14<17:17:24,  2.63s/it]                                                      {'loss': 0.0871, 'grad_norm': 3.296875, 'learning_rate': 2.999799071857688e-06, 'kl': 0.07128238076965014, 'clip_ratio/low_mean': 0.22809426135305935, 'clip_ratio/low_min': 0.12240281621615091, 'clip_ratio/high_mean': 0.08574974462545167, 'clip_ratio/high_max': 0.10207874886070689, 'clip_ratio/region_mean': 0.3138440061158811, 'num_tokens': 84308.0, 'completions/mean_length': 364.29168701171875, 'completions/min_length': 1.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 315.0555725097656, 'completions/min_terminated_length': 1.0, 'completions/max_terminated_length': 483.0, 'rewards/combined_reward_trl/mean': 0.6341666579246521, 'rewards/combined_reward_trl/std': 0.30973222851753235, 'reward': 0.6341667175292969, 'reward_std': 0.25196564197540283, 'epoch': 0.11}
  1%|‚ñè         | 325/24000 [08:14<17:17:24,  2.63s/it]wandb: WARNING Tried to log to step 325 that is less than the current step 2964. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-10 17:52:47,026 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4916666666666667, 'avg_raw_dharma_score': 0.5583333333333333, 'avg_raw_helpfulness_score': 0.6166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5558333333333333}
2025-05-10 17:52:47,994 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5729166666666666, 'avg_raw_dharma_score': 0.7541666666666668, 'avg_raw_helpfulness_score': 0.6416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6660416666666666}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 17:53:39,086 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7861111111111111, 'avg_raw_dharma_score': 0.8291666666666666, 'avg_raw_helpfulness_score': 0.7916666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.805}
2025-05-10 17:53:52,213 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.59875, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.6916666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7204583333333333}
2025-05-10 17:54:42,952 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5416666666666667, 'avg_raw_dharma_score': 0.775, 'avg_raw_helpfulness_score': 0.6583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6699999999999999}
2025-05-10 17:54:43,467 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.45416666666666666, 'avg_raw_dharma_score': 0.4583333333333333, 'avg_raw_helpfulness_score': 0.4666666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.4595833333333333}
2025-05-10 17:55:35,804 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6319444444444445, 'avg_raw_dharma_score': 0.8208333333333333, 'avg_raw_helpfulness_score': 0.6749999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7204166666666666}
2025-05-10 17:55:37,669 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.39986111111111106, 'avg_raw_dharma_score': 0.6041666666666666, 'avg_raw_helpfulness_score': 0.5833333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5366249999999999}
  warnings.warn(
2025-05-10 17:56:42,860 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4569444444444444, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.5416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6162500000000001}
2025-05-10 17:56:43,018 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5708333333333334, 'avg_raw_dharma_score': 0.7541666666666668, 'avg_raw_helpfulness_score': 0.65, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6679166666666667}
  2%|‚ñè         | 521/24000 [12:59<58:39:58,  9.00s/it]  2%|‚ñè         | 522/24000 [12:59<42:18:16,  6.49s/it]  2%|‚ñè         | 523/24000 [13:00<30:51:05,  4.73s/it]  2%|‚ñè         | 524/24000 [13:00<22:50:08,  3.50s/it]  2%|‚ñè         | 525/24000 [13:01<17:13:27,  2.64s/it]                                                      {'loss': -0.0888, 'grad_norm': 9.1875, 'learning_rate': 2.99862838913397e-06, 'kl': 0.17924580633640289, 'clip_ratio/low_mean': 0.12373388008369754, 'clip_ratio/low_min': 0.06018382358830422, 'clip_ratio/high_mean': 0.13662297060596756, 'clip_ratio/high_max': 0.17034943951060996, 'clip_ratio/region_mean': 0.26035684915880364, 'num_tokens': 132690.0, 'completions/mean_length': 365.125, 'completions/min_length': 32.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 316.1666564941406, 'completions/min_terminated_length': 32.0, 'completions/max_terminated_length': 499.0, 'rewards/combined_reward_trl/mean': 0.6420833468437195, 'rewards/combined_reward_trl/std': 0.28158774971961975, 'reward': 0.6420833468437195, 'reward_std': 0.2344009131193161, 'epoch': 0.17}
2025-05-10 17:57:34,982 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.51875, 'avg_raw_dharma_score': 0.725, 'avg_raw_helpfulness_score': 0.6166666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.630625}
2025-05-10 17:57:35,818 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.47500000000000003, 'avg_raw_dharma_score': 0.5499999999999999, 'avg_raw_helpfulness_score': 0.5499999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5275}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 17:58:27,941 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6291666666666665, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.75, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7470833333333333}
2025-05-10 17:58:40,289 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5354166666666668, 'avg_raw_dharma_score': 0.6291666666666668, 'avg_raw_helpfulness_score': 0.5833333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5872916666666667}
2025-05-10 17:59:31,376 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5583333333333335, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.6083333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6833333333333335}
2025-05-10 17:59:33,090 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5083333333333333, 'avg_raw_dharma_score': 0.6833333333333332, 'avg_raw_helpfulness_score': 0.5916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6033333333333334}
2025-05-10 18:00:25,034 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6708333333333334, 'avg_raw_dharma_score': 0.9833333333333334, 'avg_raw_helpfulness_score': 0.7166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8095833333333333}
2025-05-10 18:00:27,114 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6437499999999999, 'avg_raw_dharma_score': 0.7833333333333333, 'avg_raw_helpfulness_score': 0.6583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7039583333333335}
  warnings.warn(
2025-05-10 18:01:34,290 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6124999999999999, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.6166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6687500000000001}
2025-05-10 18:01:34,655 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.35833333333333334, 'avg_raw_dharma_score': 0.27499999999999997, 'avg_raw_helpfulness_score': 0.4833333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.3625}
  3%|‚ñé         | 721/24000 [17:50<57:23:47,  8.88s/it]  3%|‚ñé         | 722/24000 [17:51<41:24:18,  6.40s/it]  3%|‚ñé         | 723/24000 [17:51<30:12:28,  4.67s/it]  3%|‚ñé         | 724/24000 [17:52<22:22:14,  3.46s/it]  3%|‚ñé         | 725/24000 [17:53<16:53:01,  2.61s/it]                                                      {'loss': -0.0204, 'grad_norm': 13.625, 'learning_rate': 2.996413287914716e-06, 'kl': 0.34797171314557396, 'clip_ratio/low_mean': 0.09528664774882296, 'clip_ratio/low_min': 0.06317925499752164, 'clip_ratio/high_mean': 0.08952918777552744, 'clip_ratio/high_max': 0.11914892461150885, 'clip_ratio/region_mean': 0.18481583730317652, 'num_tokens': 185149.0, 'completions/mean_length': 377.5833435058594, 'completions/min_length': 34.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.33333333333333337, 'completions/mean_terminated_length': 310.375, 'completions/min_terminated_length': 34.0, 'completions/max_terminated_length': 448.0, 'rewards/combined_reward_trl/mean': 0.515625, 'rewards/combined_reward_trl/std': 0.38579198718070984, 'reward': 0.515625, 'reward_std': 0.3481978178024292, 'epoch': 0.24}
  3%|‚ñé         | 725/24000 [17:53<16:53:01,  2.61s/it]  3%|‚ñé         | 726/24000 [17:53<13:03:06,  2.02s/it]  3%|‚ñé         | 727/24000 [17:54<10:21:42,  1.60s/it]wandb: WARNING Tried to log to step 725 that is less than the current step 6610. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-10 18:02:26,029 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6708333333333334, 'avg_raw_dharma_score': 0.7666666666666666, 'avg_raw_helpfulness_score': 0.7250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7254166666666668}
2025-05-10 18:02:26,221 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5166666666666667, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.525, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6125}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 18:03:17,557 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.39999999999999997, 'avg_raw_dharma_score': 0.5416666666666666, 'avg_raw_helpfulness_score': 0.5416666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.4991666666666667}
2025-05-10 18:03:33,728 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.54, 'avg_raw_dharma_score': 0.7083333333333334, 'avg_raw_helpfulness_score': 0.5666666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6153333333333333}
2025-05-10 18:04:28,145 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6, 'avg_raw_dharma_score': 0.5499999999999999, 'avg_raw_helpfulness_score': 0.6, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5800000000000001}
2025-05-10 18:04:28,918 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4237499999999999, 'avg_raw_dharma_score': 0.5666666666666667, 'avg_raw_helpfulness_score': 0.44166666666666665, 'avg_penalty': 0.0, 'avg_combined_reward': 0.48629166666666673}
2025-05-10 18:05:22,255 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.69375, 'avg_raw_dharma_score': 0.8583333333333334, 'avg_raw_helpfulness_score': 0.7666666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7814583333333335}
2025-05-10 18:05:22,771 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6654166666666667, 'avg_raw_dharma_score': 0.7999999999999999, 'avg_raw_helpfulness_score': 0.7416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.742125}
  warnings.warn(
2025-05-10 18:06:28,235 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5083333333333334, 'avg_raw_dharma_score': 0.5416666666666666, 'avg_raw_helpfulness_score': 0.5666666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5391666666666667}
2025-05-10 18:06:29,047 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5527777777777778, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.6000000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6458333333333333}
  4%|‚ñç         | 921/24000 [22:45<57:47:07,  9.01s/it]  4%|‚ñç         | 922/24000 [22:45<41:39:40,  6.50s/it]  4%|‚ñç         | 923/24000 [22:46<30:22:26,  4.74s/it]  4%|‚ñç         | 924/24000 [22:46<22:28:41,  3.51s/it]  4%|‚ñç         | 925/24000 [22:47<16:56:46,  2.64s/it]                                                      {'loss': -0.0281, 'grad_norm': 7.96875, 'learning_rate': 2.9931553119399887e-06, 'kl': 0.4562556936343511, 'clip_ratio/low_mean': 0.08638470234077734, 'clip_ratio/low_min': 0.052441931342085205, 'clip_ratio/high_mean': 0.0695734846262106, 'clip_ratio/high_max': 0.08647268203009541, 'clip_ratio/region_mean': 0.15595818866897995, 'num_tokens': 232650.0, 'completions/mean_length': 293.375, 'completions/min_length': 1.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 262.1428527832031, 'completions/min_terminated_length': 1.0, 'completions/max_terminated_length': 456.0, 'rewards/combined_reward_trl/mean': 0.5925000309944153, 'rewards/combined_reward_trl/std': 0.3375970125198364, 'reward': 0.5925000905990601, 'reward_std': 0.2425224483013153, 'epoch': 0.31}
2025-05-10 18:07:23,077 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5604166666666667, 'avg_raw_dharma_score': 0.8666666666666667, 'avg_raw_helpfulness_score': 0.6749999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7172916666666667}
2025-05-10 18:07:24,070 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6958333333333333, 'avg_raw_dharma_score': 0.8791666666666668, 'avg_raw_helpfulness_score': 0.7833333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7954166666666668}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 18:08:17,674 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5333333333333334, 'avg_raw_dharma_score': 0.6458333333333334, 'avg_raw_helpfulness_score': 0.5333333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5783333333333335}
2025-05-10 18:08:32,144 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5111111111111111, 'avg_raw_dharma_score': 0.7166666666666667, 'avg_raw_helpfulness_score': 0.6416666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6325}
2025-05-10 18:09:23,358 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.46944444444444455, 'avg_raw_dharma_score': 0.5666666666666667, 'avg_raw_helpfulness_score': 0.5416666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5299999999999999}
2025-05-10 18:09:26,548 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7554166666666666, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.7916666666666669, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8307916666666667}
2025-05-10 18:10:18,475 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6958333333333333, 'avg_raw_dharma_score': 0.8958333333333334, 'avg_raw_helpfulness_score': 0.775, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7995833333333332}
2025-05-10 18:10:20,574 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6258333333333334, 'avg_raw_dharma_score': 0.7125, 'avg_raw_helpfulness_score': 0.6416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.66525}
  warnings.warn(
2025-05-10 18:11:26,481 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5583333333333333, 'avg_raw_dharma_score': 0.7333333333333334, 'avg_raw_helpfulness_score': 0.6750000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6633333333333334}
2025-05-10 18:11:27,698 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6875, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.6583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7370833333333334}
  5%|‚ñç         | 1121/24000 [27:43<58:39:20,  9.23s/it]  5%|‚ñç         | 1122/24000 [27:44<42:15:13,  6.65s/it]  5%|‚ñç         | 1123/24000 [27:44<30:46:23,  4.84s/it]  5%|‚ñç         | 1124/24000 [27:45<22:44:13,  3.58s/it]  5%|‚ñç         | 1125/24000 [27:46<17:06:43,  2.69s/it]                                                       {'loss': -0.0757, 'grad_norm': 10.9375, 'learning_rate': 2.9888567317462273e-06, 'kl': 0.549654366572698, 'clip_ratio/low_mean': 0.07703645771408144, 'clip_ratio/low_min': 0.03708184593978028, 'clip_ratio/high_mean': 0.08382794191750387, 'clip_ratio/high_max': 0.0984201471755902, 'clip_ratio/region_mean': 0.16086439767852426, 'num_tokens': 280491.0, 'completions/mean_length': 384.125, 'completions/min_length': 194.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.20833333333333337, 'completions/mean_terminated_length': 350.47369384765625, 'completions/min_terminated_length': 194.0, 'completions/max_terminated_length': 488.0, 'rewards/combined_reward_trl/mean': 0.7002083659172058, 'rewards/combined_reward_trl/std': 0.3243671953678131, 'reward': 0.7002083659172058, 'reward_std': 0.3039206862449646, 'epoch': 0.38}
2025-05-10 18:12:18,719 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.49583333333333335, 'avg_raw_dharma_score': 0.6625, 'avg_raw_helpfulness_score': 0.6083333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.59625}
2025-05-10 18:12:20,772 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5708333333333333, 'avg_raw_dharma_score': 0.5833333333333334, 'avg_raw_helpfulness_score': 0.6083333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5870833333333333}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 18:13:12,975 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5095833333333334, 'avg_raw_dharma_score': 0.6083333333333333, 'avg_raw_helpfulness_score': 0.5083333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5487083333333334}
2025-05-10 18:13:27,069 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.57625, 'avg_raw_dharma_score': 0.7333333333333334, 'avg_raw_helpfulness_score': 0.6583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6637083333333335}
2025-05-10 18:14:19,704 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5583333333333332, 'avg_raw_dharma_score': 0.7208333333333333, 'avg_raw_helpfulness_score': 0.6583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6533333333333334}
2025-05-10 18:14:20,757 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.725, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.8000000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8408333333333334}
2025-05-10 18:15:13,643 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4916666666666667, 'avg_raw_dharma_score': 0.6541666666666667, 'avg_raw_helpfulness_score': 0.6, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5891666666666666}
2025-05-10 18:15:15,169 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5208333333333334, 'avg_raw_dharma_score': 0.6041666666666666, 'avg_raw_helpfulness_score': 0.5333333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5579166666666667}
  warnings.warn(
2025-05-10 18:16:18,501 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6416666666666667, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.7333333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7624999999999998}
2025-05-10 18:16:23,645 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5770833333333333, 'avg_raw_dharma_score': 0.7291666666666666, 'avg_raw_helpfulness_score': 0.7166666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6797916666666667}
  6%|‚ñå         | 1321/24000 [32:39<57:48:34,  9.18s/it]  6%|‚ñå         | 1322/24000 [32:40<41:39:59,  6.61s/it]  6%|‚ñå         | 1323/24000 [32:40<30:22:00,  4.82s/it]  6%|‚ñå         | 1324/24000 [32:41<22:27:26,  3.57s/it]  6%|‚ñå         | 1325/24000 [32:42<16:55:10,  2.69s/it]                                                       {'loss': 0.0648, 'grad_norm': 4.84375, 'learning_rate': 2.983520543083874e-06, 'kl': 1.3048071161905925, 'clip_ratio/low_mean': 0.11312684028215396, 'clip_ratio/low_min': 0.062157224474164344, 'clip_ratio/high_mean': 0.08564024638850241, 'clip_ratio/high_max': 0.1207448889221996, 'clip_ratio/region_mean': 0.19876708519334593, 'num_tokens': 326276.0, 'completions/mean_length': 317.875, 'completions/min_length': 1.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 290.1428527832031, 'completions/min_terminated_length': 1.0, 'completions/max_terminated_length': 426.0, 'rewards/combined_reward_trl/mean': 0.7211458683013916, 'rewards/combined_reward_trl/std': 0.14902213215827942, 'reward': 0.7211458683013916, 'reward_std': 0.11249387264251709, 'epoch': 0.44}
2025-05-10 18:17:15,406 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5479166666666667, 'avg_raw_dharma_score': 0.6, 'avg_raw_helpfulness_score': 0.5583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.571875}
2025-05-10 18:17:15,709 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6854166666666668, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.8250000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8197916666666667}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 18:18:07,239 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5208333333333334, 'avg_raw_dharma_score': 0.5499999999999999, 'avg_raw_helpfulness_score': 0.5916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.55375}
2025-05-10 18:18:22,599 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5708333333333334, 'avg_raw_dharma_score': 0.6833333333333332, 'avg_raw_helpfulness_score': 0.5750000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6170833333333333}
2025-05-10 18:19:15,893 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6291666666666667, 'avg_raw_dharma_score': 0.7333333333333334, 'avg_raw_helpfulness_score': 0.7083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6945833333333334}
2025-05-10 18:19:16,174 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.37222222222222223, 'avg_raw_dharma_score': 0.65, 'avg_raw_helpfulness_score': 0.5333333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5316666666666667}
2025-05-10 18:20:09,706 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6583333333333333, 'avg_raw_dharma_score': 0.9, 'avg_raw_helpfulness_score': 0.7583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7850000000000001}
2025-05-10 18:20:09,805 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6749999999999999, 'avg_raw_dharma_score': 0.8375, 'avg_raw_helpfulness_score': 0.6749999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7399999999999999}
  warnings.warn(
2025-05-10 18:21:16,771 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6381944444444446, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.6916666666666665, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6656249999999999}
2025-05-10 18:21:17,256 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4875000000000001, 'avg_raw_dharma_score': 0.4583333333333333, 'avg_raw_helpfulness_score': 0.6833333333333332, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5345833333333333}
  6%|‚ñã         | 1521/24000 [37:33<55:22:53,  8.87s/it]  6%|‚ñã         | 1522/24000 [37:33<39:56:55,  6.40s/it]  6%|‚ñã         | 1523/24000 [37:34<29:08:49,  4.67s/it]  6%|‚ñã         | 1524/24000 [37:35<21:35:09,  3.46s/it]  6%|‚ñã         | 1525/24000 [37:35<16:17:40,  2.61s/it]                                                       {'loss': 0.0107, 'grad_norm': 9.0, 'learning_rate': 2.977150464829586e-06, 'kl': 0.7261122967799505, 'clip_ratio/low_mean': 0.06174980508279987, 'clip_ratio/low_min': 0.035156612743933995, 'clip_ratio/high_mean': 0.1524136533650259, 'clip_ratio/high_max': 0.23505905639380217, 'clip_ratio/region_mean': 0.2141634577078124, 'num_tokens': 371912.0, 'completions/mean_length': 352.25, 'completions/min_length': 47.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 329.4285888671875, 'completions/min_terminated_length': 47.0, 'completions/max_terminated_length': 511.0, 'rewards/combined_reward_trl/mean': 0.6001041531562805, 'rewards/combined_reward_trl/std': 0.285299688577652, 'reward': 0.6001042127609253, 'reward_std': 0.21516387164592743, 'epoch': 0.51}
  6%|‚ñã         | 1525/24000 [37:35<16:17:40,  2.61s/it]  6%|‚ñã         | 1526/24000 [37:36<12:35:59,  2.02s/it]wandb: WARNING Tried to log to step 1525 that is less than the current step 13902. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-10 18:22:09,841 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5416666666666666, 'avg_raw_dharma_score': 0.6583333333333333, 'avg_raw_helpfulness_score': 0.6333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6158333333333333}
2025-05-10 18:22:10,757 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6291666666666668, 'avg_raw_dharma_score': 0.8583333333333334, 'avg_raw_helpfulness_score': 0.7166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7470833333333333}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 18:23:03,025 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.42083333333333334, 'avg_raw_dharma_score': 0.6833333333333332, 'avg_raw_helpfulness_score': 0.6, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5795833333333333}
2025-05-10 18:23:18,945 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5858333333333333, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.5916666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6199166666666668}
2025-05-10 18:24:09,856 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5875, 'avg_raw_dharma_score': 0.5416666666666666, 'avg_raw_helpfulness_score': 0.6249999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5804166666666667}
2025-05-10 18:24:10,946 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5416666666666666, 'avg_raw_dharma_score': 0.6916666666666668, 'avg_raw_helpfulness_score': 0.5666666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6091666666666666}
2025-05-10 18:25:00,954 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6708333333333334, 'avg_raw_dharma_score': 0.8166666666666668, 'avg_raw_helpfulness_score': 0.6833333333333332, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7329166666666667}
2025-05-10 18:25:01,418 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6791666666666666, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.7000000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.76375}
  warnings.warn(
2025-05-10 18:26:06,765 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6625000000000001, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.5499999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6804166666666666}
2025-05-10 18:26:06,907 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.46249999999999997, 'avg_raw_dharma_score': 0.7333333333333334, 'avg_raw_helpfulness_score': 0.5416666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5945833333333334}
  7%|‚ñã         | 1721/24000 [42:22<51:15:35,  8.28s/it]  7%|‚ñã         | 1722/24000 [42:23<37:03:04,  5.99s/it]  7%|‚ñã         | 1723/24000 [42:24<27:06:24,  4.38s/it]  7%|‚ñã         | 1724/24000 [42:24<20:08:41,  3.26s/it]  7%|‚ñã         | 1725/24000 [42:25<15:16:19,  2.47s/it]                                                       {'loss': 0.061, 'grad_norm': 9.8125, 'learning_rate': 2.9697509363944906e-06, 'kl': 0.7093813753128052, 'clip_ratio/low_mean': 0.11773254344860713, 'clip_ratio/low_min': 0.08037648681085557, 'clip_ratio/high_mean': 0.057940984276744226, 'clip_ratio/high_max': 0.07778620979748667, 'clip_ratio/region_mean': 0.1756735280683885, 'num_tokens': 419042.0, 'completions/mean_length': 356.4583435058594, 'completions/min_length': 221.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.20833333333333337, 'completions/mean_terminated_length': 315.52630615234375, 'completions/min_terminated_length': 221.0, 'completions/max_terminated_length': 487.0, 'rewards/combined_reward_trl/mean': 0.637499988079071, 'rewards/combined_reward_trl/std': 0.2590702474117279, 'reward': 0.6375000476837158, 'reward_std': 0.2682590186595917, 'epoch': 0.57}
  7%|‚ñã         | 1725/24000 [42:25<15:16:19,  2.47s/it]  7%|‚ñã         | 1726/24000 [42:26<11:52:14,  1.92s/it]  7%|‚ñã         | 1727/24000 [42:26<9:28:56,  1.53s/it] wandb: WARNING Tried to log to step 1725 that is less than the current step 15725. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-10 18:26:56,557 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6291666666666665, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.7833333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7904166666666668}
2025-05-10 18:26:58,225 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.3879166666666667, 'avg_raw_dharma_score': 0.5666666666666667, 'avg_raw_helpfulness_score': 0.47500000000000003, 'avg_penalty': 0.0, 'avg_combined_reward': 0.4855416666666666}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 18:27:50,732 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5800000000000001, 'avg_raw_dharma_score': 0.8583333333333334, 'avg_raw_helpfulness_score': 0.7000000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7273333333333333}
2025-05-10 18:28:07,273 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4166666666666666, 'avg_raw_dharma_score': 0.4166666666666667, 'avg_raw_helpfulness_score': 0.47500000000000003, 'avg_penalty': 0.0, 'avg_combined_reward': 0.43416666666666665}
2025-05-10 18:28:58,660 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6541666666666667, 'avg_raw_dharma_score': 0.4166666666666667, 'avg_raw_helpfulness_score': 0.7416666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5854166666666666}
2025-05-10 18:29:00,132 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5166666666666667, 'avg_raw_dharma_score': 0.625, 'avg_raw_helpfulness_score': 0.5666666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5750000000000001}
  8%|‚ñä         | 1841/24000 [45:16<54:34:58,  8.87s/it]  8%|‚ñä         | 1842/24000 [45:16<39:22:56,  6.40s/it]  8%|‚ñä         | 1843/24000 [45:17<28:44:44,  4.67s/it]  8%|‚ñä         | 1844/24000 [45:18<21:17:51,  3.46s/it]  8%|‚ñä         | 1845/24000 [45:18<16:05:03,  2.61s/it]  8%|‚ñä         | 1846/24000 [45:19<12:26:06,  2.02s/it]  8%|‚ñä         | 1847/24000 [45:19<9:52:49,  1.61s/it]   8%|‚ñä         | 1848/24000 [45:21<8:58:13,  1.46s/it]  8%|‚ñä         | 1849/24000 [45:21<7:27:17,  1.21s/it]  8%|‚ñä         | 1850/24000 [45:22<6:23:39,  1.04s/it]                                                      {'loss': 0.0653, 'grad_norm': 64.5, 'learning_rate': 2.96460572504618e-06, 'kl': 1.1115654305617015, 'clip_ratio/low_mean': 0.08120945089186231, 'clip_ratio/low_min': 0.06115322911025335, 'clip_ratio/high_mean': 0.11101179054006934, 'clip_ratio/high_max': 0.1892068900850912, 'clip_ratio/region_mean': 0.19222124030813575, 'num_tokens': 445108.0, 'completions/mean_length': 296.75, 'completions/min_length': 1.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 266.0, 'completions/min_terminated_length': 1.0, 'completions/max_terminated_length': 437.0, 'rewards/combined_reward_trl/mean': 0.5802083611488342, 'rewards/combined_reward_trl/std': 0.2838611304759979, 'reward': 0.580208420753479, 'reward_std': 0.20965459942817688, 'epoch': 0.62}
2025-05-10 18:29:52,284 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7319444444444444, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.7916666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8404166666666667}
2025-05-10 18:29:53,203 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.42083333333333334, 'avg_raw_dharma_score': 0.6875, 'avg_raw_helpfulness_score': 0.5916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.57875}
  warnings.warn(
2025-05-10 18:30:59,263 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.33138888888888884, 'avg_raw_dharma_score': 0.43333333333333335, 'avg_raw_helpfulness_score': 0.3583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.38025}
2025-05-10 18:30:59,392 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4958333333333334, 'avg_raw_dharma_score': 0.6083333333333333, 'avg_raw_helpfulness_score': 0.5833333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5670833333333334}
  8%|‚ñä         | 1921/24000 [47:15<52:21:30,  8.54s/it]  8%|‚ñä         | 1922/24000 [47:16<37:48:40,  6.17s/it]  8%|‚ñä         | 1923/24000 [47:16<27:37:43,  4.51s/it]  8%|‚ñä         | 1924/24000 [47:17<20:30:13,  3.34s/it]  8%|‚ñä         | 1925/24000 [47:17<15:31:01,  2.53s/it]                                                       {'loss': 0.0004, 'grad_norm': 13.0, 'learning_rate': 2.961327114630288e-06, 'kl': 0.604700045188268, 'clip_ratio/low_mean': 0.08702416984752441, 'clip_ratio/low_min': 0.07118690062003831, 'clip_ratio/high_mean': 0.11205403834891815, 'clip_ratio/high_max': 0.1591737166636934, 'clip_ratio/region_mean': 0.19907820720225572, 'num_tokens': 464204.0, 'completions/mean_length': 355.66668701171875, 'completions/min_length': 142.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.20833333333333337, 'completions/mean_terminated_length': 314.52630615234375, 'completions/min_terminated_length': 142.0, 'completions/max_terminated_length': 507.0, 'rewards/combined_reward_trl/mean': 0.4736666679382324, 'rewards/combined_reward_trl/std': 0.3161853849887848, 'reward': 0.4736666679382324, 'reward_std': 0.17327693104743958, 'epoch': 0.64}
2025-05-10 18:31:50,610 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6375000000000001, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.8000000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7312500000000001}
2025-05-10 18:31:54,149 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6000000000000001, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.5833333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6716666666666667}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 18:32:42,977 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8250000000000001, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.8166666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8925000000000001}
2025-05-10 18:33:00,393 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7472222222222222, 'avg_raw_dharma_score': 0.9, 'avg_raw_helpfulness_score': 0.8166666666666669, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8291666666666666}
2025-05-10 18:33:51,303 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4354166666666666, 'avg_raw_dharma_score': 0.5083333333333333, 'avg_raw_helpfulness_score': 0.4833333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.4789583333333334}
2025-05-10 18:33:53,896 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6658333333333334, 'avg_raw_dharma_score': 0.9, 'avg_raw_helpfulness_score': 0.7416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.78225}
2025-05-10 18:34:45,008 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6124999999999999, 'avg_raw_dharma_score': 0.8083333333333332, 'avg_raw_helpfulness_score': 0.7749999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7395833333333334}
2025-05-10 18:34:49,003 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.43749999999999994, 'avg_raw_dharma_score': 0.7041666666666666, 'avg_raw_helpfulness_score': 0.46666666666666673, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5529166666666667}
  warnings.warn(
2025-05-10 18:35:53,564 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7416666666666666, 'avg_raw_dharma_score': 0.9249999999999999, 'avg_raw_helpfulness_score': 0.7583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8200000000000002}
2025-05-10 18:35:55,166 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5833333333333334, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.6416666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6341666666666667}
  9%|‚ñâ         | 2121/24000 [52:11<51:51:29,  8.53s/it]  9%|‚ñâ         | 2122/24000 [52:11<37:27:29,  6.16s/it]  9%|‚ñâ         | 2123/24000 [52:12<27:22:43,  4.51s/it]  9%|‚ñâ         | 2124/24000 [52:13<20:19:23,  3.34s/it]  9%|‚ñâ         | 2125/24000 [52:13<15:22:59,  2.53s/it]                                                       {'loss': -0.0174, 'grad_norm': 11.5625, 'learning_rate': 2.9518848702353558e-06, 'kl': 0.5495741512378057, 'clip_ratio/low_mean': 0.1182872494061788, 'clip_ratio/low_min': 0.06512537322938443, 'clip_ratio/high_mean': 0.12787595255300402, 'clip_ratio/high_max': 0.1516065297710399, 'clip_ratio/region_mean': 0.2461632009471456, 'num_tokens': 511437.0, 'completions/mean_length': 328.91668701171875, 'completions/min_length': 111.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.04166666666666663, 'completions/mean_terminated_length': 320.95654296875, 'completions/min_terminated_length': 111.0, 'completions/max_terminated_length': 510.0, 'rewards/combined_reward_trl/mean': 0.7270832657814026, 'rewards/combined_reward_trl/std': 0.26230135560035706, 'reward': 0.7270833849906921, 'reward_std': 0.20809273421764374, 'epoch': 0.71}
  9%|‚ñâ         | 2125/24000 [52:13<15:22:59,  2.53s/it]  9%|‚ñâ         | 2126/24000 [52:14<12:45:55,  2.10s/it]  9%|‚ñâ         | 2127/24000 [52:15<10:05:38,  1.66s/it]  9%|‚ñâ         | 2128/24000 [52:16<8:13:29,  1.35s/it]   9%|‚ñâ         | 2129/24000 [52:16<6:54:56,  1.14s/it]wandb: WARNING Tried to log to step 2125 that is less than the current step 19371. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-10 18:36:48,072 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6666666666666666, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.8166666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8450000000000001}
2025-05-10 18:36:48,594 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.2798611111111111, 'avg_raw_dharma_score': 0.3333333333333333, 'avg_raw_helpfulness_score': 0.39999999999999997, 'avg_penalty': 0.0, 'avg_combined_reward': 0.3372916666666667}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 18:37:41,184 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7666666666666666, 'avg_raw_dharma_score': 0.8583333333333334, 'avg_raw_helpfulness_score': 0.8666666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8333333333333335}
2025-05-10 18:37:56,676 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4666666666666666, 'avg_raw_dharma_score': 0.3958333333333333, 'avg_raw_helpfulness_score': 0.4750000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.44083333333333324}
2025-05-10 18:38:50,070 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6041666666666666, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.7999999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8045833333333334}
2025-05-10 18:38:50,215 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6458333333333334, 'avg_raw_dharma_score': 0.8125, 'avg_raw_helpfulness_score': 0.7166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.73375}
2025-05-10 18:39:42,142 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.3916666666666666, 'avg_raw_dharma_score': 0.5541666666666667, 'avg_raw_helpfulness_score': 0.5750000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5116666666666667}
2025-05-10 18:39:42,672 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5375, 'avg_raw_dharma_score': 0.6749999999999999, 'avg_raw_helpfulness_score': 0.6, 'avg_penalty': 0.0, 'avg_combined_reward': 0.61125}
  warnings.warn(
2025-05-10 18:40:46,811 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6041666666666666, 'avg_raw_dharma_score': 0.8125, 'avg_raw_helpfulness_score': 0.6833333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.71125}
2025-05-10 18:40:47,056 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5354166666666668, 'avg_raw_dharma_score': 0.625, 'avg_raw_helpfulness_score': 0.6000000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5906250000000001}
 10%|‚ñâ         | 2321/24000 [57:03<50:44:07,  8.43s/it] 10%|‚ñâ         | 2322/24000 [57:03<36:39:36,  6.09s/it] 10%|‚ñâ         | 2323/24000 [57:04<26:48:21,  4.45s/it] 10%|‚ñâ         | 2324/24000 [57:04<19:54:29,  3.31s/it] 10%|‚ñâ         | 2325/24000 [57:05<15:05:02,  2.51s/it]                                                       {'loss': 0.0409, 'grad_norm': 14.0625, 'learning_rate': 2.9414307836633664e-06, 'kl': 0.9542249472935994, 'clip_ratio/low_mean': 0.11977302238539171, 'clip_ratio/low_min': 0.07819091111421585, 'clip_ratio/high_mean': 0.0856288574077189, 'clip_ratio/high_max': 0.1329055432851116, 'clip_ratio/region_mean': 0.20540187677989402, 'num_tokens': 563580.0, 'completions/mean_length': 378.41668701171875, 'completions/min_length': 49.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.16666666666666663, 'completions/mean_terminated_length': 351.70001220703125, 'completions/min_terminated_length': 49.0, 'completions/max_terminated_length': 508.0, 'rewards/combined_reward_trl/mean': 0.6509374976158142, 'rewards/combined_reward_trl/std': 0.3098253607749939, 'reward': 0.650937557220459, 'reward_std': 0.27237170934677124, 'epoch': 0.78}
 10%|‚ñâ         | 2325/24000 [57:05<15:05:02,  2.51s/it] 10%|‚ñâ         | 2326/24000 [57:06<11:42:47,  1.95s/it] 10%|‚ñâ         | 2327/24000 [57:06<9:20:44,  1.55s/it] wandb: WARNING Tried to log to step 2325 that is less than the current step 21194. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-10 18:41:38,174 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6770833333333334, 'avg_raw_dharma_score': 0.8250000000000001, 'avg_raw_helpfulness_score': 0.7666666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.763125}
2025-05-10 18:41:38,976 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5624999999999999, 'avg_raw_dharma_score': 0.5, 'avg_raw_helpfulness_score': 0.6083333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5512500000000001}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 18:42:34,260 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.476388888888889, 'avg_raw_dharma_score': 0.6083333333333333, 'avg_raw_helpfulness_score': 0.5416666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5487500000000001}
2025-05-10 18:42:43,585 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6416666666666667, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.7250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7599999999999998}
2025-05-10 18:43:32,244 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7041666666666667, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.8750000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7904166666666667}
2025-05-10 18:43:34,563 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5954166666666667, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.6, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6252916666666667}
2025-05-10 18:44:25,531 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4791666666666667, 'avg_raw_dharma_score': 0.6416666666666667, 'avg_raw_helpfulness_score': 0.6, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5804166666666667}
2025-05-10 18:44:27,467 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5791666666666667, 'avg_raw_dharma_score': 0.43333333333333335, 'avg_raw_helpfulness_score': 0.6833333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5520833333333334}
  warnings.warn(
2025-05-10 18:45:32,455 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7374999999999999, 'avg_raw_dharma_score': 0.8166666666666668, 'avg_raw_helpfulness_score': 0.775, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7804166666666666}
2025-05-10 18:45:33,792 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7125, 'avg_raw_dharma_score': 0.7083333333333334, 'avg_raw_helpfulness_score': 0.6916666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7045833333333333}
 11%|‚ñà         | 2521/24000 [1:01:49<50:57:34,  8.54s/it] 11%|‚ñà         | 2522/24000 [1:01:50<36:48:06,  6.17s/it] 11%|‚ñà         | 2523/24000 [1:01:51<26:53:28,  4.51s/it] 11%|‚ñà         | 2524/24000 [1:01:51<19:57:18,  3.35s/it] 11%|‚ñà         | 2525/24000 [1:01:52<15:05:58,  2.53s/it]                                                         {'loss': 0.1148, 'grad_norm': 11.625, 'learning_rate': 2.9299721405372582e-06, 'kl': 1.1416920761267344, 'clip_ratio/low_mean': 0.11812268216356946, 'clip_ratio/low_min': 0.08937565669494991, 'clip_ratio/high_mean': 0.07177111871540547, 'clip_ratio/high_max': 0.09897160273666183, 'clip_ratio/region_mean': 0.18989380040516457, 'num_tokens': 610158.0, 'completions/mean_length': 355.0, 'completions/min_length': 203.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.08333333333333337, 'completions/mean_terminated_length': 340.727294921875, 'completions/min_terminated_length': 203.0, 'completions/max_terminated_length': 467.0, 'rewards/combined_reward_trl/mean': 0.7425000071525574, 'rewards/combined_reward_trl/std': 0.22747193276882172, 'reward': 0.7425000667572021, 'reward_std': 0.12575507164001465, 'epoch': 0.84}
2025-05-10 18:46:25,101 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6245833333333334, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.6416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.679875}
2025-05-10 18:46:25,819 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.725, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.7916666666666669, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8383333333333334}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 18:47:19,635 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.55, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.6583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6625}
2025-05-10 18:47:31,498 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6875000000000001, 'avg_raw_dharma_score': 0.8583333333333334, 'avg_raw_helpfulness_score': 0.7416666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7720833333333333}
2025-05-10 18:48:25,681 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6625, 'avg_raw_dharma_score': 0.9, 'avg_raw_helpfulness_score': 0.6666666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.75875}
2025-05-10 18:48:26,647 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5291666666666667, 'avg_raw_dharma_score': 0.7166666666666667, 'avg_raw_helpfulness_score': 0.6333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6354166666666666}
2025-05-10 18:49:19,962 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5875, 'avg_raw_dharma_score': 0.5416666666666666, 'avg_raw_helpfulness_score': 0.7333333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6129166666666667}
2025-05-10 18:49:20,066 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6409722222222222, 'avg_raw_dharma_score': 0.7833333333333333, 'avg_raw_helpfulness_score': 0.65, 'avg_penalty': 0.0, 'avg_combined_reward': 0.700625}
  warnings.warn(
2025-05-10 18:50:28,384 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.24305555555555558, 'avg_raw_dharma_score': 0.4666666666666666, 'avg_raw_helpfulness_score': 0.34166666666666673, 'avg_penalty': 0.0, 'avg_combined_reward': 0.36208333333333337}
2025-05-10 18:50:28,397 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.49874999999999997, 'avg_raw_dharma_score': 0.625, 'avg_raw_helpfulness_score': 0.5, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5496250000000001}
 11%|‚ñà‚ñè        | 2721/24000 [1:06:44<52:53:14,  8.95s/it] 11%|‚ñà‚ñè        | 2722/24000 [1:06:45<38:09:00,  6.45s/it] 11%|‚ñà‚ñè        | 2723/24000 [1:06:45<27:50:00,  4.71s/it] 11%|‚ñà‚ñè        | 2724/24000 [1:06:46<20:36:44,  3.49s/it] 11%|‚ñà‚ñè        | 2725/24000 [1:06:46<15:33:23,  2.63s/it]                                                         {'loss': 0.0511, 'grad_norm': 13.0, 'learning_rate': 2.9175169265717708e-06, 'kl': 0.8760540252923965, 'clip_ratio/low_mean': 0.12584026440201948, 'clip_ratio/low_min': 0.05433652568608523, 'clip_ratio/high_mean': 0.058695904825969286, 'clip_ratio/high_max': 0.07729426031466574, 'clip_ratio/region_mean': 0.18453616932267322, 'num_tokens': 653524.0, 'completions/mean_length': 322.5833435058594, 'completions/min_length': 60.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.16666666666666663, 'completions/mean_terminated_length': 284.70001220703125, 'completions/min_terminated_length': 60.0, 'completions/max_terminated_length': 432.0, 'rewards/combined_reward_trl/mean': 0.4558541774749756, 'rewards/combined_reward_trl/std': 0.2730964124202728, 'reward': 0.4558541774749756, 'reward_std': 0.2469598948955536, 'epoch': 0.91}
 11%|‚ñà‚ñè        | 2725/24000 [1:06:47<15:33:23,  2.63s/it]wandb: WARNING Tried to log to step 2725 that is less than the current step 24840. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-10 18:51:20,151 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5333333333333333, 'avg_raw_dharma_score': 0.5833333333333334, 'avg_raw_helpfulness_score': 0.65, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5883333333333334}
2025-05-10 18:51:21,976 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6416666666666666, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.6416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6516666666666666}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 18:52:15,733 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6083333333333334, 'avg_raw_dharma_score': 0.8125, 'avg_raw_helpfulness_score': 0.6833333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7124999999999999}
2025-05-10 18:52:29,197 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4541666666666666, 'avg_raw_dharma_score': 0.6875, 'avg_raw_helpfulness_score': 0.6166666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5962500000000001}
2025-05-10 18:53:21,219 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6666666666666666, 'avg_raw_dharma_score': 0.725, 'avg_raw_helpfulness_score': 0.7583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7174999999999999}
2025-05-10 18:53:22,177 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.31527777777777777, 'avg_raw_dharma_score': 0.31666666666666665, 'avg_raw_helpfulness_score': 0.47500000000000003, 'avg_penalty': 0.0, 'avg_combined_reward': 0.36374999999999996}
2025-05-10 18:54:13,748 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6666666666666666, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.7833333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.785}
2025-05-10 18:54:13,939 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6679166666666667, 'avg_raw_dharma_score': 0.5625, 'avg_raw_helpfulness_score': 0.7500000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6503749999999999}
  warnings.warn(
2025-05-10 18:55:17,365 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.717361111111111, 'avg_raw_dharma_score': 0.8666666666666667, 'avg_raw_helpfulness_score': 0.775, 'avg_penalty': 0.0, 'avg_combined_reward': 0.794375}
2025-05-10 18:55:22,326 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6, 'avg_raw_dharma_score': 0.7291666666666666, 'avg_raw_helpfulness_score': 0.6666666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6716666666666665}
 12%|‚ñà‚ñè        | 2921/24000 [1:11:38<53:36:06,  9.15s/it] 12%|‚ñà‚ñè        | 2922/24000 [1:11:38<38:37:49,  6.60s/it] 12%|‚ñà‚ñè        | 2923/24000 [1:11:39<28:09:11,  4.81s/it] 12%|‚ñà‚ñè        | 2924/24000 [1:11:40<20:49:10,  3.56s/it] 12%|‚ñà‚ñè        | 2925/24000 [1:11:40<15:41:25,  2.68s/it]                                                         {'loss': -0.0582, 'grad_norm': 11.5625, 'learning_rate': 2.9040738220080663e-06, 'kl': 0.44670685529708865, 'clip_ratio/low_mean': 0.08004486646076354, 'clip_ratio/low_min': 0.05034905932145193, 'clip_ratio/high_mean': 0.042604819455494485, 'clip_ratio/high_max': 0.055998371212432785, 'clip_ratio/region_mean': 0.12264968746341764, 'num_tokens': 699472.0, 'completions/mean_length': 333.2083435058594, 'completions/min_length': 73.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 307.66668701171875, 'completions/min_terminated_length': 73.0, 'completions/max_terminated_length': 445.0, 'rewards/combined_reward_trl/mean': 0.7330208420753479, 'rewards/combined_reward_trl/std': 0.21020333468914032, 'reward': 0.7330209016799927, 'reward_std': 0.14854875206947327, 'epoch': 0.97}
2025-05-10 18:56:12,719 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5979166666666665, 'avg_raw_dharma_score': 0.6916666666666668, 'avg_raw_helpfulness_score': 0.6166666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6410416666666666}
2025-05-10 18:56:13,030 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6616666666666667, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.775, 'avg_penalty': 0.0, 'avg_combined_reward': 0.831}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 18:57:02,773 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6958333333333334, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.6583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.75625}
2025-05-10 18:57:22,597 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5159722222222222, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.5833333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5964583333333334}
2025-05-10 18:58:14,186 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8458333333333333, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.875, 'avg_penalty': 0.0, 'avg_combined_reward': 0.9162500000000001}
2025-05-10 18:58:16,301 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6041666666666666, 'avg_raw_dharma_score': 0.5, 'avg_raw_helpfulness_score': 0.6666666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.58125}
2025-05-10 18:59:04,156 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7583333333333333, 'avg_raw_dharma_score': 0.9666666666666668, 'avg_raw_helpfulness_score': 0.725, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8316666666666667}
2025-05-10 18:59:04,863 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8416666666666667, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.8083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.895}
  warnings.warn(
2025-05-10 19:00:09,085 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5750000000000001, 'avg_raw_dharma_score': 0.775, 'avg_raw_helpfulness_score': 0.6166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6675}
2025-05-10 19:00:09,603 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5583333333333333, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.6000000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6475000000000001}
 13%|‚ñà‚ñé        | 3121/24000 [1:16:25<50:22:09,  8.68s/it] 13%|‚ñà‚ñé        | 3122/24000 [1:16:26<36:21:22,  6.27s/it] 13%|‚ñà‚ñé        | 3123/24000 [1:16:26<26:32:51,  4.58s/it] 13%|‚ñà‚ñé        | 3124/24000 [1:16:27<19:40:54,  3.39s/it] 13%|‚ñà‚ñé        | 3125/24000 [1:16:28<14:53:32,  2.57s/it]                                                         {'loss': -0.0026, 'grad_norm': 15.875, 'learning_rate': 2.8896521955643314e-06, 'kl': 0.4121756527821223, 'clip_ratio/low_mean': 0.06016690524915854, 'clip_ratio/low_min': 0.04990888133645058, 'clip_ratio/high_mean': 0.04192068692917625, 'clip_ratio/high_max': 0.05444957078124086, 'clip_ratio/region_mean': 0.10208759222800533, 'num_tokens': 744040.0, 'completions/mean_length': 333.875, 'completions/min_length': 156.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.16666666666666663, 'completions/mean_terminated_length': 298.25, 'completions/min_terminated_length': 156.0, 'completions/max_terminated_length': 488.0, 'rewards/combined_reward_trl/mean': 0.6574999690055847, 'rewards/combined_reward_trl/std': 0.2808258831501007, 'reward': 0.6575000286102295, 'reward_std': 0.25321000814437866, 'epoch': 1.04}
 13%|‚ñà‚ñé        | 3125/24000 [1:16:28<14:53:32,  2.57s/it] 13%|‚ñà‚ñé        | 3126/24000 [1:16:28<11:31:53,  1.99s/it]wandb: WARNING Tried to log to step 3125 that is less than the current step 28486. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-10 19:01:02,883 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6243055555555556, 'avg_raw_dharma_score': 0.7541666666666668, 'avg_raw_helpfulness_score': 0.7083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7014583333333334}
2025-05-10 19:01:03,605 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7195833333333334, 'avg_raw_dharma_score': 0.8791666666666668, 'avg_raw_helpfulness_score': 0.7500000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7925416666666667}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 19:01:57,958 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6916666666666668, 'avg_raw_dharma_score': 0.9, 'avg_raw_helpfulness_score': 0.8250000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.815}
2025-05-10 19:02:10,581 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.71375, 'avg_raw_dharma_score': 0.7666666666666666, 'avg_raw_helpfulness_score': 0.8333333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7707916666666667}
2025-05-10 19:03:01,314 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5687500000000001, 'avg_raw_dharma_score': 0.48333333333333334, 'avg_raw_helpfulness_score': 0.6083333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5464583333333334}
2025-05-10 19:03:02,539 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6520833333333332, 'avg_raw_dharma_score': 0.6458333333333334, 'avg_raw_helpfulness_score': 0.6666666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6539583333333333}
2025-05-10 19:03:52,388 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.44583333333333336, 'avg_raw_dharma_score': 0.4083333333333334, 'avg_raw_helpfulness_score': 0.5083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.4495833333333333}
2025-05-10 19:03:53,740 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7749999999999999, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.7500000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8241666666666667}
  warnings.warn(
2025-05-10 19:05:01,556 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5422222222222223, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.7166666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6943333333333334}
2025-05-10 19:05:02,003 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6479166666666667, 'avg_raw_dharma_score': 0.7083333333333334, 'avg_raw_helpfulness_score': 0.7583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7052083333333332}
 14%|‚ñà‚ñç        | 3321/24000 [1:21:18<51:58:00,  9.05s/it] 14%|‚ñà‚ñç        | 3322/24000 [1:21:18<37:28:09,  6.52s/it] 14%|‚ñà‚ñç        | 3323/24000 [1:21:19<27:19:13,  4.76s/it] 14%|‚ñà‚ñç        | 3324/24000 [1:21:19<20:13:02,  3.52s/it] 14%|‚ñà‚ñç        | 3325/24000 [1:21:20<15:14:44,  2.65s/it]                                                         {'loss': 0.0114, 'grad_norm': 11.125, 'learning_rate': 2.8742620979065635e-06, 'kl': 1.1357995559771856, 'clip_ratio/low_mean': 0.05906284678882609, 'clip_ratio/low_min': 0.0303111071845827, 'clip_ratio/high_mean': 0.08380209119990469, 'clip_ratio/high_max': 0.12326215508704384, 'clip_ratio/region_mean': 0.14286493786300222, 'num_tokens': 788433.0, 'completions/mean_length': 348.41668701171875, 'completions/min_length': 100.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.08333333333333337, 'completions/mean_terminated_length': 333.54547119140625, 'completions/min_terminated_length': 100.0, 'completions/max_terminated_length': 463.0, 'rewards/combined_reward_trl/mean': 0.6997707486152649, 'rewards/combined_reward_trl/std': 0.19885393977165222, 'reward': 0.6997708678245544, 'reward_std': 0.1360473930835724, 'epoch': 1.11}
2025-05-10 19:05:53,197 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5166666666666667, 'avg_raw_dharma_score': 0.6083333333333333, 'avg_raw_helpfulness_score': 0.5916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5758333333333333}
2025-05-10 19:05:57,301 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7749999999999999, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.8916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.9000000000000002}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 19:06:50,815 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6833333333333332, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.7250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7725}
2025-05-10 19:07:02,607 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7034722222222224, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.7666666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7743750000000001}
2025-05-10 19:07:53,913 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5663888888888888, 'avg_raw_dharma_score': 0.6124999999999999, 'avg_raw_helpfulness_score': 0.625, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6024166666666667}
2025-05-10 19:07:54,092 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5295833333333333, 'avg_raw_dharma_score': 0.6083333333333333, 'avg_raw_helpfulness_score': 0.6166666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5872083333333334}
2025-05-10 19:08:44,589 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8116666666666666, 'avg_raw_dharma_score': 0.9833333333333334, 'avg_raw_helpfulness_score': 0.8916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.9043333333333335}
2025-05-10 19:08:45,849 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7125, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.8750000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8762500000000001}
  warnings.warn(
2025-05-10 19:09:50,035 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5333333333333333, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.5500000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6416666666666667}
2025-05-10 19:09:53,961 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6833333333333332, 'avg_raw_dharma_score': 0.7583333333333334, 'avg_raw_helpfulness_score': 0.7666666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7383333333333334}
 15%|‚ñà‚ñç        | 3521/24000 [1:26:09<51:20:29,  9.03s/it] 15%|‚ñà‚ñç        | 3522/24000 [1:26:10<37:00:42,  6.51s/it] 15%|‚ñà‚ñç        | 3523/24000 [1:26:11<26:58:50,  4.74s/it] 15%|‚ñà‚ñç        | 3524/24000 [1:26:11<19:57:34,  3.51s/it] 15%|‚ñà‚ñç        | 3525/24000 [1:26:12<15:02:39,  2.65s/it]                                                         {'loss': -0.0797, 'grad_norm': 11.0, 'learning_rate': 2.8579142546440987e-06, 'kl': 0.28870928168296817, 'clip_ratio/low_mean': 0.03810762677108869, 'clip_ratio/low_min': 0.03187573631294072, 'clip_ratio/high_mean': 0.033789492246384424, 'clip_ratio/high_max': 0.04191031666472554, 'clip_ratio/region_mean': 0.07189711933024227, 'num_tokens': 834320.0, 'completions/mean_length': 304.91668701171875, 'completions/min_length': 16.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.08333333333333337, 'completions/mean_terminated_length': 286.0909118652344, 'completions/min_terminated_length': 16.0, 'completions/max_terminated_length': 501.0, 'rewards/combined_reward_trl/mean': 0.6899999976158142, 'rewards/combined_reward_trl/std': 0.2832843065261841, 'reward': 0.690000057220459, 'reward_std': 0.229394793510437, 'epoch': 1.18}
2025-05-10 19:10:46,120 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.741111111111111, 'avg_raw_dharma_score': 0.9041666666666667, 'avg_raw_helpfulness_score': 0.8166666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8289999999999998}
2025-05-10 19:10:46,425 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.725, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.8500000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8558333333333333}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 19:11:39,095 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6458333333333333, 'avg_raw_dharma_score': 0.5, 'avg_raw_helpfulness_score': 0.6750000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.59625}
2025-05-10 19:11:49,649 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7000000000000001, 'avg_raw_dharma_score': 0.8166666666666668, 'avg_raw_helpfulness_score': 0.7916666666666669, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7741666666666666}
2025-05-10 19:12:37,347 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7916666666666666, 'avg_raw_dharma_score': 0.9791666666666666, 'avg_raw_helpfulness_score': 0.8916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8966666666666668}
2025-05-10 19:12:41,035 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4666666666666666, 'avg_raw_dharma_score': 0.4583333333333333, 'avg_raw_helpfulness_score': 0.6, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5033333333333333}
2025-05-10 19:13:30,550 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7333333333333334, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.8750000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8825}
2025-05-10 19:13:33,628 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6845833333333333, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.7749999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.787875}
  warnings.warn(
2025-05-10 19:14:39,478 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7229166666666665, 'avg_raw_dharma_score': 0.9, 'avg_raw_helpfulness_score': 0.7833333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.811875}
2025-05-10 19:14:40,326 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7041666666666666, 'avg_raw_dharma_score': 0.8250000000000001, 'avg_raw_helpfulness_score': 0.775, 'avg_penalty': 0.0, 'avg_combined_reward': 0.77375}
 16%|‚ñà‚ñå        | 3721/24000 [1:30:56<47:53:27,  8.50s/it] 16%|‚ñà‚ñå        | 3722/24000 [1:30:56<34:35:24,  6.14s/it] 16%|‚ñà‚ñå        | 3723/24000 [1:30:57<25:16:50,  4.49s/it] 16%|‚ñà‚ñå        | 3724/24000 [1:30:58<18:45:50,  3.33s/it] 16%|‚ñà‚ñå        | 3725/24000 [1:30:58<14:12:08,  2.52s/it]                                                         {'loss': -0.0602, 'grad_norm': 5.34375, 'learning_rate': 2.840620058854761e-06, 'kl': 0.29049586176872255, 'clip_ratio/low_mean': 0.06531890541470299, 'clip_ratio/low_min': 0.024590287599712612, 'clip_ratio/high_mean': 0.03730707669475426, 'clip_ratio/high_max': 0.05497213103498022, 'clip_ratio/region_mean': 0.10262598203805585, 'num_tokens': 878911.0, 'completions/mean_length': 324.7083435058594, 'completions/min_length': 9.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.08333333333333337, 'completions/mean_terminated_length': 307.68182373046875, 'completions/min_terminated_length': 9.0, 'completions/max_terminated_length': 429.0, 'rewards/combined_reward_trl/mean': 0.7928125262260437, 'rewards/combined_reward_trl/std': 0.1991630643606186, 'reward': 0.7928125262260437, 'reward_std': 0.17013977468013763, 'epoch': 1.24}
 16%|‚ñà‚ñå        | 3725/24000 [1:30:58<14:12:08,  2.52s/it] 16%|‚ñà‚ñå        | 3726/24000 [1:30:59<11:01:04,  1.96s/it]wandb: WARNING Tried to log to step 3725 that is less than the current step 33955. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-10 19:15:32,656 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5375000000000001, 'avg_raw_dharma_score': 0.6416666666666667, 'avg_raw_helpfulness_score': 0.5499999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5829166666666666}
2025-05-10 19:15:34,069 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6250000000000001, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.7333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7075}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 19:16:26,841 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6291666666666665, 'avg_raw_dharma_score': 0.8458333333333333, 'avg_raw_helpfulness_score': 0.7416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7495833333333332}
2025-05-10 19:16:41,118 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5666666666666665, 'avg_raw_dharma_score': 0.7958333333333334, 'avg_raw_helpfulness_score': 0.6916666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6958333333333334}
2025-05-10 19:17:26,030 - openai._base_client - INFO - Retrying request to /chat/completions in 0.495181 seconds
2025-05-10 19:17:32,368 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.45, 'avg_raw_dharma_score': 0.5083333333333333, 'avg_raw_helpfulness_score': 0.5750000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5108333333333334}
2025-05-10 19:17:33,977 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4054166666666667, 'avg_raw_dharma_score': 0.5416666666666666, 'avg_raw_helpfulness_score': 0.5, 'avg_penalty': 0.0, 'avg_combined_reward': 0.48829166666666673}
2025-05-10 19:18:20,876 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7191666666666667, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.8166666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8440833333333334}
2025-05-10 19:18:25,246 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7025, 'avg_raw_dharma_score': 0.8833333333333334, 'avg_raw_helpfulness_score': 0.7500000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7890833333333335}
  warnings.warn(
2025-05-10 19:19:29,240 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7744444444444443, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.9, 'avg_penalty': 0.0, 'avg_combined_reward': 0.9023333333333335}
2025-05-10 19:19:30,182 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8000000000000002, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.9, 'avg_penalty': 0.0, 'avg_combined_reward': 0.9099999999999998}
 16%|‚ñà‚ñã        | 3921/24000 [1:35:46<44:53:03,  8.05s/it] 16%|‚ñà‚ñã        | 3922/24000 [1:35:46<32:23:09,  5.81s/it] 16%|‚ñà‚ñã        | 3923/24000 [1:35:47<23:38:14,  4.24s/it] 16%|‚ñà‚ñã        | 3924/24000 [1:35:47<17:30:46,  3.14s/it] 16%|‚ñà‚ñã        | 3925/24000 [1:35:48<13:13:31,  2.37s/it]                                                         {'loss': -0.0691, 'grad_norm': 5.40625, 'learning_rate': 2.822391563144838e-06, 'kl': 0.3119640682140986, 'clip_ratio/low_mean': 0.07459118187505132, 'clip_ratio/low_min': 0.012963324565595636, 'clip_ratio/high_mean': 0.05079948079384242, 'clip_ratio/high_max': 0.06592427649690459, 'clip_ratio/region_mean': 0.1253906635583068, 'num_tokens': 923738.0, 'completions/mean_length': 343.7083435058594, 'completions/min_length': 253.0, 'completions/max_length': 452.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 343.7083435058594, 'completions/min_terminated_length': 253.0, 'completions/max_terminated_length': 452.0, 'rewards/combined_reward_trl/mean': 0.9061667323112488, 'rewards/combined_reward_trl/std': 0.019394464790821075, 'reward': 0.9061667323112488, 'reward_std': 0.00837220810353756, 'epoch': 1.31}
 16%|‚ñà‚ñã        | 3925/24000 [1:35:48<13:13:31,  2.37s/it] 16%|‚ñà‚ñã        | 3926/24000 [1:35:49<10:13:59,  1.84s/it] 16%|‚ñà‚ñã        | 3927/24000 [1:35:49<8:07:49,  1.46s/it] wandb: WARNING Tried to log to step 3925 that is less than the current step 35778. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-10 19:20:18,318 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5020833333333333, 'avg_raw_dharma_score': 0.6083333333333333, 'avg_raw_helpfulness_score': 0.5583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5614583333333334}
2025-05-10 19:20:19,140 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5725000000000001, 'avg_raw_dharma_score': 0.775, 'avg_raw_helpfulness_score': 0.6749999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.68425}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 19:21:12,250 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.74375, 'avg_raw_dharma_score': 0.9833333333333334, 'avg_raw_helpfulness_score': 0.8916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8839583333333332}
2025-05-10 19:21:24,192 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.3429166666666667, 'avg_raw_dharma_score': 0.43333333333333335, 'avg_raw_helpfulness_score': 0.44166666666666665, 'avg_penalty': 0.0, 'avg_combined_reward': 0.4087083333333334}
2025-05-10 19:22:15,631 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5750000000000001, 'avg_raw_dharma_score': 0.6458333333333334, 'avg_raw_helpfulness_score': 0.6250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6183333333333334}
2025-05-10 19:22:16,503 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6583333333333333, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.7416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7866666666666667}
2025-05-10 19:23:06,730 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.55, 'avg_raw_dharma_score': 0.7083333333333334, 'avg_raw_helpfulness_score': 0.5750000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6208333333333335}
2025-05-10 19:23:07,493 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7333333333333333, 'avg_raw_dharma_score': 0.9416666666666668, 'avg_raw_helpfulness_score': 0.7583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8241666666666667}
  warnings.warn(
2025-05-10 19:24:13,356 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4291666666666667, 'avg_raw_dharma_score': 0.5, 'avg_raw_helpfulness_score': 0.4583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.4662499999999999}
2025-05-10 19:24:13,500 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.525, 'avg_raw_dharma_score': 0.65, 'avg_raw_helpfulness_score': 0.5583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.585}
 17%|‚ñà‚ñã        | 4121/24000 [1:40:29<46:26:21,  8.41s/it] 17%|‚ñà‚ñã        | 4122/24000 [1:40:30<33:32:50,  6.08s/it] 17%|‚ñà‚ñã        | 4123/24000 [1:40:30<24:31:27,  4.44s/it] 17%|‚ñà‚ñã        | 4124/24000 [1:40:31<18:12:27,  3.30s/it] 17%|‚ñà‚ñã        | 4125/24000 [1:40:32<13:47:11,  2.50s/it]                                                         {'loss': 0.1443, 'grad_norm': 13.5625, 'learning_rate': 2.803241471249428e-06, 'kl': 1.1734664191802342, 'clip_ratio/low_mean': 0.07040419177695488, 'clip_ratio/low_min': 0.022726253788763036, 'clip_ratio/high_mean': 0.061134562734514473, 'clip_ratio/high_max': 0.09546122554844866, 'clip_ratio/region_mean': 0.13153875483510394, 'num_tokens': 966704.0, 'completions/mean_length': 306.4583435058594, 'completions/min_length': 88.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.20833333333333337, 'completions/mean_terminated_length': 252.36842346191406, 'completions/min_terminated_length': 88.0, 'completions/max_terminated_length': 409.0, 'rewards/combined_reward_trl/mean': 0.5256249904632568, 'rewards/combined_reward_trl/std': 0.362741082906723, 'reward': 0.5256249904632568, 'reward_std': 0.3357352912425995, 'epoch': 1.38}
2025-05-10 19:25:05,956 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7104166666666666, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.7166666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8114583333333333}
2025-05-10 19:25:08,517 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7083333333333334, 'avg_raw_dharma_score': 0.775, 'avg_raw_helpfulness_score': 0.775, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7549999999999999}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 19:26:03,175 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.46249999999999997, 'avg_raw_dharma_score': 0.6083333333333333, 'avg_raw_helpfulness_score': 0.525, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5395833333333332}
2025-05-10 19:26:10,718 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.7333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7666666666666667}
2025-05-10 19:27:00,304 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6541666666666667, 'avg_raw_dharma_score': 0.775, 'avg_raw_helpfulness_score': 0.6666666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7062500000000002}
2025-05-10 19:27:02,073 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6666666666666666, 'avg_raw_dharma_score': 0.625, 'avg_raw_helpfulness_score': 0.7833333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.685}
2025-05-10 19:27:54,774 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5625, 'avg_raw_dharma_score': 0.65, 'avg_raw_helpfulness_score': 0.5416666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.59125}
2025-05-10 19:27:55,675 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.642361111111111, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.7416666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7818749999999999}
  warnings.warn(
2025-05-10 19:29:01,350 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5812499999999999, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.6083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.656875}
2025-05-10 19:29:02,445 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7000000000000001, 'avg_raw_dharma_score': 0.7708333333333334, 'avg_raw_helpfulness_score': 0.7916666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7558333333333334}
 18%|‚ñà‚ñä        | 4321/24000 [1:45:18<49:54:11,  9.13s/it] 18%|‚ñà‚ñä        | 4322/24000 [1:45:19<35:58:16,  6.58s/it] 18%|‚ñà‚ñä        | 4323/24000 [1:45:19<26:13:05,  4.80s/it] 18%|‚ñà‚ñä        | 4324/24000 [1:45:20<19:23:24,  3.55s/it] 18%|‚ñà‚ñä        | 4325/24000 [1:45:21<14:36:40,  2.67s/it]                                                         {'loss': -0.0091, 'grad_norm': 18.875, 'learning_rate': 2.7831831291789975e-06, 'kl': 0.8021535178025564, 'clip_ratio/low_mean': 0.08475417074242918, 'clip_ratio/low_min': 0.05694358671704928, 'clip_ratio/high_mean': 0.06030403391458094, 'clip_ratio/high_max': 0.080670807727923, 'clip_ratio/region_mean': 0.1450582054598878, 'num_tokens': 1009632.0, 'completions/mean_length': 323.75, 'completions/min_length': 168.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.04166666666666663, 'completions/mean_terminated_length': 315.5652160644531, 'completions/min_terminated_length': 168.0, 'completions/max_terminated_length': 461.0, 'rewards/combined_reward_trl/mean': 0.7063541412353516, 'rewards/combined_reward_trl/std': 0.24767503142356873, 'reward': 0.7063541412353516, 'reward_std': 0.23859672248363495, 'epoch': 1.44}
2025-05-10 19:29:48,433 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7566666666666668, 'avg_raw_dharma_score': 0.9500000000000001, 'avg_raw_helpfulness_score': 0.8416666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8595}
2025-05-10 19:29:55,729 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7441666666666668, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.8333333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8565833333333334}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 19:30:46,742 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.54875, 'avg_raw_dharma_score': 0.7333333333333334, 'avg_raw_helpfulness_score': 0.6250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6454583333333334}
2025-05-10 19:31:03,489 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5166666666666667, 'avg_raw_dharma_score': 0.5499999999999999, 'avg_raw_helpfulness_score': 0.6083333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5575}
2025-05-10 19:31:50,301 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.63875, 'avg_raw_dharma_score': 0.8583333333333334, 'avg_raw_helpfulness_score': 0.7000000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7449583333333333}
2025-05-10 19:31:57,342 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5715277777777777, 'avg_raw_dharma_score': 0.625, 'avg_raw_helpfulness_score': 0.6250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6089583333333334}
2025-05-10 19:32:47,704 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6124999999999999, 'avg_raw_dharma_score': 0.8583333333333334, 'avg_raw_helpfulness_score': 0.8083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7695833333333336}
2025-05-10 19:32:48,112 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6366666666666667, 'avg_raw_dharma_score': 0.7083333333333334, 'avg_raw_helpfulness_score': 0.7083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6868333333333334}
  warnings.warn(
2025-05-10 19:33:50,071 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5499999999999999, 'avg_raw_dharma_score': 0.7541666666666668, 'avg_raw_helpfulness_score': 0.5916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6441666666666667}
2025-05-10 19:33:51,280 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7374999999999999, 'avg_raw_dharma_score': 0.5, 'avg_raw_helpfulness_score': 0.7583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.64875}
 19%|‚ñà‚ñâ        | 4521/24000 [1:50:07<50:15:42,  9.29s/it] 19%|‚ñà‚ñâ        | 4522/24000 [1:50:07<36:12:24,  6.69s/it] 19%|‚ñà‚ñâ        | 4523/24000 [1:50:08<26:22:05,  4.87s/it] 19%|‚ñà‚ñâ        | 4524/24000 [1:50:09<19:28:51,  3.60s/it] 19%|‚ñà‚ñâ        | 4525/24000 [1:50:09<14:39:36,  2.71s/it]                                                         {'loss': -0.0037, 'grad_norm': 12.8125, 'learning_rate': 2.7622305159183297e-06, 'kl': 0.46059926827748615, 'clip_ratio/low_mean': 0.07276779252414901, 'clip_ratio/low_min': 0.026708867570074898, 'clip_ratio/high_mean': 0.041048139482736584, 'clip_ratio/high_max': 0.04527046906296164, 'clip_ratio/region_mean': 0.11381593223350743, 'num_tokens': 1051017.0, 'completions/mean_length': 280.125, 'completions/min_length': 1.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 247.0, 'completions/min_terminated_length': 1.0, 'completions/max_terminated_length': 494.0, 'rewards/combined_reward_trl/mean': 0.6464583873748779, 'rewards/combined_reward_trl/std': 0.22140108048915863, 'reward': 0.6464583873748779, 'reward_std': 0.11521624028682709, 'epoch': 1.51}
 19%|‚ñà‚ñâ        | 4525/24000 [1:50:09<14:39:36,  2.71s/it] 19%|‚ñà‚ñâ        | 4526/24000 [1:50:10<11:17:37,  2.09s/it] 19%|‚ñà‚ñâ        | 4527/24000 [1:50:11<8:55:43,  1.65s/it] wandb: WARNING Tried to log to step 4525 that is less than the current step 41247. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-10 19:34:40,452 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6166666666666667, 'avg_raw_dharma_score': 0.6708333333333334, 'avg_raw_helpfulness_score': 0.7583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6808333333333333}
2025-05-10 19:34:43,178 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7041666666666666, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.8416666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8470833333333334}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 19:35:35,578 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6625000000000001, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.7416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7879166666666665}
2025-05-10 19:35:47,965 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.33749999999999997, 'avg_raw_dharma_score': 0.26666666666666666, 'avg_raw_helpfulness_score': 0.5083333333333332, 'avg_penalty': 0.0, 'avg_combined_reward': 0.3604166666666666}
2025-05-10 19:36:37,857 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7145833333333332, 'avg_raw_dharma_score': 0.8250000000000002, 'avg_raw_helpfulness_score': 0.75, 'avg_penalty': 0.0, 'avg_combined_reward': 0.769375}
2025-05-10 19:36:40,250 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5541666666666667, 'avg_raw_dharma_score': 0.6916666666666668, 'avg_raw_helpfulness_score': 0.5666666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6129166666666667}
2025-05-10 19:37:31,133 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6041666666666666, 'avg_raw_dharma_score': 0.7083333333333334, 'avg_raw_helpfulness_score': 0.6, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6445833333333334}
2025-05-10 19:37:32,021 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4000000000000001, 'avg_raw_dharma_score': 0.4166666666666667, 'avg_raw_helpfulness_score': 0.5083333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.43916666666666676}
  warnings.warn(
2025-05-10 19:38:38,239 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5541666666666666, 'avg_raw_dharma_score': 0.725, 'avg_raw_helpfulness_score': 0.7250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6737500000000001}
2025-05-10 19:38:38,715 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7083333333333334, 'avg_raw_dharma_score': 0.5208333333333334, 'avg_raw_helpfulness_score': 0.8666666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6808333333333333}
 20%|‚ñà‚ñâ        | 4721/24000 [1:54:54<45:55:37,  8.58s/it] 20%|‚ñà‚ñâ        | 4722/24000 [1:54:55<33:09:40,  6.19s/it] 20%|‚ñà‚ñâ        | 4723/24000 [1:54:55<24:13:28,  4.52s/it] 20%|‚ñà‚ñâ        | 4724/24000 [1:54:56<17:58:13,  3.36s/it] 20%|‚ñà‚ñâ        | 4725/24000 [1:54:57<13:35:30,  2.54s/it]                                                         {'loss': 0.1485, 'grad_norm': 5.84375, 'learning_rate': 2.740398233684345e-06, 'kl': 1.5286972131331762, 'clip_ratio/low_mean': 0.10965132033297172, 'clip_ratio/low_min': 0.027691254473756997, 'clip_ratio/high_mean': 0.10452891558098297, 'clip_ratio/high_max': 0.17141420669543248, 'clip_ratio/region_mean': 0.21418023383244872, 'num_tokens': 1093270.0, 'completions/mean_length': 322.54168701171875, 'completions/min_length': 1.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.04166666666666663, 'completions/mean_terminated_length': 314.3043518066406, 'completions/min_terminated_length': 1.0, 'completions/max_terminated_length': 504.0, 'rewards/combined_reward_trl/mean': 0.6772916316986084, 'rewards/combined_reward_trl/std': 0.2397960126399994, 'reward': 0.677291750907898, 'reward_std': 0.14632849395275116, 'epoch': 1.57}
2025-05-10 19:39:27,912 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7291666666666666, 'avg_raw_dharma_score': 0.7291666666666666, 'avg_raw_helpfulness_score': 0.7916666666666669, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7479166666666665}
2025-05-10 19:39:32,524 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7666666666666667, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.8000000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8533333333333334}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 19:40:25,292 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.47361111111111115, 'avg_raw_dharma_score': 0.6333333333333333, 'avg_raw_helpfulness_score': 0.525, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5529166666666666}
2025-05-10 19:40:39,063 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.775, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.7999999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8724999999999999}
2025-05-10 19:41:26,568 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5783333333333334, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.5583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6576666666666666}
2025-05-10 19:41:30,393 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5375000000000001, 'avg_raw_dharma_score': 0.7083333333333334, 'avg_raw_helpfulness_score': 0.6749999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6470833333333333}
2025-05-10 19:42:22,976 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5541666666666667, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.6500000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6945833333333334}
2025-05-10 19:42:23,135 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.39166666666666666, 'avg_raw_dharma_score': 0.5166666666666667, 'avg_raw_helpfulness_score': 0.55, 'avg_penalty': 0.0, 'avg_combined_reward': 0.4891666666666666}
  warnings.warn(
2025-05-10 19:43:26,216 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7361111111111112, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.75, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7458333333333335}
2025-05-10 19:43:29,133 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6416666666666666, 'avg_raw_dharma_score': 0.6041666666666666, 'avg_raw_helpfulness_score': 0.6583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6316666666666667}
 21%|‚ñà‚ñà        | 4921/24000 [1:59:45<47:19:03,  8.93s/it] 21%|‚ñà‚ñà        | 4922/24000 [1:59:45<34:07:08,  6.44s/it] 21%|‚ñà‚ñà        | 4923/24000 [1:59:46<24:52:49,  4.70s/it] 21%|‚ñà‚ñà        | 4924/24000 [1:59:47<18:24:49,  3.48s/it] 21%|‚ñà‚ñà        | 4925/24000 [1:59:47<13:53:13,  2.62s/it]                                                         {'loss': 0.0483, 'grad_norm': 5.28125, 'learning_rate': 2.7177014977495743e-06, 'kl': 1.5168200017015139, 'clip_ratio/low_mean': 0.041994750918044395, 'clip_ratio/low_min': 0.005377363983231286, 'clip_ratio/high_mean': 0.09561199557812264, 'clip_ratio/high_max': 0.18512006306710344, 'clip_ratio/region_mean': 0.13760674457686642, 'num_tokens': 1136271.0, 'completions/mean_length': 308.2083435058594, 'completions/min_length': 1.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 279.0952453613281, 'completions/min_terminated_length': 1.0, 'completions/max_terminated_length': 427.0, 'rewards/combined_reward_trl/mean': 0.6887500286102295, 'rewards/combined_reward_trl/std': 0.2076328843832016, 'reward': 0.6887499690055847, 'reward_std': 0.127448171377182, 'epoch': 1.64}
2025-05-10 19:44:19,729 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6416666666666666, 'avg_raw_dharma_score': 0.7958333333333334, 'avg_raw_helpfulness_score': 0.6916666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7183333333333334}
2025-05-10 19:44:21,978 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5520833333333334, 'avg_raw_dharma_score': 0.7333333333333334, 'avg_raw_helpfulness_score': 0.6416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6514583333333334}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 19:45:15,028 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6416666666666666, 'avg_raw_dharma_score': 0.8666666666666667, 'avg_raw_helpfulness_score': 0.7166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7541666666666668}
2025-05-10 19:45:28,459 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.43, 'avg_raw_dharma_score': 0.7333333333333334, 'avg_raw_helpfulness_score': 0.5166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5773333333333334}
2025-05-10 19:46:19,588 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6812499999999999, 'avg_raw_dharma_score': 0.6708333333333334, 'avg_raw_helpfulness_score': 0.6666666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6727083333333334}
2025-05-10 19:46:19,641 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7333333333333333, 'avg_raw_dharma_score': 0.9375, 'avg_raw_helpfulness_score': 0.775, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8275}
2025-05-10 19:47:11,076 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5854166666666668, 'avg_raw_dharma_score': 0.7083333333333334, 'avg_raw_helpfulness_score': 0.5916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6364583333333333}
2025-05-10 19:47:11,254 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6062500000000001, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.6749999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7177083333333334}
  warnings.warn(
2025-05-10 19:48:15,802 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7195833333333334, 'avg_raw_dharma_score': 0.8416666666666667, 'avg_raw_helpfulness_score': 0.7666666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7825416666666666}
2025-05-10 19:48:16,326 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7712499999999999, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.8583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7888750000000001}
 21%|‚ñà‚ñà‚ñè       | 5121/24000 [2:04:32<45:17:41,  8.64s/it] 21%|‚ñà‚ñà‚ñè       | 5122/24000 [2:04:32<32:41:05,  6.23s/it] 21%|‚ñà‚ñà‚ñè       | 5123/24000 [2:04:33<23:51:36,  4.55s/it] 21%|‚ñà‚ñà‚ñè       | 5124/24000 [2:04:34<17:40:56,  3.37s/it] 21%|‚ñà‚ñà‚ñè       | 5125/24000 [2:04:34<13:21:29,  2.55s/it]                                                         {'loss': 0.0052, 'grad_norm': 6.1875, 'learning_rate': 2.6941561258383915e-06, 'kl': 1.102691356341044, 'clip_ratio/low_mean': 0.06879305924056098, 'clip_ratio/low_min': 0.024791375865849355, 'clip_ratio/high_mean': 0.10914572378310064, 'clip_ratio/high_max': 0.16324813708585376, 'clip_ratio/region_mean': 0.17793878248271844, 'num_tokens': 1182736.0, 'completions/mean_length': 318.0833435058594, 'completions/min_length': 92.0, 'completions/max_length': 506.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 318.0833435058594, 'completions/min_terminated_length': 92.0, 'completions/max_terminated_length': 506.0, 'rewards/combined_reward_trl/mean': 0.7857083678245544, 'rewards/combined_reward_trl/std': 0.1600448191165924, 'reward': 0.7857084274291992, 'reward_std': 0.07466864585876465, 'epoch': 1.71}
2025-05-10 19:49:06,237 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6633333333333333, 'avg_raw_dharma_score': 0.9, 'avg_raw_helpfulness_score': 0.7166666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.774}
2025-05-10 19:49:07,706 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6250000000000001, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.7500000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7625000000000001}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 19:49:59,342 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5729166666666666, 'avg_raw_dharma_score': 0.7458333333333332, 'avg_raw_helpfulness_score': 0.6250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6577083333333335}
2025-05-10 19:50:11,319 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7083333333333334, 'avg_raw_dharma_score': 0.7166666666666667, 'avg_raw_helpfulness_score': 0.6749999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7016666666666667}
2025-05-10 19:51:04,409 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.725, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.7916666666666669, 'avg_penalty': 0.0, 'avg_combined_reward': 0.805}
2025-05-10 19:51:05,301 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.48750000000000004, 'avg_raw_dharma_score': 0.5583333333333333, 'avg_raw_helpfulness_score': 0.6416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5620833333333334}
2025-05-10 19:51:57,005 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.37916666666666665, 'avg_raw_dharma_score': 0.525, 'avg_raw_helpfulness_score': 0.325, 'avg_penalty': 0.0, 'avg_combined_reward': 0.42124999999999996}
2025-05-10 19:51:57,843 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6208333333333335, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.6333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7262500000000002}
  warnings.warn(
2025-05-10 19:53:01,087 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6437499999999999, 'avg_raw_dharma_score': 0.8166666666666668, 'avg_raw_helpfulness_score': 0.7416666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7422916666666666}
2025-05-10 19:53:01,914 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7083333333333334, 'avg_raw_dharma_score': 0.7458333333333332, 'avg_raw_helpfulness_score': 0.7583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7383333333333333}
 22%|‚ñà‚ñà‚ñè       | 5321/24000 [2:09:17<43:17:40,  8.34s/it] 22%|‚ñà‚ñà‚ñè       | 5322/24000 [2:09:18<31:15:07,  6.02s/it] 22%|‚ñà‚ñà‚ñè       | 5323/24000 [2:09:19<22:49:25,  4.40s/it] 22%|‚ñà‚ñà‚ñè       | 5324/24000 [2:09:19<16:55:29,  3.26s/it] 22%|‚ñà‚ñà‚ñè       | 5325/24000 [2:09:20<12:47:32,  2.47s/it]                                                         {'loss': -0.1508, 'grad_norm': 8.1875, 'learning_rate': 2.669778527103384e-06, 'kl': 0.830256447394689, 'clip_ratio/low_mean': 0.05714573308825493, 'clip_ratio/low_min': 0.035656315501158435, 'clip_ratio/high_mean': 0.2100289604626596, 'clip_ratio/high_max': 0.3049457579975327, 'clip_ratio/region_mean': 0.2671746939482788, 'num_tokens': 1227255.0, 'completions/mean_length': 332.25, 'completions/min_length': 12.0, 'completions/max_length': 471.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 332.25, 'completions/min_terminated_length': 12.0, 'completions/max_terminated_length': 471.0, 'rewards/combined_reward_trl/mean': 0.7403125166893005, 'rewards/combined_reward_trl/std': 0.2541784644126892, 'reward': 0.7403125762939453, 'reward_std': 0.18253330886363983, 'epoch': 1.77}
2025-05-10 19:53:52,898 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7354166666666666, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.7666666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8339583333333334}
2025-05-10 19:53:54,564 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5569444444444446, 'avg_raw_dharma_score': 0.625, 'avg_raw_helpfulness_score': 0.6083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5995833333333335}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 19:54:48,088 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8041666666666667, 'avg_raw_dharma_score': 0.9833333333333334, 'avg_raw_helpfulness_score': 0.9083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.9070833333333334}
2025-05-10 19:54:56,422 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7250000000000001, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.9083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8900000000000001}
2025-05-10 19:55:46,045 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7374999999999999, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.8666666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.88125}
2025-05-10 19:55:52,751 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5270833333333332, 'avg_raw_dharma_score': 0.5791666666666667, 'avg_raw_helpfulness_score': 0.725, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6072916666666667}
 23%|‚ñà‚ñà‚ñé       | 5441/24000 [2:12:08<51:30:34,  9.99s/it] 23%|‚ñà‚ñà‚ñé       | 5442/24000 [2:12:09<37:01:47,  7.18s/it] 23%|‚ñà‚ñà‚ñé       | 5443/24000 [2:12:10<26:53:45,  5.22s/it] 23%|‚ñà‚ñà‚ñé       | 5444/24000 [2:12:10<19:48:07,  3.84s/it] 23%|‚ñà‚ñà‚ñé       | 5445/24000 [2:12:11<14:50:15,  2.88s/it] 23%|‚ñà‚ñà‚ñé       | 5446/24000 [2:12:11<11:21:42,  2.20s/it] 23%|‚ñà‚ñà‚ñé       | 5447/24000 [2:12:12<8:55:52,  1.73s/it]  23%|‚ñà‚ñà‚ñé       | 5448/24000 [2:12:13<7:13:41,  1.40s/it] 23%|‚ñà‚ñà‚ñé       | 5449/24000 [2:12:13<6:02:06,  1.17s/it] 23%|‚ñà‚ñà‚ñé       | 5450/24000 [2:12:14<5:12:01,  1.01s/it]                                                        {'loss': 0.0268, 'grad_norm': 4.09375, 'learning_rate': 2.6541274377920694e-06, 'kl': 0.32205565124750135, 'clip_ratio/low_mean': 0.03400865877357622, 'clip_ratio/low_min': 0.013208781421805421, 'clip_ratio/high_mean': 0.03682158828402559, 'clip_ratio/high_max': 0.04924428161854545, 'clip_ratio/region_mean': 0.07083024693342546, 'num_tokens': 1254332.0, 'completions/mean_length': 356.75, 'completions/min_length': 195.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.04166666666666663, 'completions/mean_terminated_length': 350.0, 'completions/min_terminated_length': 195.0, 'completions/max_terminated_length': 435.0, 'rewards/combined_reward_trl/mean': 0.7442708015441895, 'rewards/combined_reward_trl/std': 0.22264647483825684, 'reward': 0.744270920753479, 'reward_std': 0.13216692209243774, 'epoch': 1.82}
2025-05-10 19:56:41,453 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6791666666666666, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.8583333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.86125}
2025-05-10 19:56:43,450 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.725, 'avg_raw_dharma_score': 0.8624999999999999, 'avg_raw_helpfulness_score': 0.8083333333333336, 'avg_penalty': 0.0, 'avg_combined_reward': 0.805}
  warnings.warn(
2025-05-10 19:57:48,634 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7362500000000001, 'avg_raw_dharma_score': 0.9458333333333333, 'avg_raw_helpfulness_score': 0.8083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8417083333333334}
2025-05-10 19:57:48,893 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7000000000000001, 'avg_raw_dharma_score': 0.8541666666666666, 'avg_raw_helpfulness_score': 0.8666666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8116666666666666}
 23%|‚ñà‚ñà‚ñé       | 5521/24000 [2:14:04<45:39:41,  8.90s/it] 23%|‚ñà‚ñà‚ñé       | 5522/24000 [2:14:05<32:56:04,  6.42s/it] 23%|‚ñà‚ñà‚ñé       | 5523/24000 [2:14:06<24:01:32,  4.68s/it] 23%|‚ñà‚ñà‚ñé       | 5524/24000 [2:14:06<17:47:41,  3.47s/it] 23%|‚ñà‚ñà‚ñé       | 5525/24000 [2:14:07<13:25:45,  2.62s/it]                                                         {'loss': 0.0021, 'grad_norm': 18.25, 'learning_rate': 2.6445856906895467e-06, 'kl': 0.25602554380893705, 'clip_ratio/low_mean': 0.056584779910820844, 'clip_ratio/low_min': 0.025500498157925905, 'clip_ratio/high_mean': 0.04625902157276869, 'clip_ratio/high_max': 0.05725728859814505, 'clip_ratio/region_mean': 0.10284380028955638, 'num_tokens': 1273790.0, 'completions/mean_length': 379.41668701171875, 'completions/min_length': 277.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.08333333333333337, 'completions/mean_terminated_length': 367.3636474609375, 'completions/min_terminated_length': 277.0, 'completions/max_terminated_length': 472.0, 'rewards/combined_reward_trl/mean': 0.8266875147819519, 'rewards/combined_reward_trl/std': 0.07947980612516403, 'reward': 0.8266875147819519, 'reward_std': 0.05730711668729782, 'epoch': 1.84}
2025-05-10 19:58:34,858 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6708333333333334, 'avg_raw_dharma_score': 0.5833333333333334, 'avg_raw_helpfulness_score': 0.7583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6620833333333332}
2025-05-10 19:58:42,013 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6666666666666666, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.7833333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.735}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 19:59:31,830 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.765, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.8250000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8436666666666669}
2025-05-10 19:59:45,662 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6666666666666666, 'avg_raw_dharma_score': 0.8541666666666666, 'avg_raw_helpfulness_score': 0.7666666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7716666666666666}
2025-05-10 20:00:37,392 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6750000000000002, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.6916666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.71}
2025-05-10 20:00:38,985 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6591666666666667, 'avg_raw_dharma_score': 0.8583333333333334, 'avg_raw_helpfulness_score': 0.6916666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7485833333333334}
2025-05-10 20:01:31,696 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.61125, 'avg_raw_dharma_score': 0.6833333333333332, 'avg_raw_helpfulness_score': 0.75, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6817083333333332}
2025-05-10 20:01:31,711 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6541666666666667, 'avg_raw_dharma_score': 0.8166666666666668, 'avg_raw_helpfulness_score': 0.7833333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7579166666666667}
  warnings.warn(
2025-05-10 20:02:34,627 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7416666666666667, 'avg_raw_dharma_score': 0.7666666666666666, 'avg_raw_helpfulness_score': 0.6916666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7366666666666667}
2025-05-10 20:02:36,232 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5633333333333334, 'avg_raw_dharma_score': 0.7083333333333334, 'avg_raw_helpfulness_score': 0.6583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6498333333333332}
 24%|‚ñà‚ñà‚ñç       | 5721/24000 [2:18:52<43:09:40,  8.50s/it] 24%|‚ñà‚ñà‚ñç       | 5722/24000 [2:18:53<31:10:31,  6.14s/it] 24%|‚ñà‚ñà‚ñç       | 5723/24000 [2:18:53<22:47:10,  4.49s/it] 24%|‚ñà‚ñà‚ñç       | 5724/24000 [2:18:54<16:54:52,  3.33s/it] 24%|‚ñà‚ñà‚ñç       | 5725/24000 [2:18:54<12:48:11,  2.52s/it]                                                         {'loss': 0.083, 'grad_norm': 7.25, 'learning_rate': 2.618595173894269e-06, 'kl': 1.3226462826132774, 'clip_ratio/low_mean': 0.04305415526110058, 'clip_ratio/low_min': 0.028457351432492336, 'clip_ratio/high_mean': 0.04718961821869016, 'clip_ratio/high_max': 0.054091703860710064, 'clip_ratio/region_mean': 0.09024377321824431, 'num_tokens': 1320262.0, 'completions/mean_length': 330.79168701171875, 'completions/min_length': 61.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.04166666666666663, 'completions/mean_terminated_length': 322.9130554199219, 'completions/min_terminated_length': 61.0, 'completions/max_terminated_length': 500.0, 'rewards/combined_reward_trl/mean': 0.6932500004768372, 'rewards/combined_reward_trl/std': 0.2911859452724457, 'reward': 0.6932500600814819, 'reward_std': 0.23620685935020447, 'epoch': 1.91}
 24%|‚ñà‚ñà‚ñç       | 5725/24000 [2:18:54<12:48:11,  2.52s/it]wandb: WARNING Tried to log to step 5725 that is less than the current step 52185. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-10 20:03:26,855 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.49583333333333335, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.6083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.63125}
2025-05-10 20:03:30,047 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7752777777777778, 'avg_raw_dharma_score': 0.9666666666666668, 'avg_raw_helpfulness_score': 0.8750000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8817499999999999}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 20:04:22,479 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8263888888888888, 'avg_raw_dharma_score': 0.9833333333333334, 'avg_raw_helpfulness_score': 0.8750000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.9037500000000002}
2025-05-10 20:04:37,527 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6916666666666668, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.7666666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8041666666666667}
2025-05-10 20:05:33,393 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7083333333333334, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.8000000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8025000000000001}
2025-05-10 20:05:36,660 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6749999999999999, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.625, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7233333333333333}
 24%|‚ñà‚ñà‚ñç       | 5841/24000 [2:21:52<54:24:59, 10.79s/it] 24%|‚ñà‚ñà‚ñç       | 5842/24000 [2:21:53<39:02:57,  7.74s/it] 24%|‚ñà‚ñà‚ñç       | 5843/24000 [2:21:53<28:17:31,  5.61s/it] 24%|‚ñà‚ñà‚ñç       | 5844/24000 [2:21:54<20:46:04,  4.12s/it] 24%|‚ñà‚ñà‚ñç       | 5845/24000 [2:21:55<15:29:46,  3.07s/it] 24%|‚ñà‚ñà‚ñç       | 5846/24000 [2:21:55<11:48:25,  2.34s/it] 24%|‚ñà‚ñà‚ñç       | 5847/24000 [2:21:56<9:14:02,  1.83s/it]  24%|‚ñà‚ñà‚ñç       | 5848/24000 [2:21:57<7:25:29,  1.47s/it] 24%|‚ñà‚ñà‚ñç       | 5849/24000 [2:21:57<6:09:27,  1.22s/it] 24%|‚ñà‚ñà‚ñç       | 5850/24000 [2:21:58<5:16:11,  1.05s/it]                                                        {'loss': 0.0148, 'grad_norm': 5.03125, 'learning_rate': 2.601954054401432e-06, 'kl': 0.6008094253142675, 'clip_ratio/low_mean': 0.04012378053933693, 'clip_ratio/low_min': 0.027539438710858424, 'clip_ratio/high_mean': 0.047795618698000905, 'clip_ratio/high_max': 0.06085779815912247, 'clip_ratio/region_mean': 0.08791939875576645, 'num_tokens': 1347991.0, 'completions/mean_length': 384.2083435058594, 'completions/min_length': 192.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 341.6111145019531, 'completions/min_terminated_length': 192.0, 'completions/max_terminated_length': 466.0, 'rewards/combined_reward_trl/mean': 0.762916624546051, 'rewards/combined_reward_trl/std': 0.20737969875335693, 'reward': 0.7629167437553406, 'reward_std': 0.199095219373703, 'epoch': 1.95}
2025-05-10 20:06:24,578 - openai._base_client - INFO - Retrying request to /chat/completions in 0.412972 seconds
2025-05-10 20:06:25,823 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6791666666666667, 'avg_raw_dharma_score': 0.9, 'avg_raw_helpfulness_score': 0.8250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8112499999999999}
2025-05-10 20:06:31,024 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6374999999999998, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.6416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7170833333333334}
  warnings.warn(
2025-05-10 20:07:36,849 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6875, 'avg_raw_dharma_score': 0.8624999999999999, 'avg_raw_helpfulness_score': 0.7916666666666669, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7887500000000002}
2025-05-10 20:07:37,046 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6416666666666667, 'avg_raw_dharma_score': 0.7083333333333334, 'avg_raw_helpfulness_score': 0.6500000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6708333333333334}
 25%|‚ñà‚ñà‚ñç       | 5921/24000 [2:23:53<44:56:03,  8.95s/it] 25%|‚ñà‚ñà‚ñç       | 5922/24000 [2:23:53<32:24:17,  6.45s/it] 25%|‚ñà‚ñà‚ñç       | 5923/24000 [2:23:54<23:38:06,  4.71s/it] 25%|‚ñà‚ñà‚ñç       | 5924/24000 [2:23:54<17:29:45,  3.48s/it] 25%|‚ñà‚ñà‚ñç       | 5925/24000 [2:23:55<13:11:57,  2.63s/it]                                                         {'loss': -0.0055, 'grad_norm': 11.3125, 'learning_rate': 2.5918250899313718e-06, 'kl': 0.6868009769916534, 'clip_ratio/low_mean': 0.0713088607962709, 'clip_ratio/low_min': 0.030494570434093475, 'clip_ratio/high_mean': 0.07356003037343423, 'clip_ratio/high_max': 0.12020739970107873, 'clip_ratio/region_mean': 0.14486889218911528, 'num_tokens': 1365893.0, 'completions/mean_length': 328.41668701171875, 'completions/min_length': 27.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.20833333333333337, 'completions/mean_terminated_length': 280.1052551269531, 'completions/min_terminated_length': 27.0, 'completions/max_terminated_length': 499.0, 'rewards/combined_reward_trl/mean': 0.7297916412353516, 'rewards/combined_reward_trl/std': 0.24569988250732422, 'reward': 0.7297916412353516, 'reward_std': 0.2244856059551239, 'epoch': 1.98}
 25%|‚ñà‚ñà‚ñç       | 5925/24000 [2:23:55<13:11:57,  2.63s/it]wandb: WARNING Tried to log to step 5925 that is less than the current step 54008. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-10 20:08:25,210 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6879166666666666, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.7333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7763749999999999}
2025-05-10 20:08:28,707 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7179166666666666, 'avg_raw_dharma_score': 0.7791666666666668, 'avg_raw_helpfulness_score': 0.775, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7595416666666668}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 20:09:17,957 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8095833333333333, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.9, 'avg_penalty': 0.0, 'avg_combined_reward': 0.912875}
2025-05-10 20:09:34,520 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.63125, 'avg_raw_dharma_score': 0.8583333333333334, 'avg_raw_helpfulness_score': 0.7083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7452083333333333}
2025-05-10 20:10:22,427 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6083333333333334, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.625, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6366666666666667}
2025-05-10 20:10:26,367 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.65875, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.775, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7801250000000001}
2025-05-10 20:11:17,729 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7312500000000001, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.7833333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7210416666666667}
2025-05-10 20:11:18,228 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8016666666666666, 'avg_raw_dharma_score': 0.9833333333333334, 'avg_raw_helpfulness_score': 0.8583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8913333333333334}
  warnings.warn(
2025-05-10 20:12:20,715 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7308333333333333, 'avg_raw_dharma_score': 0.9625, 'avg_raw_helpfulness_score': 0.8500000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.85925}
2025-05-10 20:12:26,295 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7000000000000001, 'avg_raw_dharma_score': 0.8875000000000002, 'avg_raw_helpfulness_score': 0.75, 'avg_penalty': 0.0, 'avg_combined_reward': 0.79}
 26%|‚ñà‚ñà‚ñå       | 6121/24000 [2:28:42<44:45:29,  9.01s/it] 26%|‚ñà‚ñà‚ñå       | 6122/24000 [2:28:42<32:16:22,  6.50s/it] 26%|‚ñà‚ñà‚ñå       | 6123/24000 [2:28:43<23:32:06,  4.74s/it] 26%|‚ñà‚ñà‚ñå       | 6124/24000 [2:28:44<17:25:04,  3.51s/it] 26%|‚ñà‚ñà‚ñå       | 6125/24000 [2:28:44<13:08:10,  2.65s/it]                                                         {'loss': 0.0863, 'grad_norm': 10.0625, 'learning_rate': 2.564294095307711e-06, 'kl': 0.631111528078715, 'clip_ratio/low_mean': 0.0442512816885331, 'clip_ratio/low_min': 0.033237328231334684, 'clip_ratio/high_mean': 0.0404357451836889, 'clip_ratio/high_max': 0.05582056264703472, 'clip_ratio/region_mean': 0.08468702661960076, 'num_tokens': 1412775.0, 'completions/mean_length': 339.8333435058594, 'completions/min_length': 215.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 315.23809814453125, 'completions/min_terminated_length': 215.0, 'completions/max_terminated_length': 426.0, 'rewards/combined_reward_trl/mean': 0.8246250152587891, 'rewards/combined_reward_trl/std': 0.11819910258054733, 'reward': 0.8246250152587891, 'reward_std': 0.09352970123291016, 'epoch': 2.04}
 26%|‚ñà‚ñà‚ñå       | 6125/24000 [2:28:44<13:08:10,  2.65s/it] 26%|‚ñà‚ñà‚ñå       | 6126/24000 [2:28:45<10:49:07,  2.18s/it]wandb: WARNING Tried to log to step 6125 that is less than the current step 55831. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-10 20:13:18,886 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7062499999999999, 'avg_raw_dharma_score': 0.7708333333333334, 'avg_raw_helpfulness_score': 0.8333333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7702083333333332}
2025-05-10 20:13:19,425 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5779166666666666, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.6833333333333332, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6950416666666666}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 20:14:11,985 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5562499999999999, 'avg_raw_dharma_score': 0.6458333333333334, 'avg_raw_helpfulness_score': 0.6166666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6102083333333334}
2025-05-10 20:14:24,742 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6416666666666667, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.7999999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7991666666666668}
2025-05-10 20:15:17,938 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.44875000000000015, 'avg_raw_dharma_score': 0.5583333333333333, 'avg_raw_helpfulness_score': 0.5166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5129583333333333}
2025-05-10 20:15:18,057 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6625, 'avg_raw_dharma_score': 0.8416666666666668, 'avg_raw_helpfulness_score': 0.7250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7529166666666666}
2025-05-10 20:16:10,400 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7075, 'avg_raw_dharma_score': 0.8916666666666666, 'avg_raw_helpfulness_score': 0.7833333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8039166666666667}
2025-05-10 20:16:11,965 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.43333333333333335, 'avg_raw_dharma_score': 0.6, 'avg_raw_helpfulness_score': 0.5333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5300000000000001}
  warnings.warn(
2025-05-10 20:17:16,690 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7333333333333334, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.9, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8900000000000001}
2025-05-10 20:17:17,500 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7431944444444444, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.8000000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8296250000000002}
 26%|‚ñà‚ñà‚ñã       | 6321/24000 [2:33:33<40:35:23,  8.27s/it] 26%|‚ñà‚ñà‚ñã       | 6322/24000 [2:33:34<29:19:08,  5.97s/it] 26%|‚ñà‚ñà‚ñã       | 6323/24000 [2:33:34<21:25:49,  4.36s/it] 26%|‚ñà‚ñà‚ñã       | 6324/24000 [2:33:35<15:54:47,  3.24s/it] 26%|‚ñà‚ñà‚ñã       | 6325/24000 [2:33:36<12:02:48,  2.45s/it]                                                         {'loss': -0.028, 'grad_norm': 5.0625, 'learning_rate': 2.5360213768211586e-06, 'kl': 1.085686388015747, 'clip_ratio/low_mean': 0.06578277462317297, 'clip_ratio/low_min': 0.047874018605798485, 'clip_ratio/high_mean': 0.050297089802722135, 'clip_ratio/high_max': 0.06650225039571524, 'clip_ratio/region_mean': 0.11607986233507593, 'num_tokens': 1458990.0, 'completions/mean_length': 379.125, 'completions/min_length': 267.0, 'completions/max_length': 486.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 379.125, 'completions/min_terminated_length': 267.0, 'completions/max_terminated_length': 486.0, 'rewards/combined_reward_trl/mean': 0.8598124980926514, 'rewards/combined_reward_trl/std': 0.1846034973859787, 'reward': 0.8598124980926514, 'reward_std': 0.10766791552305222, 'epoch': 2.11}
 26%|‚ñà‚ñà‚ñã       | 6325/24000 [2:33:36<12:02:48,  2.45s/it]wandb: WARNING Tried to log to step 6325 that is less than the current step 57654. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-10 20:18:09,612 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6347222222222221, 'avg_raw_dharma_score': 0.775, 'avg_raw_helpfulness_score': 0.6750000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7029166666666665}
2025-05-10 20:18:10,507 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.725, 'avg_raw_dharma_score': 0.8375, 'avg_raw_helpfulness_score': 0.8166666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7974999999999999}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 20:18:59,908 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7208333333333332, 'avg_raw_dharma_score': 0.7083333333333334, 'avg_raw_helpfulness_score': 0.7416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7220833333333333}
2025-05-10 20:19:15,214 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7179166666666666, 'avg_raw_dharma_score': 0.9249999999999999, 'avg_raw_helpfulness_score': 0.6750000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.787875}
2025-05-10 20:20:06,220 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6729166666666666, 'avg_raw_dharma_score': 0.7208333333333333, 'avg_raw_helpfulness_score': 0.7833333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7252083333333332}
2025-05-10 20:20:09,503 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6541666666666667, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.7416666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7520833333333335}
2025-05-10 20:21:01,624 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6124999999999999, 'avg_raw_dharma_score': 0.5416666666666666, 'avg_raw_helpfulness_score': 0.6083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5829166666666667}
2025-05-10 20:21:01,628 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6541666666666667, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.7583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7737500000000002}
  warnings.warn(
2025-05-10 20:22:05,550 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.59375, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.75, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7031250000000001}
2025-05-10 20:22:06,055 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5541666666666666, 'avg_raw_dharma_score': 0.6833333333333332, 'avg_raw_helpfulness_score': 0.5666666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6095833333333333}
 27%|‚ñà‚ñà‚ñã       | 6521/24000 [2:38:22<41:02:03,  8.45s/it] 27%|‚ñà‚ñà‚ñã       | 6522/24000 [2:38:22<29:38:30,  6.11s/it] 27%|‚ñà‚ñà‚ñã       | 6523/24000 [2:38:23<21:40:08,  4.46s/it] 27%|‚ñà‚ñà‚ñã       | 6524/24000 [2:38:23<16:05:13,  3.31s/it] 27%|‚ñà‚ñà‚ñã       | 6525/24000 [2:38:24<12:10:46,  2.51s/it]                                                         {'loss': 0.092, 'grad_norm': 8.25, 'learning_rate': 2.507026638189006e-06, 'kl': 0.8802026932438215, 'clip_ratio/low_mean': 0.07720043809269556, 'clip_ratio/low_min': 0.054742745036104073, 'clip_ratio/high_mean': 0.07901307392554978, 'clip_ratio/high_max': 0.11208988731727004, 'clip_ratio/region_mean': 0.15621351151261478, 'num_tokens': 1502295.0, 'completions/mean_length': 332.79168701171875, 'completions/min_length': 62.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 307.19049072265625, 'completions/min_terminated_length': 62.0, 'completions/max_terminated_length': 480.0, 'rewards/combined_reward_trl/mean': 0.6563541889190674, 'rewards/combined_reward_trl/std': 0.3191794753074646, 'reward': 0.6563541889190674, 'reward_std': 0.2583288848400116, 'epoch': 2.17}
 27%|‚ñà‚ñà‚ñã       | 6525/24000 [2:38:24<12:10:46,  2.51s/it] 27%|‚ñà‚ñà‚ñã       | 6526/24000 [2:38:25<9:27:09,  1.95s/it]  27%|‚ñà‚ñà‚ñã       | 6527/24000 [2:38:25<7:32:16,  1.55s/it]wandb: WARNING Tried to log to step 6525 that is less than the current step 59477. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-10 20:22:53,024 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5895833333333333, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.7333333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7802083333333334}
2025-05-10 20:23:02,458 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6916666666666668, 'avg_raw_dharma_score': 0.8166666666666668, 'avg_raw_helpfulness_score': 0.7166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7491666666666665}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 20:23:55,916 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7470833333333333, 'avg_raw_dharma_score': 0.8416666666666668, 'avg_raw_helpfulness_score': 0.8166666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8057916666666668}
2025-05-10 20:24:07,460 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6841666666666667, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.7666666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.78525}
2025-05-10 20:24:59,170 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5770833333333334, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.7000000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6997916666666667}
2025-05-10 20:25:00,669 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7000000000000001, 'avg_raw_dharma_score': 0.7083333333333334, 'avg_raw_helpfulness_score': 0.7583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7208333333333333}
2025-05-10 20:25:49,348 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7766666666666667, 'avg_raw_dharma_score': 0.8625000000000002, 'avg_raw_helpfulness_score': 0.7999999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8180000000000002}
2025-05-10 20:25:52,931 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6395833333333333, 'avg_raw_dharma_score': 0.8208333333333333, 'avg_raw_helpfulness_score': 0.7166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7352083333333334}
  warnings.warn(
2025-05-10 20:26:55,981 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7124999999999999, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.7583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8079166666666668}
2025-05-10 20:26:57,843 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6699999999999999, 'avg_raw_dharma_score': 0.6875, 'avg_raw_helpfulness_score': 0.8250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7235}
 28%|‚ñà‚ñà‚ñä       | 6721/24000 [2:43:13<41:24:16,  8.63s/it] 28%|‚ñà‚ñà‚ñä       | 6722/24000 [2:43:14<29:53:54,  6.23s/it] 28%|‚ñà‚ñà‚ñä       | 6723/24000 [2:43:15<21:50:11,  4.55s/it] 28%|‚ñà‚ñà‚ñä       | 6724/24000 [2:43:15<16:11:34,  3.37s/it] 28%|‚ñà‚ñà‚ñä       | 6725/24000 [2:43:16<12:14:39,  2.55s/it]                                                         {'loss': -0.0338, 'grad_norm': 8.1875, 'learning_rate': 2.477330086316128e-06, 'kl': 0.5278621983528137, 'clip_ratio/low_mean': 0.043372779573934775, 'clip_ratio/low_min': 0.018296496624437473, 'clip_ratio/high_mean': 0.10082178798116123, 'clip_ratio/high_max': 0.15617269832175226, 'clip_ratio/region_mean': 0.1441945679454754, 'num_tokens': 1544769.0, 'completions/mean_length': 299.3333435058594, 'completions/min_length': 113.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.04166666666666663, 'completions/mean_terminated_length': 290.08697509765625, 'completions/min_terminated_length': 113.0, 'completions/max_terminated_length': 465.0, 'rewards/combined_reward_trl/mean': 0.7657082676887512, 'rewards/combined_reward_trl/std': 0.18732956051826477, 'reward': 0.7657083868980408, 'reward_std': 0.1474994719028473, 'epoch': 2.24}
 28%|‚ñà‚ñà‚ñä       | 6725/24000 [2:43:16<12:14:39,  2.55s/it]wandb: WARNING Tried to log to step 6725 that is less than the current step 61300. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-10 20:27:47,697 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7083333333333334, 'avg_raw_dharma_score': 0.9, 'avg_raw_helpfulness_score': 0.7416666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7949999999999999}
2025-05-10 20:27:52,261 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.725, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.7333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7541666666666668}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 20:28:44,289 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7291666666666666, 'avg_raw_dharma_score': 0.85, 'avg_raw_helpfulness_score': 0.7833333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7937500000000001}
2025-05-10 20:28:57,623 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5983333333333333, 'avg_raw_dharma_score': 0.5666666666666667, 'avg_raw_helpfulness_score': 0.6750000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6086666666666668}
2025-05-10 20:29:46,624 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7354166666666667, 'avg_raw_dharma_score': 0.8958333333333334, 'avg_raw_helpfulness_score': 0.7999999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8189583333333333}
2025-05-10 20:29:46,850 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7520833333333333, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.8916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.893125}
2025-05-10 20:30:36,621 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7058333333333334, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.8083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8209166666666666}
2025-05-10 20:30:37,784 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5654166666666667, 'avg_raw_dharma_score': 0.7291666666666666, 'avg_raw_helpfulness_score': 0.6, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6412916666666667}
  warnings.warn(
2025-05-10 20:31:43,731 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8370833333333333, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.8583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8419583333333334}
2025-05-10 20:31:45,757 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5929166666666666, 'avg_raw_dharma_score': 0.7083333333333334, 'avg_raw_helpfulness_score': 0.6666666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6612083333333334}
 29%|‚ñà‚ñà‚ñâ       | 6921/24000 [2:48:01<42:33:15,  8.97s/it] 29%|‚ñà‚ñà‚ñâ       | 6922/24000 [2:48:02<30:41:05,  6.47s/it] 29%|‚ñà‚ñà‚ñâ       | 6923/24000 [2:48:03<22:22:35,  4.72s/it] 29%|‚ñà‚ñà‚ñâ       | 6924/24000 [2:48:03<16:33:38,  3.49s/it] 29%|‚ñà‚ñà‚ñâ       | 6925/24000 [2:48:04<12:29:22,  2.63s/it]                                                         {'loss': 0.1893, 'grad_norm': 9.4375, 'learning_rate': 2.4469524172124593e-06, 'kl': 1.721704694032669, 'clip_ratio/low_mean': 0.04562346035148948, 'clip_ratio/low_min': 0.023063770298225185, 'clip_ratio/high_mean': 0.044859843876523274, 'clip_ratio/high_max': 0.060231951414607465, 'clip_ratio/region_mean': 0.09048330455630396, 'num_tokens': 1587792.0, 'completions/mean_length': 326.5833435058594, 'completions/min_length': 1.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.08333333333333337, 'completions/mean_terminated_length': 309.727294921875, 'completions/min_terminated_length': 1.0, 'completions/max_terminated_length': 509.0, 'rewards/combined_reward_trl/mean': 0.7515833377838135, 'rewards/combined_reward_trl/std': 0.26970723271369934, 'reward': 0.7515833377838135, 'reward_std': 0.1381385326385498, 'epoch': 2.31}
2025-05-10 20:32:35,662 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7999999999999999, 'avg_raw_dharma_score': 0.8541666666666666, 'avg_raw_helpfulness_score': 0.8500000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8366666666666668}
2025-05-10 20:32:38,492 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.30388888888888893, 'avg_raw_dharma_score': 0.39999999999999997, 'avg_raw_helpfulness_score': 0.30000000000000004, 'avg_penalty': 0.0, 'avg_combined_reward': 0.3411666666666667}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 20:33:32,043 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6745833333333334, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.7166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.767375}
2025-05-10 20:33:46,918 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6916666666666668, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.7333333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7608333333333333}
2025-05-10 20:34:37,284 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8666666666666667, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.9, 'avg_penalty': 0.0, 'avg_combined_reward': 0.93}
2025-05-10 20:34:38,352 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7374999999999999, 'avg_raw_dharma_score': 0.9458333333333334, 'avg_raw_helpfulness_score': 0.8250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8470833333333333}
2025-05-10 20:35:30,057 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.64, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.6416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6511666666666666}
2025-05-10 20:35:30,701 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.9, 'avg_raw_dharma_score': 0.9833333333333334, 'avg_raw_helpfulness_score': 0.9250000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.9408333333333333}
  warnings.warn(
2025-05-10 20:36:33,303 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6708333333333333, 'avg_raw_dharma_score': 0.7708333333333334, 'avg_raw_helpfulness_score': 0.8000000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7495833333333333}
2025-05-10 20:36:34,867 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.56875, 'avg_raw_dharma_score': 0.7041666666666666, 'avg_raw_helpfulness_score': 0.65, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6472916666666667}
 30%|‚ñà‚ñà‚ñâ       | 7121/24000 [2:52:50<39:04:39,  8.33s/it] 30%|‚ñà‚ñà‚ñâ       | 7122/24000 [2:52:51<28:14:25,  6.02s/it] 30%|‚ñà‚ñà‚ñâ       | 7123/24000 [2:52:52<20:39:18,  4.41s/it] 30%|‚ñà‚ñà‚ñâ       | 7124/24000 [2:52:52<15:20:46,  3.27s/it] 30%|‚ñà‚ñà‚ñâ       | 7125/24000 [2:52:53<11:37:44,  2.48s/it]                                                         {'loss': 0.0473, 'grad_norm': 10.625, 'learning_rate': 2.4159148015696083e-06, 'kl': 1.0057498818635942, 'clip_ratio/low_mean': 0.04963680398107196, 'clip_ratio/low_min': 0.015627978468934694, 'clip_ratio/high_mean': 0.03425050448160619, 'clip_ratio/high_max': 0.040482687714199224, 'clip_ratio/region_mean': 0.08388730845569323, 'num_tokens': 1632675.0, 'completions/mean_length': 323.5833435058594, 'completions/min_length': 50.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.04166666666666663, 'completions/mean_terminated_length': 315.39129638671875, 'completions/min_terminated_length': 50.0, 'completions/max_terminated_length': 459.0, 'rewards/combined_reward_trl/mean': 0.698437511920929, 'rewards/combined_reward_trl/std': 0.32029014825820923, 'reward': 0.6984375715255737, 'reward_std': 0.2005469799041748, 'epoch': 2.38}
2025-05-10 20:37:25,659 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5041666666666667, 'avg_raw_dharma_score': 0.6041666666666666, 'avg_raw_helpfulness_score': 0.7333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6129166666666668}
2025-05-10 20:37:28,161 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5370833333333334, 'avg_raw_dharma_score': 0.3541666666666667, 'avg_raw_helpfulness_score': 0.7083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5152916666666667}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 20:38:20,253 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5581944444444445, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.7250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7016249999999999}
2025-05-10 20:38:33,218 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.38958333333333334, 'avg_raw_dharma_score': 0.5416666666666666, 'avg_raw_helpfulness_score': 0.5000000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.4835416666666667}
2025-05-10 20:39:22,567 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7416666666666667, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.8333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8725}
2025-05-10 20:39:25,648 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5625, 'avg_raw_dharma_score': 0.5750000000000001, 'avg_raw_helpfulness_score': 0.5750000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5712499999999999}
2025-05-10 20:40:15,209 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7499999999999999, 'avg_raw_dharma_score': 0.9833333333333334, 'avg_raw_helpfulness_score': 0.8583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8758333333333335}
2025-05-10 20:40:18,857 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7279166666666668, 'avg_raw_dharma_score': 0.7791666666666667, 'avg_raw_helpfulness_score': 0.775, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7625416666666666}
  warnings.warn(
2025-05-10 20:41:22,550 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5320833333333334, 'avg_raw_dharma_score': 0.5208333333333334, 'avg_raw_helpfulness_score': 0.5583333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5354583333333333}
2025-05-10 20:41:24,510 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8333333333333334, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.8500000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8716666666666667}
 31%|‚ñà‚ñà‚ñà       | 7321/24000 [2:57:40<40:53:29,  8.83s/it] 31%|‚ñà‚ñà‚ñà       | 7322/24000 [2:57:41<29:30:27,  6.37s/it] 31%|‚ñà‚ñà‚ñà       | 7323/24000 [2:57:41<21:32:23,  4.65s/it] 31%|‚ñà‚ñà‚ñà       | 7324/24000 [2:57:42<15:57:42,  3.45s/it] 31%|‚ñà‚ñà‚ñà       | 7325/24000 [2:57:43<12:03:26,  2.60s/it]                                                         {'loss': -0.0604, 'grad_norm': 11.3125, 'learning_rate': 2.38423887000666e-06, 'kl': 0.48580519676208495, 'clip_ratio/low_mean': 0.03950226893182844, 'clip_ratio/low_min': 0.02516192470987638, 'clip_ratio/high_mean': 0.04380583751946688, 'clip_ratio/high_max': 0.0499669676553458, 'clip_ratio/region_mean': 0.08330810630694031, 'num_tokens': 1676931.0, 'completions/mean_length': 353.125, 'completions/min_length': 139.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 330.4285888671875, 'completions/min_terminated_length': 139.0, 'completions/max_terminated_length': 472.0, 'rewards/combined_reward_trl/mean': 0.7035624980926514, 'rewards/combined_reward_trl/std': 0.3042057156562805, 'reward': 0.7035624980926514, 'reward_std': 0.21668778359889984, 'epoch': 2.44}
2025-05-10 20:42:15,163 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6208333333333332, 'avg_raw_dharma_score': 0.8541666666666666, 'avg_raw_helpfulness_score': 0.7500000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7529166666666667}
2025-05-10 20:42:16,204 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6083333333333334, 'avg_raw_dharma_score': 0.775, 'avg_raw_helpfulness_score': 0.6833333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6974999999999999}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 20:43:09,072 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5499999999999999, 'avg_raw_dharma_score': 0.6749999999999999, 'avg_raw_helpfulness_score': 0.6416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6275}
2025-05-10 20:43:23,498 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.75, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.875, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8708333333333335}
2025-05-10 20:44:13,501 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6958333333333333, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.7500000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7670833333333333}
2025-05-10 20:44:14,389 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5569444444444446, 'avg_raw_dharma_score': 0.775, 'avg_raw_helpfulness_score': 0.6166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6620833333333334}
2025-05-10 20:45:01,607 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7702777777777777, 'avg_raw_dharma_score': 0.8833333333333334, 'avg_raw_helpfulness_score': 0.8333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8344166666666668}
2025-05-10 20:45:06,491 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6970833333333334, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.7833333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8107916666666667}
  warnings.warn(
2025-05-10 20:46:14,375 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6720833333333335, 'avg_raw_dharma_score': 0.8416666666666667, 'avg_raw_helpfulness_score': 0.7166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7532916666666666}
2025-05-10 20:46:14,452 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7220833333333334, 'avg_raw_dharma_score': 0.9416666666666668, 'avg_raw_helpfulness_score': 0.8333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8432916666666667}
 31%|‚ñà‚ñà‚ñà‚ñè      | 7521/24000 [3:02:30<40:57:46,  8.95s/it] 31%|‚ñà‚ñà‚ñà‚ñè      | 7522/24000 [3:02:31<29:32:24,  6.45s/it] 31%|‚ñà‚ñà‚ñà‚ñè      | 7523/24000 [3:02:31<21:32:44,  4.71s/it] 31%|‚ñà‚ñà‚ñà‚ñè      | 7524/24000 [3:02:32<15:57:08,  3.49s/it] 31%|‚ñà‚ñà‚ñà‚ñè      | 7525/24000 [3:02:32<12:01:59,  2.63s/it]                                                         {'loss': 0.0163, 'grad_norm': 9.5625, 'learning_rate': 2.3519466979954447e-06, 'kl': 0.4772968093554179, 'clip_ratio/low_mean': 0.04627565930248238, 'clip_ratio/low_min': 0.022437123842537404, 'clip_ratio/high_mean': 0.03671998749176661, 'clip_ratio/high_max': 0.04412110078458985, 'clip_ratio/region_mean': 0.08299564750865102, 'num_tokens': 1721189.0, 'completions/mean_length': 305.8333435058594, 'completions/min_length': 126.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.08333333333333337, 'completions/mean_terminated_length': 287.0909118652344, 'completions/min_terminated_length': 126.0, 'completions/max_terminated_length': 475.0, 'rewards/combined_reward_trl/mean': 0.7982916831970215, 'rewards/combined_reward_trl/std': 0.21266737580299377, 'reward': 0.7982916831970215, 'reward_std': 0.14565323293209076, 'epoch': 2.51}
2025-05-10 20:47:02,880 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6208333333333332, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.7416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7920833333333334}
2025-05-10 20:47:06,983 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.71875, 'avg_raw_dharma_score': 0.9458333333333334, 'avg_raw_helpfulness_score': 0.8416666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8464583333333335}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 20:47:58,878 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6229166666666667, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.65, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6818750000000001}
2025-05-10 20:48:11,741 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7333333333333333, 'avg_raw_dharma_score': 0.8916666666666666, 'avg_raw_helpfulness_score': 0.775, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8091666666666667}
2025-05-10 20:49:01,794 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7666666666666666, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.7666666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7933333333333334}
2025-05-10 20:49:02,278 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7041666666666666, 'avg_raw_dharma_score': 0.9416666666666668, 'avg_raw_helpfulness_score': 0.7999999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8279166666666665}
                                                        {'loss': 0.0358, 'grad_norm': 3.265625, 'learning_rate': 2.327336683614276e-06, 'kl': 0.6275211016337077, 'clip_ratio/low_mean': 0.07864142826447884, 'clip_ratio/low_min': 0.0059878764549891154, 'clip_ratio/high_mean': 0.03214012253408631, 'clip_ratio/high_max': 0.043304703707496325, 'clip_ratio/region_mean': 0.11078155111521483, 'epoch': 2.56}
2025-05-10 20:49:49,927 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6583333333333333, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.7916666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7850000000000001}
2025-05-10 20:49:54,355 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6887500000000001, 'avg_raw_dharma_score': 0.6625, 'avg_raw_helpfulness_score': 0.7333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.691625}
  warnings.warn(
2025-05-10 20:50:56,638 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7929166666666667, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.8916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.9053750000000002}
2025-05-10 20:50:59,364 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5666666666666667, 'avg_raw_dharma_score': 0.7166666666666667, 'avg_raw_helpfulness_score': 0.5416666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6191666666666666}
 32%|‚ñà‚ñà‚ñà‚ñè      | 7721/24000 [3:07:15<36:35:31,  8.09s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 7722/24000 [3:07:15<26:28:14,  5.85s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 7723/24000 [3:07:16<19:23:10,  4.29s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 7724/24000 [3:07:17<14:25:41,  3.19s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 7725/24000 [3:07:17<10:57:21,  2.42s/it]                                                         {'loss': 0.0793, 'grad_norm': 15.5625, 'learning_rate': 2.319060790475781e-06, 'kl': 1.2867572156588236, 'clip_ratio/low_mean': 0.03457251254934818, 'clip_ratio/low_min': 0.02208485791304459, 'clip_ratio/high_mean': 0.02840510256549654, 'clip_ratio/high_max': 0.032433586698801566, 'clip_ratio/region_mean': 0.06297761431739976, 'num_tokens': 1766269.0, 'completions/mean_length': 352.8333435058594, 'completions/min_length': 242.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 330.0952453613281, 'completions/min_terminated_length': 242.0, 'completions/max_terminated_length': 451.0, 'rewards/combined_reward_trl/mean': 0.7622708678245544, 'rewards/combined_reward_trl/std': 0.24580492079257965, 'reward': 0.7622708678245544, 'reward_std': 0.15310049057006836, 'epoch': 2.58}
 32%|‚ñà‚ñà‚ñà‚ñè      | 7725/24000 [3:07:17<10:57:21,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 7726/24000 [3:07:18<8:31:56,  1.89s/it]  32%|‚ñà‚ñà‚ñà‚ñè      | 7727/24000 [3:07:19<6:49:44,  1.51s/it]wandb: WARNING Tried to log to step 7725 that is less than the current step 70415. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-10 20:51:47,029 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6499999999999999, 'avg_raw_dharma_score': 0.7999999999999999, 'avg_raw_helpfulness_score': 0.7083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7275}
2025-05-10 20:51:50,165 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5118055555555555, 'avg_raw_dharma_score': 0.39999999999999997, 'avg_raw_helpfulness_score': 0.6583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5110416666666666}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 20:52:41,550 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7616666666666667, 'avg_raw_dharma_score': 0.85, 'avg_raw_helpfulness_score': 0.7583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7959999999999998}
2025-05-10 20:52:56,226 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6952777777777778, 'avg_raw_dharma_score': 0.6958333333333333, 'avg_raw_helpfulness_score': 0.7166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7019166666666666}
2025-05-10 20:53:48,336 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6208333333333332, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.6166666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7045833333333332}
2025-05-10 20:53:51,963 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6208333333333332, 'avg_raw_dharma_score': 0.625, 'avg_raw_helpfulness_score': 0.6833333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.64125}
2025-05-10 20:54:39,352 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.9, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.9416666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.9525000000000001}
2025-05-10 20:54:45,417 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5854166666666667, 'avg_raw_dharma_score': 0.5583333333333332, 'avg_raw_helpfulness_score': 0.7416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6214583333333333}
  warnings.warn(
2025-05-10 20:55:49,627 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7291666666666666, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.8333333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8187500000000001}
2025-05-10 20:55:54,476 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6541666666666667, 'avg_raw_dharma_score': 0.5833333333333334, 'avg_raw_helpfulness_score': 0.8166666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6745833333333334}
 33%|‚ñà‚ñà‚ñà‚ñé      | 7921/24000 [3:12:10<41:31:46,  9.30s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 7922/24000 [3:12:11<29:54:38,  6.70s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 7923/24000 [3:12:11<21:46:44,  4.88s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 7924/24000 [3:12:12<16:05:11,  3.60s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 7925/24000 [3:12:12<12:06:04,  2.71s/it]                                                         {'loss': -0.0708, 'grad_norm': 14.0, 'learning_rate': 2.285604066171421e-06, 'kl': 0.33451888491710025, 'clip_ratio/low_mean': 0.03591187009044612, 'clip_ratio/low_min': 0.02362036185261483, 'clip_ratio/high_mean': 0.04710417327160637, 'clip_ratio/high_max': 0.0635019696628054, 'clip_ratio/region_mean': 0.08301604317501188, 'num_tokens': 1813032.0, 'completions/mean_length': 361.5833435058594, 'completions/min_length': 39.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.04166666666666663, 'completions/mean_terminated_length': 355.0434875488281, 'completions/min_terminated_length': 39.0, 'completions/max_terminated_length': 507.0, 'rewards/combined_reward_trl/mean': 0.7466667294502258, 'rewards/combined_reward_trl/std': 0.1542472392320633, 'reward': 0.7466667890548706, 'reward_std': 0.06898334622383118, 'epoch': 2.64}
2025-05-10 20:56:45,155 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7270833333333333, 'avg_raw_dharma_score': 0.775, 'avg_raw_helpfulness_score': 0.6333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.718125}
2025-05-10 20:56:45,911 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8291666666666666, 'avg_raw_dharma_score': 0.9, 'avg_raw_helpfulness_score': 0.8250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8562499999999998}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 20:57:40,562 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4354166666666666, 'avg_raw_dharma_score': 0.6041666666666666, 'avg_raw_helpfulness_score': 0.5166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5272916666666666}
2025-05-10 20:57:51,486 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7070833333333333, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.7333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7987916666666667}
2025-05-10 20:58:43,698 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5583333333333333, 'avg_raw_dharma_score': 0.3125, 'avg_raw_helpfulness_score': 0.65, 'avg_penalty': 0.0, 'avg_combined_reward': 0.4875}
2025-05-10 20:58:45,019 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.775, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.8333333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8824999999999998}
2025-05-10 20:59:33,363 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6816666666666666, 'avg_raw_dharma_score': 0.8791666666666668, 'avg_raw_helpfulness_score': 0.7000000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7661666666666668}
2025-05-10 20:59:35,574 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7000000000000001, 'avg_raw_dharma_score': 0.7999999999999998, 'avg_raw_helpfulness_score': 0.8250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7775}
  warnings.warn(
2025-05-10 21:00:42,188 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7416666666666666, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.7083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.785}
2025-05-10 21:00:42,542 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6333333333333332, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.8000000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7966666666666667}
 34%|‚ñà‚ñà‚ñà‚ñç      | 8121/24000 [3:16:58<38:41:51,  8.77s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 8122/24000 [3:16:59<27:55:22,  6.33s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 8123/24000 [3:16:59<20:22:52,  4.62s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 8124/24000 [3:17:00<15:06:11,  3.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 8125/24000 [3:17:01<11:24:30,  2.59s/it]                                                         {'loss': -0.0535, 'grad_norm': 18.125, 'learning_rate': 2.251599841617615e-06, 'kl': 0.6963948744535446, 'clip_ratio/low_mean': 0.07488617463774669, 'clip_ratio/low_min': 0.013226032536476851, 'clip_ratio/high_mean': 0.0405183399717013, 'clip_ratio/high_max': 0.05052669156963627, 'clip_ratio/region_mean': 0.11540451504290104, 'num_tokens': 1858763.0, 'completions/mean_length': 353.5, 'completions/min_length': 207.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.16666666666666663, 'completions/mean_terminated_length': 321.8000183105469, 'completions/min_terminated_length': 207.0, 'completions/max_terminated_length': 484.0, 'rewards/combined_reward_trl/mean': 0.7908332943916321, 'rewards/combined_reward_trl/std': 0.2251022309064865, 'reward': 0.7908333539962769, 'reward_std': 0.20462608337402344, 'epoch': 2.71}
2025-05-10 21:01:31,308 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.73875, 'avg_raw_dharma_score': 0.7708333333333334, 'avg_raw_helpfulness_score': 0.7833333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7649583333333333}
2025-05-10 21:01:36,044 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6541666666666667, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.7833333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.78125}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 21:02:31,211 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8166666666666668, 'avg_raw_dharma_score': 0.9833333333333334, 'avg_raw_helpfulness_score': 0.9, 'avg_penalty': 0.0, 'avg_combined_reward': 0.9083333333333333}
2025-05-10 21:02:43,161 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.48458333333333337, 'avg_raw_dharma_score': 0.6458333333333334, 'avg_raw_helpfulness_score': 0.6083333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5862083333333333}
2025-05-10 21:03:33,651 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6416666666666666, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.7166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7408333333333333}
2025-05-10 21:03:34,314 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6904166666666667, 'avg_raw_dharma_score': 0.8375, 'avg_raw_helpfulness_score': 0.7333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7621250000000002}
2025-05-10 21:04:25,049 - openai._base_client - INFO - Retrying request to /chat/completions in 0.482008 seconds
2025-05-10 21:04:27,348 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7333333333333333, 'avg_raw_dharma_score': 0.8583333333333334, 'avg_raw_helpfulness_score': 0.8166666666666669, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8083333333333332}
2025-05-10 21:04:28,552 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6583333333333333, 'avg_raw_dharma_score': 0.6, 'avg_raw_helpfulness_score': 0.8083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.68}
  warnings.warn(
2025-05-10 21:05:33,051 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7116666666666666, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.8333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8301666666666666}
2025-05-10 21:05:33,685 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6104166666666666, 'avg_raw_dharma_score': 0.5833333333333334, 'avg_raw_helpfulness_score': 0.7166666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6314583333333333}
 35%|‚ñà‚ñà‚ñà‚ñç      | 8321/24000 [3:21:49<37:36:49,  8.64s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 8322/24000 [3:21:50<27:09:10,  6.23s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 8323/24000 [3:21:50<19:49:49,  4.55s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 8324/24000 [3:21:51<14:42:21,  3.38s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 8325/24000 [3:21:52<11:07:09,  2.55s/it]                                                         {'loss': 0.0602, 'grad_norm': 6.0, 'learning_rate': 2.217071814911442e-06, 'kl': 0.9137196858723958, 'clip_ratio/low_mean': 0.06338639272454505, 'clip_ratio/low_min': 0.038146057054400447, 'clip_ratio/high_mean': 0.01755890389593939, 'clip_ratio/high_max': 0.021713105098654827, 'clip_ratio/region_mean': 0.08094529724059006, 'num_tokens': 1908642.0, 'completions/mean_length': 398.54168701171875, 'completions/min_length': 254.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 360.72222900390625, 'completions/min_terminated_length': 254.0, 'completions/max_terminated_length': 494.0, 'rewards/combined_reward_trl/mean': 0.7308124899864197, 'rewards/combined_reward_trl/std': 0.30304446816444397, 'reward': 0.7308125495910645, 'reward_std': 0.24204806983470917, 'epoch': 2.77}
2025-05-10 21:06:26,252 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5375, 'avg_raw_dharma_score': 0.5416666666666666, 'avg_raw_helpfulness_score': 0.6416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5704166666666666}
2025-05-10 21:06:27,459 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7077777777777778, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.7666666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7923333333333332}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 21:07:17,758 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6020833333333333, 'avg_raw_dharma_score': 0.775, 'avg_raw_helpfulness_score': 0.6916666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.698125}
2025-05-10 21:07:33,933 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.65, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.6166666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6966666666666668}
2025-05-10 21:08:26,956 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6025, 'avg_raw_dharma_score': 0.8583333333333334, 'avg_raw_helpfulness_score': 0.6083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7065833333333335}
2025-05-10 21:08:27,353 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5079166666666667, 'avg_raw_dharma_score': 0.65, 'avg_raw_helpfulness_score': 0.5416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5748749999999999}
2025-05-10 21:09:20,145 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6458333333333334, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.7166666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7420833333333334}
2025-05-10 21:09:20,343 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5625, 'avg_raw_dharma_score': 0.775, 'avg_raw_helpfulness_score': 0.7083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.69125}
  warnings.warn(
2025-05-10 21:10:33,552 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5875, 'avg_raw_dharma_score': 0.5625, 'avg_raw_helpfulness_score': 0.7000000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.61125}
2025-05-10 21:10:36,353 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6749999999999999, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.7000000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7625000000000001}
 36%|‚ñà‚ñà‚ñà‚ñå      | 8521/24000 [3:26:52<49:01:14, 11.40s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 8522/24000 [3:26:52<35:07:52,  8.17s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 8523/24000 [3:26:53<25:24:34,  5.91s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 8524/24000 [3:26:54<18:36:16,  4.33s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 8525/24000 [3:26:54<13:50:29,  3.22s/it]                                                         {'loss': 0.1704, 'grad_norm': 15.75, 'learning_rate': 2.182044049196218e-06, 'kl': 1.7001905691623689, 'clip_ratio/low_mean': 0.0800474318182872, 'clip_ratio/low_min': 0.030522944368422032, 'clip_ratio/high_mean': 0.024735823969046274, 'clip_ratio/high_max': 0.028434796366685382, 'clip_ratio/region_mean': 0.10478325698990375, 'num_tokens': 1955809.0, 'completions/mean_length': 341.66668701171875, 'completions/min_length': 29.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.16666666666666663, 'completions/mean_terminated_length': 307.6000061035156, 'completions/min_terminated_length': 29.0, 'completions/max_terminated_length': 466.0, 'rewards/combined_reward_trl/mean': 0.6868749260902405, 'rewards/combined_reward_trl/std': 0.2809487283229828, 'reward': 0.68687504529953, 'reward_std': 0.24213135242462158, 'epoch': 2.84}
2025-05-10 21:11:39,471 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6375000000000001, 'avg_raw_dharma_score': 0.775, 'avg_raw_helpfulness_score': 0.6250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6887500000000001}
2025-05-10 21:12:02,900 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8970833333333333, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.8166666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8974583333333336}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 21:13:06,809 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5184722222222223, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.5583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5897083333333334}
2025-05-10 21:13:14,933 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6025, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.6333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6374166666666667}
2025-05-10 21:14:08,064 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7075, 'avg_raw_dharma_score': 0.9625, 'avg_raw_helpfulness_score': 0.8166666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.84225}
2025-05-10 21:14:12,068 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7291666666666669, 'avg_raw_dharma_score': 0.9333333333333332, 'avg_raw_helpfulness_score': 0.7583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8195833333333332}
 36%|‚ñà‚ñà‚ñà‚ñå      | 8641/24000 [3:30:28<43:15:56, 10.14s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 8642/24000 [3:30:28<31:05:19,  7.29s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 8643/24000 [3:30:29<22:33:53,  5.29s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 8644/24000 [3:30:29<16:35:56,  3.89s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 8645/24000 [3:30:30<12:25:20,  2.91s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 8646/24000 [3:30:31<9:29:59,  2.23s/it]  36%|‚ñà‚ñà‚ñà‚ñå      | 8647/24000 [3:30:31<7:27:17,  1.75s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 8648/24000 [3:30:32<6:01:21,  1.41s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 8649/24000 [3:30:33<5:01:11,  1.18s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 8650/24000 [3:30:33<4:19:05,  1.01s/it]                                                        {'loss': 0.0664, 'grad_norm': 11.5625, 'learning_rate': 2.1599087547838727e-06, 'kl': 1.3212993421157202, 'clip_ratio/low_mean': 0.010575645704132814, 'clip_ratio/low_min': 0.002743435127194971, 'clip_ratio/high_mean': 0.054533006334677336, 'clip_ratio/high_max': 0.09009582614526153, 'clip_ratio/region_mean': 0.0651086519099772, 'num_tokens': 1983760.0, 'completions/mean_length': 333.0, 'completions/min_length': 72.0, 'completions/max_length': 501.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 333.0, 'completions/min_terminated_length': 72.0, 'completions/max_terminated_length': 501.0, 'rewards/combined_reward_trl/mean': 0.830916702747345, 'rewards/combined_reward_trl/std': 0.12668375670909882, 'reward': 0.8309167623519897, 'reward_std': 0.10607627034187317, 'epoch': 2.88}
2025-05-10 21:15:03,505 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8429166666666666, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.8916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.9203750000000003}
2025-05-10 21:15:05,064 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.43625, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.5083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5500416666666667}
  warnings.warn(
2025-05-10 21:16:11,092 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8125, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.8583333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.9012500000000001}
2025-05-10 21:16:14,893 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7708333333333331, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.8333333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8145833333333333}
 36%|‚ñà‚ñà‚ñà‚ñã      | 8721/24000 [3:32:30<42:44:11, 10.07s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 8722/24000 [3:32:31<30:43:38,  7.24s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 8723/24000 [3:32:32<22:19:18,  5.26s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 8724/24000 [3:32:32<16:26:17,  3.87s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 8725/24000 [3:32:33<12:19:10,  2.90s/it]                                                         {'loss': 0.0625, 'grad_norm': 8.5625, 'learning_rate': 2.146540955891503e-06, 'kl': 1.0772598306337993, 'clip_ratio/low_mean': 0.029197064815477156, 'clip_ratio/low_min': 0.0151198094834884, 'clip_ratio/high_mean': 0.03628303232292334, 'clip_ratio/high_max': 0.04333187789345781, 'clip_ratio/region_mean': 0.06548009640381981, 'num_tokens': 2001262.0, 'completions/mean_length': 309.875, 'completions/min_length': 133.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.04166666666666663, 'completions/mean_terminated_length': 301.08697509765625, 'completions/min_terminated_length': 133.0, 'completions/max_terminated_length': 452.0, 'rewards/combined_reward_trl/mean': 0.8579166531562805, 'rewards/combined_reward_trl/std': 0.13165268301963806, 'reward': 0.8579167127609253, 'reward_std': 0.0828467458486557, 'epoch': 2.91}
2025-05-10 21:17:08,383 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5708333333333334, 'avg_raw_dharma_score': 0.5, 'avg_raw_helpfulness_score': 0.5583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5387500000000001}
2025-05-10 21:17:09,223 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.39166666666666666, 'avg_raw_dharma_score': 0.5499999999999999, 'avg_raw_helpfulness_score': 0.46666666666666673, 'avg_penalty': 0.0, 'avg_combined_reward': 0.4775}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 21:18:01,143 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5904166666666666, 'avg_raw_dharma_score': 0.7083333333333334, 'avg_raw_helpfulness_score': 0.6000000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6404583333333332}
2025-05-10 21:18:16,434 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6045833333333336, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.7083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7105416666666667}
2025-05-10 21:19:08,400 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7819444444444444, 'avg_raw_dharma_score': 0.9833333333333334, 'avg_raw_helpfulness_score': 0.875, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8904166666666667}
2025-05-10 21:19:09,490 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.775, 'avg_raw_dharma_score': 0.85, 'avg_raw_helpfulness_score': 0.7916666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.81}
2025-05-10 21:20:02,629 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.64375, 'avg_raw_dharma_score': 0.8583333333333334, 'avg_raw_helpfulness_score': 0.7500000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7614583333333332}
2025-05-10 21:20:03,208 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6804166666666668, 'avg_raw_dharma_score': 0.7791666666666667, 'avg_raw_helpfulness_score': 0.6583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7132916666666667}
  warnings.warn(
2025-05-10 21:21:16,074 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5229166666666666, 'avg_raw_dharma_score': 0.775, 'avg_raw_helpfulness_score': 0.65, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6618750000000001}
2025-05-10 21:21:16,489 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6661111111111112, 'avg_raw_dharma_score': 0.7583333333333334, 'avg_raw_helpfulness_score': 0.625, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6906666666666667}
 37%|‚ñà‚ñà‚ñà‚ñã      | 8921/24000 [3:37:32<44:17:32, 10.57s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 8922/24000 [3:37:33<31:47:58,  7.59s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 8923/24000 [3:37:33<23:03:17,  5.50s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 8924/24000 [3:37:34<16:56:02,  4.04s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 8925/24000 [3:37:35<12:38:59,  3.02s/it]                                                         {'loss': 0.0295, 'grad_norm': 9.75, 'learning_rate': 2.110587277680383e-06, 'kl': 1.1637636788686117, 'clip_ratio/low_mean': 0.03441963991460701, 'clip_ratio/low_min': 0.0032372779119759798, 'clip_ratio/high_mean': 0.032604897202303015, 'clip_ratio/high_max': 0.04431614429689944, 'clip_ratio/region_mean': 0.06702453711380561, 'num_tokens': 2044982.0, 'completions/mean_length': 346.2083435058594, 'completions/min_length': 1.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 322.5238037109375, 'completions/min_terminated_length': 1.0, 'completions/max_terminated_length': 490.0, 'rewards/combined_reward_trl/mean': 0.6762707829475403, 'rewards/combined_reward_trl/std': 0.31903448700904846, 'reward': 0.6762708425521851, 'reward_std': 0.3387627601623535, 'epoch': 2.98}
2025-05-10 21:22:04,169 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7958333333333333, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.8416666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8912500000000002}
2025-05-10 21:22:06,668 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5791666666666667, 'avg_raw_dharma_score': 0.6333333333333333, 'avg_raw_helpfulness_score': 0.775, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6595833333333333}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 21:22:59,048 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6945833333333334, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.7583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7692083333333333}
2025-05-10 21:23:08,658 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7720833333333333, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.8083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8574583333333333}
2025-05-10 21:23:58,487 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5383333333333332, 'avg_raw_dharma_score': 0.46249999999999997, 'avg_raw_helpfulness_score': 0.625, 'avg_penalty': 0.0, 'avg_combined_reward': 0.534}
2025-05-10 21:23:59,691 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8616666666666668, 'avg_raw_dharma_score': 0.8958333333333334, 'avg_raw_helpfulness_score': 0.8333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8668333333333335}
2025-05-10 21:24:51,149 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4840277777777778, 'avg_raw_dharma_score': 0.6333333333333333, 'avg_raw_helpfulness_score': 0.6000000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5785416666666667}
2025-05-10 21:24:52,266 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6916666666666668, 'avg_raw_dharma_score': 0.525, 'avg_raw_helpfulness_score': 0.7333333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6375}
  warnings.warn(
2025-05-10 21:25:58,105 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.64, 'avg_raw_dharma_score': 0.625, 'avg_raw_helpfulness_score': 0.65, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6370000000000001}
2025-05-10 21:25:58,948 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7166666666666668, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.9, 'avg_penalty': 0.0, 'avg_combined_reward': 0.785}
 38%|‚ñà‚ñà‚ñà‚ñä      | 9121/24000 [3:42:14<37:33:00,  9.09s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 9122/24000 [3:42:15<27:04:01,  6.55s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 9123/24000 [3:42:16<19:43:53,  4.77s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 9124/24000 [3:42:16<14:35:52,  3.53s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 9125/24000 [3:42:17<11:00:14,  2.66s/it]                                                         {'loss': 0.1809, 'grad_norm': 8.0, 'learning_rate': 2.0742080712658923e-06, 'kl': 1.639063425064087, 'clip_ratio/low_mean': 0.030048599880343925, 'clip_ratio/low_min': 0.014774556246896584, 'clip_ratio/high_mean': 0.109432916296646, 'clip_ratio/high_max': 0.19582068459751706, 'clip_ratio/region_mean': 0.13948151670396328, 'num_tokens': 2088058.0, 'completions/mean_length': 351.16668701171875, 'completions/min_length': 127.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.16666666666666663, 'completions/mean_terminated_length': 319.0, 'completions/min_terminated_length': 127.0, 'completions/max_terminated_length': 488.0, 'rewards/combined_reward_trl/mean': 0.7109999656677246, 'rewards/combined_reward_trl/std': 0.21402472257614136, 'reward': 0.7109999656677246, 'reward_std': 0.16456957161426544, 'epoch': 3.04}
 38%|‚ñà‚ñà‚ñà‚ñä      | 9125/24000 [3:42:17<11:00:14,  2.66s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 9126/24000 [3:42:18<8:29:38,  2.06s/it]  38%|‚ñà‚ñà‚ñà‚ñä      | 9127/24000 [3:42:18<6:43:43,  1.63s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 9128/24000 [3:42:19<5:29:37,  1.33s/it]wandb: WARNING Tried to log to step 9125 that is less than the current step 83176. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-10 21:26:50,301 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5412499999999999, 'avg_raw_dharma_score': 0.7708333333333334, 'avg_raw_helpfulness_score': 0.6750000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6732083333333333}
2025-05-10 21:26:52,097 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7680555555555556, 'avg_raw_dharma_score': 0.8666666666666667, 'avg_raw_helpfulness_score': 0.8416666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8295833333333333}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 21:27:44,707 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7499999999999999, 'avg_raw_dharma_score': 0.8416666666666667, 'avg_raw_helpfulness_score': 0.8000000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8016666666666667}
2025-05-10 21:27:53,644 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7025000000000001, 'avg_raw_dharma_score': 0.8666666666666667, 'avg_raw_helpfulness_score': 0.7916666666666669, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7949166666666665}
2025-05-10 21:28:44,058 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6708333333333334, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.6916666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7420833333333333}
2025-05-10 21:28:45,708 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7166666666666667, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.7250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7658333333333335}
2025-05-10 21:29:39,062 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6895833333333333, 'avg_raw_dharma_score': 0.7958333333333334, 'avg_raw_helpfulness_score': 0.7416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7477083333333333}
2025-05-10 21:29:39,871 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6895833333333332, 'avg_raw_dharma_score': 0.7958333333333334, 'avg_raw_helpfulness_score': 0.7333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7452083333333334}
  warnings.warn(
2025-05-10 21:30:41,163 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7666666666666667, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.75, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8216666666666667}
2025-05-10 21:30:42,854 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6358333333333333, 'avg_raw_dharma_score': 0.8583333333333334, 'avg_raw_helpfulness_score': 0.6916666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7415833333333333}
 39%|‚ñà‚ñà‚ñà‚ñâ      | 9321/24000 [3:46:58<32:29:54,  7.97s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 9322/24000 [3:46:59<23:27:55,  5.76s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 9323/24000 [3:46:59<17:08:00,  4.20s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 9324/24000 [3:47:00<12:42:07,  3.12s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 9325/24000 [3:47:01<9:35:59,  2.36s/it]                                                         {'loss': 0.0843, 'grad_norm': 8.8125, 'learning_rate': 2.0374286899085914e-06, 'kl': 1.357838311990102, 'clip_ratio/low_mean': 0.05891186514869332, 'clip_ratio/low_min': 0.05085815727710724, 'clip_ratio/high_mean': 0.023212174425522487, 'clip_ratio/high_max': 0.03492638607198993, 'clip_ratio/region_mean': 0.08212404009575645, 'num_tokens': 2133262.0, 'completions/mean_length': 272.0, 'completions/min_length': 12.0, 'completions/max_length': 459.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 272.0, 'completions/min_terminated_length': 12.0, 'completions/max_terminated_length': 459.0, 'rewards/combined_reward_trl/mean': 0.781624972820282, 'rewards/combined_reward_trl/std': 0.2487400472164154, 'reward': 0.781624972820282, 'reward_std': 0.2519199252128601, 'epoch': 3.11}
2025-05-10 21:31:33,069 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7791666666666668, 'avg_raw_dharma_score': 0.9, 'avg_raw_helpfulness_score': 0.8500000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8487499999999999}
2025-05-10 21:31:34,185 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7733333333333334, 'avg_raw_dharma_score': 0.8666666666666668, 'avg_raw_helpfulness_score': 0.8083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8211666666666666}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 21:32:24,846 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7583333333333333, 'avg_raw_dharma_score': 0.8958333333333334, 'avg_raw_helpfulness_score': 0.8166666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8308333333333334}
2025-05-10 21:32:40,370 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7300000000000001, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.7666666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7823333333333334}
2025-05-10 21:33:31,335 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7416666666666668, 'avg_raw_dharma_score': 0.9, 'avg_raw_helpfulness_score': 0.8166666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8274999999999998}
2025-05-10 21:33:34,057 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5583333333333335, 'avg_raw_dharma_score': 0.7083333333333334, 'avg_raw_helpfulness_score': 0.6000000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6308333333333334}
2025-05-10 21:34:26,227 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.2920833333333334, 'avg_raw_dharma_score': 0.48333333333333334, 'avg_raw_helpfulness_score': 0.35833333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.38845833333333335}
2025-05-10 21:34:28,783 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7458333333333332, 'avg_raw_dharma_score': 0.9416666666666668, 'avg_raw_helpfulness_score': 0.8666666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8604166666666667}
  warnings.warn(
2025-05-10 21:35:34,990 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7012499999999999, 'avg_raw_dharma_score': 0.8875000000000001, 'avg_raw_helpfulness_score': 0.775, 'avg_penalty': 0.0, 'avg_combined_reward': 0.797875}
2025-05-10 21:35:36,109 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5145833333333333, 'avg_raw_dharma_score': 0.6458333333333334, 'avg_raw_helpfulness_score': 0.6333333333333332, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6027083333333333}
 40%|‚ñà‚ñà‚ñà‚ñâ      | 9521/24000 [3:51:52<35:19:34,  8.78s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 9522/24000 [3:51:52<25:29:49,  6.34s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 9523/24000 [3:51:53<18:36:59,  4.63s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 9524/24000 [3:51:54<13:48:02,  3.43s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 9525/24000 [3:51:54<10:25:47,  2.59s/it]                                                         {'loss': 0.1699, 'grad_norm': 14.0, 'learning_rate': 2.000274765757465e-06, 'kl': 1.771107209523519, 'clip_ratio/low_mean': 0.009741572294927513, 'clip_ratio/low_min': 0.0005617905609930554, 'clip_ratio/high_mean': 0.08551927901959668, 'clip_ratio/high_max': 0.15041314400111636, 'clip_ratio/region_mean': 0.09526085098584493, 'num_tokens': 2178375.0, 'completions/mean_length': 321.8333435058594, 'completions/min_length': 121.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.04166666666666663, 'completions/mean_terminated_length': 313.5652160644531, 'completions/min_terminated_length': 121.0, 'completions/max_terminated_length': 488.0, 'rewards/combined_reward_trl/mean': 0.700291633605957, 'rewards/combined_reward_trl/std': 0.25372588634490967, 'reward': 0.7002917528152466, 'reward_std': 0.20702147483825684, 'epoch': 3.17}
2025-05-10 21:36:24,121 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.75, 'avg_raw_dharma_score': 0.8166666666666668, 'avg_raw_helpfulness_score': 0.7916666666666669, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7891666666666666}
2025-05-10 21:36:25,480 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6875, 'avg_raw_dharma_score': 0.9, 'avg_raw_helpfulness_score': 0.6666666666666669, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7662499999999999}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 21:37:11,159 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6491666666666668, 'avg_raw_dharma_score': 0.8541666666666666, 'avg_raw_helpfulness_score': 0.7000000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7464166666666667}
2025-05-10 21:37:28,115 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7508333333333334, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.8333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8585833333333333}
2025-05-10 21:38:16,527 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7000000000000001, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.9, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8133333333333334}
2025-05-10 21:38:22,610 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6020833333333333, 'avg_raw_dharma_score': 0.625, 'avg_raw_helpfulness_score': 0.6333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6206250000000001}
2025-05-10 21:39:14,137 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7062500000000002, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.6833333333333332, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7502083333333335}
2025-05-10 21:39:16,102 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5750000000000001, 'avg_raw_dharma_score': 0.7583333333333333, 'avg_raw_helpfulness_score': 0.6583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6733333333333333}
  warnings.warn(
2025-05-10 21:40:20,098 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7804166666666666, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.8750000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8966250000000001}
2025-05-10 21:40:24,725 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.49999999999999994, 'avg_raw_dharma_score': 0.625, 'avg_raw_helpfulness_score': 0.525, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5575}
 41%|‚ñà‚ñà‚ñà‚ñà      | 9721/24000 [3:56:40<36:12:45,  9.13s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 9722/24000 [3:56:41<26:05:47,  6.58s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 9723/24000 [3:56:41<19:01:00,  4.80s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 9724/24000 [3:56:42<14:03:35,  3.55s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 9725/24000 [3:56:43<10:35:29,  2.67s/it]                                                         {'loss': 0.1057, 'grad_norm': 9.0, 'learning_rate': 1.962772191986463e-06, 'kl': 1.3756256341934203, 'clip_ratio/low_mean': 0.07654791925374108, 'clip_ratio/low_min': 0.032840330381101616, 'clip_ratio/high_mean': 0.016286517310266695, 'clip_ratio/high_max': 0.018711767536588014, 'clip_ratio/region_mean': 0.0928344381817927, 'num_tokens': 2219635.0, 'completions/mean_length': 325.79168701171875, 'completions/min_length': 62.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.04166666666666663, 'completions/mean_terminated_length': 317.6956481933594, 'completions/min_terminated_length': 62.0, 'completions/max_terminated_length': 499.0, 'rewards/combined_reward_trl/mean': 0.727062463760376, 'rewards/combined_reward_trl/std': 0.31765809655189514, 'reward': 0.7270625829696655, 'reward_std': 0.19717036187648773, 'epoch': 3.24}
2025-05-10 21:41:16,208 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7291666666666666, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.8500000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8570833333333333}
2025-05-10 21:41:16,401 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6991666666666667, 'avg_raw_dharma_score': 0.9, 'avg_raw_helpfulness_score': 0.775, 'avg_penalty': 0.0, 'avg_combined_reward': 0.80225}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 21:42:11,551 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5750000000000001, 'avg_raw_dharma_score': 0.8166666666666668, 'avg_raw_helpfulness_score': 0.6166666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6841666666666667}
2025-05-10 21:42:21,801 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4833333333333334, 'avg_raw_dharma_score': 0.7083333333333334, 'avg_raw_helpfulness_score': 0.525, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5858333333333333}
2025-05-10 21:43:09,026 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.75, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.8083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8341666666666666}
2025-05-10 21:43:12,403 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7333333333333334, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.7583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7808333333333333}
2025-05-10 21:44:01,825 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.63125, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.6916666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7302083333333335}
2025-05-10 21:44:02,737 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6749999999999999, 'avg_raw_dharma_score': 0.8583333333333334, 'avg_raw_helpfulness_score': 0.7416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7683333333333332}
  warnings.warn(
2025-05-10 21:45:08,097 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.85, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.9166666666666669, 'avg_penalty': 0.0, 'avg_combined_reward': 0.9300000000000003}
2025-05-10 21:45:08,932 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7458333333333335, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.6749999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7595833333333332}
 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 9921/24000 [4:01:24<33:01:15,  8.44s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 9922/24000 [4:01:25<23:50:53,  6.10s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 9923/24000 [4:01:26<17:25:37,  4.46s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 9924/24000 [4:01:26<12:55:56,  3.31s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 9925/24000 [4:01:27<9:47:11,  2.50s/it]                                                         {'loss': 0.0773, 'grad_norm': 10.375, 'learning_rate': 1.924947104749124e-06, 'kl': 1.066901639699936, 'clip_ratio/low_mean': 0.06595869973612328, 'clip_ratio/low_min': 0.007696581458051999, 'clip_ratio/high_mean': 0.019372679099130135, 'clip_ratio/high_max': 0.02457441172252099, 'clip_ratio/region_mean': 0.08533137901686132, 'num_tokens': 2260394.0, 'completions/mean_length': 294.79168701171875, 'completions/min_length': 147.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.04166666666666663, 'completions/mean_terminated_length': 285.34783935546875, 'completions/min_terminated_length': 147.0, 'completions/max_terminated_length': 466.0, 'rewards/combined_reward_trl/mean': 0.8447916507720947, 'rewards/combined_reward_trl/std': 0.25103041529655457, 'reward': 0.8447917699813843, 'reward_std': 0.09686112403869629, 'epoch': 3.31}
 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 9925/24000 [4:01:27<9:47:11,  2.50s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 9926/24000 [4:01:28<7:35:24,  1.94s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 9927/24000 [4:01:28<6:02:49,  1.55s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 9928/24000 [4:01:29<4:58:00,  1.27s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 9929/24000 [4:01:29<4:12:38,  1.08s/it]wandb: WARNING Tried to log to step 9925 that is less than the current step 90468. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-10 21:46:00,692 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7470833333333333, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.7833333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8257916666666668}
2025-05-10 21:46:02,046 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6541666666666667, 'avg_raw_dharma_score': 0.9416666666666668, 'avg_raw_helpfulness_score': 0.7166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7879166666666668}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 21:46:55,851 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6605555555555557, 'avg_raw_dharma_score': 0.8583333333333334, 'avg_raw_helpfulness_score': 0.7083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7540000000000001}
2025-05-10 21:47:07,122 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7741666666666666, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.8333333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.88225}
2025-05-10 21:47:57,904 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6958333333333333, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.7333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7454166666666667}
2025-05-10 21:47:59,494 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6423611111111112, 'avg_raw_dharma_score': 0.7666666666666666, 'avg_raw_helpfulness_score': 0.5916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.676875}
2025-05-10 21:48:44,280 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6095833333333333, 'avg_raw_dharma_score': 0.8833333333333334, 'avg_raw_helpfulness_score': 0.7083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7487083333333334}
2025-05-10 21:48:47,594 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7423611111111112, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.7916666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.776875}
  warnings.warn(
2025-05-10 21:49:50,455 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5904166666666667, 'avg_raw_dharma_score': 0.6291666666666667, 'avg_raw_helpfulness_score': 0.5666666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5987916666666667}
2025-05-10 21:49:51,681 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.52375, 'avg_raw_dharma_score': 0.6749999999999999, 'avg_raw_helpfulness_score': 0.43333333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5571250000000001}
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 10121/24000 [4:06:07<32:28:23,  8.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 10122/24000 [4:06:08<23:27:48,  6.09s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 10123/24000 [4:06:08<17:09:23,  4.45s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 10124/24000 [4:06:09<12:44:32,  3.31s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 10125/24000 [4:06:10<9:39:07,  2.50s/it]                                                          {'loss': 0.0158, 'grad_norm': 20.375, 'learning_rate': 1.8868258649638675e-06, 'kl': 1.2651365520556768, 'clip_ratio/low_mean': 0.047511539035864796, 'clip_ratio/low_min': 0.02138838698156178, 'clip_ratio/high_mean': 0.04890936524607241, 'clip_ratio/high_max': 0.07960620386215547, 'clip_ratio/region_mean': 0.09642090435760717, 'num_tokens': 2303185.0, 'completions/mean_length': 308.375, 'completions/min_length': 41.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.16666666666666663, 'completions/mean_terminated_length': 267.6499938964844, 'completions/min_terminated_length': 41.0, 'completions/max_terminated_length': 496.0, 'rewards/combined_reward_trl/mean': 0.577958345413208, 'rewards/combined_reward_trl/std': 0.2878756821155548, 'reward': 0.577958345413208, 'reward_std': 0.2917756736278534, 'epoch': 3.38}
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 10125/24000 [4:06:10<9:39:07,  2.50s/it]wandb: WARNING Tried to log to step 10125 that is less than the current step 92291. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-10 21:50:36,892 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5041666666666667, 'avg_raw_dharma_score': 0.5833333333333334, 'avg_raw_helpfulness_score': 0.5083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5370833333333334}
2025-05-10 21:50:45,564 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.43750000000000006, 'avg_raw_dharma_score': 0.375, 'avg_raw_helpfulness_score': 0.5, 'avg_penalty': 0.0, 'avg_combined_reward': 0.4312500000000001}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 21:51:34,599 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6916666666666668, 'avg_raw_dharma_score': 0.8125, 'avg_raw_helpfulness_score': 0.8250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7799999999999999}
2025-05-10 21:51:47,867 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5695833333333334, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.65, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6658749999999999}
2025-05-10 21:52:33,969 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8445833333333334, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.8583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8942083333333334}
2025-05-10 21:52:35,132 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8416666666666667, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.9, 'avg_penalty': 0.0, 'avg_combined_reward': 0.9225000000000002}
2025-05-10 21:53:24,166 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8012500000000001, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.7083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8362083333333333}
2025-05-10 21:53:27,935 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7095833333333332, 'avg_raw_dharma_score': 0.625, 'avg_raw_helpfulness_score': 0.7083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.675375}
  warnings.warn(
2025-05-10 21:54:30,543 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8541666666666666, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.9, 'avg_penalty': 0.0, 'avg_combined_reward': 0.9262500000000001}
2025-05-10 21:54:35,986 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6470833333333333, 'avg_raw_dharma_score': 0.5833333333333334, 'avg_raw_helpfulness_score': 0.6666666666666669, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6274583333333335}
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 10321/24000 [4:10:51<34:06:47,  8.98s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 10322/24000 [4:10:52<24:35:54,  6.47s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 10323/24000 [4:10:53<17:56:17,  4.72s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 10324/24000 [4:10:53<13:16:33,  3.49s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 10325/24000 [4:10:54<10:00:49,  2.64s/it]                                                          {'loss': 0.037, 'grad_norm': 13.6875, 'learning_rate': 1.8484350399426383e-06, 'kl': 0.6207560686270396, 'clip_ratio/low_mean': 0.05725776117217417, 'clip_ratio/low_min': 0.004649879202867547, 'clip_ratio/high_mean': 0.022383550032197188, 'clip_ratio/high_max': 0.028990397695451975, 'clip_ratio/region_mean': 0.0796413123064364, 'num_tokens': 2342665.0, 'completions/mean_length': 305.7083435058594, 'completions/min_length': 100.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.08333333333333337, 'completions/mean_terminated_length': 286.9545593261719, 'completions/min_terminated_length': 100.0, 'completions/max_terminated_length': 404.0, 'rewards/combined_reward_trl/mean': 0.7768542170524597, 'rewards/combined_reward_trl/std': 0.1981213539838791, 'reward': 0.7768542170524597, 'reward_std': 0.10157912969589233, 'epoch': 3.44}
2025-05-10 21:55:26,273 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7708333333333334, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.8166666666666669, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8595833333333335}
2025-05-10 21:55:27,544 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6283333333333334, 'avg_raw_dharma_score': 0.7291666666666666, 'avg_raw_helpfulness_score': 0.6916666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6876666666666668}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 21:56:18,983 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6816666666666668, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.6916666666666665, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7620000000000001}
2025-05-10 21:56:33,183 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7374999999999999, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.7833333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8229166666666666}
2025-05-10 21:57:24,036 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6375000000000001, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.7333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7945833333333332}
2025-05-10 21:57:24,042 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7029166666666665, 'avg_raw_dharma_score': 0.8624999999999999, 'avg_raw_helpfulness_score': 0.7583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7833750000000003}
                                                         {'loss': 0.0351, 'grad_norm': 3.921875, 'learning_rate': 1.8194810942460478e-06, 'kl': 0.8628719878196717, 'clip_ratio/low_mean': 0.04209394957094143, 'clip_ratio/low_min': 0.02623766888398677, 'clip_ratio/high_mean': 0.016319737775872152, 'clip_ratio/high_max': 0.02109467487161358, 'clip_ratio/region_mean': 0.05841368692616622, 'epoch': 3.49}
2025-05-10 21:58:14,390 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7916666666666666, 'avg_raw_dharma_score': 0.9208333333333334, 'avg_raw_helpfulness_score': 0.8750000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8683333333333333}
2025-05-10 21:58:16,623 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.725, 'avg_raw_dharma_score': 0.7875, 'avg_raw_helpfulness_score': 0.8000000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7725}
  warnings.warn(
2025-05-10 21:59:24,622 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6095833333333333, 'avg_raw_dharma_score': 0.9, 'avg_raw_helpfulness_score': 0.7416666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.765375}
2025-05-10 21:59:25,479 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7374999999999998, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.8416666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8404166666666669}
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 10521/24000 [4:15:41<34:33:12,  9.23s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 10522/24000 [4:15:42<24:53:30,  6.65s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 10523/24000 [4:15:42<18:07:48,  4.84s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 10524/24000 [4:15:43<13:23:47,  3.58s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 10525/24000 [4:15:43<10:05:00,  2.69s/it]                                                          {'loss': 0.0205, 'grad_norm': 21.5, 'learning_rate': 1.8098013848757173e-06, 'kl': 0.7709102592865626, 'clip_ratio/low_mean': 0.025269438851003845, 'clip_ratio/low_min': 0.01646316923201084, 'clip_ratio/high_mean': 0.03777438314864412, 'clip_ratio/high_max': 0.04936137570689122, 'clip_ratio/region_mean': 0.06304382145249596, 'num_tokens': 2388349.0, 'completions/mean_length': 311.3333435058594, 'completions/min_length': 149.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.08333333333333337, 'completions/mean_terminated_length': 293.0909118652344, 'completions/min_terminated_length': 149.0, 'completions/max_terminated_length': 415.0, 'rewards/combined_reward_trl/mean': 0.8028958439826965, 'rewards/combined_reward_trl/std': 0.22605106234550476, 'reward': 0.8028959035873413, 'reward_std': 0.20868675410747528, 'epoch': 3.51}
2025-05-10 22:00:18,539 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7220833333333334, 'avg_raw_dharma_score': 0.9, 'avg_raw_helpfulness_score': 0.7333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.796625}
2025-05-10 22:00:18,547 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6, 'avg_raw_dharma_score': 0.775, 'avg_raw_helpfulness_score': 0.7333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.71}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 22:01:09,333 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7245833333333334, 'avg_raw_dharma_score': 0.8583333333333334, 'avg_raw_helpfulness_score': 0.8166666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8057083333333334}
2025-05-10 22:01:23,574 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7166666666666668, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.7583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8091666666666667}
2025-05-10 22:02:14,615 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.49625000000000014, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.6583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.646375}
2025-05-10 22:02:16,520 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.3326388888888889, 'avg_raw_dharma_score': 0.5, 'avg_raw_helpfulness_score': 0.39999999999999997, 'avg_penalty': 0.0, 'avg_combined_reward': 0.41979166666666673}
2025-05-10 22:03:09,108 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4208333333333334, 'avg_raw_dharma_score': 0.5, 'avg_raw_helpfulness_score': 0.5166666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.48125}
2025-05-10 22:03:09,338 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6249999999999999, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.6666666666666669, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7041666666666666}
  warnings.warn(
2025-05-10 22:04:12,628 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8200000000000002, 'avg_raw_dharma_score': 0.9833333333333334, 'avg_raw_helpfulness_score': 0.9083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.9118333333333335}
2025-05-10 22:04:15,698 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8333333333333334, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.8750000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.9125000000000001}
 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 10721/24000 [4:20:31<33:19:38,  9.04s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 10722/24000 [4:20:32<24:01:26,  6.51s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 10723/24000 [4:20:32<17:30:44,  4.75s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 10724/24000 [4:20:33<12:57:18,  3.51s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 10725/24000 [4:20:34<9:45:50,  2.65s/it]                                                          {'loss': 0.0746, 'grad_norm': 7.84375, 'learning_rate': 1.7709518241855921e-06, 'kl': 1.8927433854341507, 'clip_ratio/low_mean': 0.014090538757154719, 'clip_ratio/low_min': 0.0004799731665601333, 'clip_ratio/high_mean': 0.16432695741454761, 'clip_ratio/high_max': 0.2367756051880618, 'clip_ratio/region_mean': 0.178417494695168, 'num_tokens': 2433087.0, 'completions/mean_length': 355.8333435058594, 'completions/min_length': 225.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.04166666666666663, 'completions/mean_terminated_length': 349.0434875488281, 'completions/min_terminated_length': 225.0, 'completions/max_terminated_length': 494.0, 'rewards/combined_reward_trl/mean': 0.9121666550636292, 'rewards/combined_reward_trl/std': 0.03117540292441845, 'reward': 0.9121667742729187, 'reward_std': 0.023639604449272156, 'epoch': 3.58}
2025-05-10 22:05:06,228 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.67375, 'avg_raw_dharma_score': 0.6875, 'avg_raw_helpfulness_score': 0.775, 'avg_penalty': 0.0, 'avg_combined_reward': 0.709625}
2025-05-10 22:05:08,561 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7161111111111111, 'avg_raw_dharma_score': 0.8166666666666668, 'avg_raw_helpfulness_score': 0.7416666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7639999999999999}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 22:06:00,340 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5095833333333334, 'avg_raw_dharma_score': 0.5833333333333334, 'avg_raw_helpfulness_score': 0.5416666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5487083333333334}
2025-05-10 22:06:16,296 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7625000000000001, 'avg_raw_dharma_score': 0.625, 'avg_raw_helpfulness_score': 0.8583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7362500000000001}
2025-05-10 22:07:06,693 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7083333333333334, 'avg_raw_dharma_score': 0.9250000000000002, 'avg_raw_helpfulness_score': 0.8083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8250000000000002}
2025-05-10 22:07:07,267 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6768055555555555, 'avg_raw_dharma_score': 0.9833333333333334, 'avg_raw_helpfulness_score': 0.7916666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.833875}
2025-05-10 22:07:56,809 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8229166666666666, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.8500000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8185416666666668}
2025-05-10 22:07:58,474 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7926388888888889, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.8333333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8044583333333334}
  warnings.warn(
2025-05-10 22:09:02,013 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6208333333333332, 'avg_raw_dharma_score': 0.8583333333333334, 'avg_raw_helpfulness_score': 0.6083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7120833333333333}
2025-05-10 22:09:03,457 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.42500000000000004, 'avg_raw_dharma_score': 0.35000000000000003, 'avg_raw_helpfulness_score': 0.55, 'avg_penalty': 0.0, 'avg_combined_reward': 0.43250000000000005}
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 10921/24000 [4:25:19<31:51:54,  8.77s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 10922/24000 [4:25:20<22:59:42,  6.33s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 10923/24000 [4:25:20<16:47:11,  4.62s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 10924/24000 [4:25:21<12:26:38,  3.43s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 10925/24000 [4:25:22<9:24:03,  2.59s/it]                                                          {'loss': 0.0595, 'grad_norm': 17.5, 'learning_rate': 1.7319134327628918e-06, 'kl': 0.5400107537706693, 'clip_ratio/low_mean': 0.04299124994625648, 'clip_ratio/low_min': 0.008331379455824694, 'clip_ratio/high_mean': 0.02579585659550503, 'clip_ratio/high_max': 0.03720076765554647, 'clip_ratio/region_mean': 0.06878710624373828, 'num_tokens': 2477917.0, 'completions/mean_length': 325.625, 'completions/min_length': 113.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 299.0, 'completions/min_terminated_length': 113.0, 'completions/max_terminated_length': 484.0, 'rewards/combined_reward_trl/mean': 0.5722916126251221, 'rewards/combined_reward_trl/std': 0.26390451192855835, 'reward': 0.5722916722297668, 'reward_std': 0.22374257445335388, 'epoch': 3.64}
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 10925/24000 [4:25:22<9:24:03,  2.59s/it]wandb: WARNING Tried to log to step 10925 that is less than the current step 99583. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-10 22:09:55,500 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6041666666666666, 'avg_raw_dharma_score': 0.7166666666666667, 'avg_raw_helpfulness_score': 0.5750000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6404166666666665}
2025-05-10 22:09:58,695 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4125000000000001, 'avg_raw_dharma_score': 0.5208333333333334, 'avg_raw_helpfulness_score': 0.5333333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.49208333333333326}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 22:10:51,123 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5291666666666667, 'avg_raw_dharma_score': 0.7166666666666667, 'avg_raw_helpfulness_score': 0.5750000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6179166666666667}
2025-05-10 22:11:07,975 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7020833333333333, 'avg_raw_dharma_score': 0.775, 'avg_raw_helpfulness_score': 0.775, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7531249999999999}
2025-05-10 22:11:57,777 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6029166666666667, 'avg_raw_dharma_score': 0.5625, 'avg_raw_helpfulness_score': 0.8083333333333332, 'avg_penalty': 0.0, 'avg_combined_reward': 0.648375}
2025-05-10 22:11:58,478 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.71375, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.775, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8132916666666667}
2025-05-10 22:12:49,876 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8249999999999998, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.8333333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8975000000000001}
2025-05-10 22:12:49,927 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6841666666666667, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.7250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7894166666666665}
  warnings.warn(
2025-05-10 22:13:56,172 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.44166666666666665, 'avg_raw_dharma_score': 0.525, 'avg_raw_helpfulness_score': 0.6166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5275}
2025-05-10 22:14:02,739 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8916666666666666, 'avg_raw_dharma_score': 0.9333333333333332, 'avg_raw_helpfulness_score': 0.8916666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.9083333333333333}
 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 11121/24000 [4:30:18<37:18:10, 10.43s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 11122/24000 [4:30:19<26:47:08,  7.49s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 11123/24000 [4:30:19<19:25:26,  5.43s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 11124/24000 [4:30:20<14:16:16,  3.99s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 11125/24000 [4:30:21<10:39:52,  2.98s/it]                                                          {'loss': -0.0717, 'grad_norm': 23.625, 'learning_rate': 1.6927134170974528e-06, 'kl': 0.4642508327960968, 'clip_ratio/low_mean': 0.03480310934285323, 'clip_ratio/low_min': 0.005646980199962855, 'clip_ratio/high_mean': 0.04455905912599216, 'clip_ratio/high_max': 0.06951279772135119, 'clip_ratio/region_mean': 0.0793621681149428, 'num_tokens': 2518107.0, 'completions/mean_length': 281.9583435058594, 'completions/min_length': 1.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.04166666666666663, 'completions/mean_terminated_length': 271.9565124511719, 'completions/min_terminated_length': 1.0, 'completions/max_terminated_length': 510.0, 'rewards/combined_reward_trl/mean': 0.7179166674613953, 'rewards/combined_reward_trl/std': 0.3181806802749634, 'reward': 0.7179166674613953, 'reward_std': 0.20695678889751434, 'epoch': 3.71}
 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 11125/24000 [4:30:21<10:39:52,  2.98s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 11126/24000 [4:30:21<8:08:44,  2.28s/it]  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 11127/24000 [4:30:22<6:22:39,  1.78s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 11128/24000 [4:30:23<5:08:20,  1.44s/it]wandb: WARNING Tried to log to step 11125 that is less than the current step 101406. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-10 22:14:54,876 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8166666666666665, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.9, 'avg_penalty': 0.0, 'avg_combined_reward': 0.9150000000000001}
2025-05-10 22:14:58,058 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.75, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.8333333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8250000000000001}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 22:15:48,970 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8395833333333335, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.8916666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8860416666666667}
2025-05-10 22:16:03,819 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6854166666666667, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.7166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7372916666666667}
2025-05-10 22:16:52,964 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6895833333333333, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.8166666666666669, 'avg_penalty': 0.0, 'avg_combined_reward': 0.851875}
2025-05-10 22:16:56,040 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6145833333333334, 'avg_raw_dharma_score': 0.7083333333333334, 'avg_raw_helpfulness_score': 0.6749999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6702083333333334}
2025-05-10 22:17:44,780 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8125, 'avg_raw_dharma_score': 0.9833333333333334, 'avg_raw_helpfulness_score': 0.8833333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.9020833333333335}
2025-05-10 22:17:48,375 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6833333333333335, 'avg_raw_dharma_score': 0.8624999999999999, 'avg_raw_helpfulness_score': 0.8833333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8150000000000001}
  warnings.warn(
2025-05-10 22:18:54,486 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7819444444444444, 'avg_raw_dharma_score': 0.8416666666666667, 'avg_raw_helpfulness_score': 0.7999999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8112500000000002}
2025-05-10 22:18:57,592 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6583333333333333, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.7166666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7291666666666666}
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 11321/24000 [4:35:13<32:53:57,  9.34s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 11322/24000 [4:35:14<23:41:51,  6.73s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 11323/24000 [4:35:14<17:15:10,  4.90s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 11324/24000 [4:35:15<12:44:28,  3.62s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 11325/24000 [4:35:16<9:35:00,  2.72s/it]                                                          {'loss': -0.061, 'grad_norm': 15.6875, 'learning_rate': 1.6533790963176743e-06, 'kl': 0.40361369868119557, 'clip_ratio/low_mean': 0.02885433757250818, 'clip_ratio/low_min': 0.018288128512601056, 'clip_ratio/high_mean': 0.030642710958297053, 'clip_ratio/high_max': 0.04041936146405836, 'clip_ratio/region_mean': 0.05949704815633595, 'num_tokens': 2560102.0, 'completions/mean_length': 308.5833435058594, 'completions/min_length': 71.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.04166666666666663, 'completions/mean_terminated_length': 299.7391357421875, 'completions/min_terminated_length': 71.0, 'completions/max_terminated_length': 483.0, 'rewards/combined_reward_trl/mean': 0.7702083587646484, 'rewards/combined_reward_trl/std': 0.25575751066207886, 'reward': 0.7702083587646484, 'reward_std': 0.19414928555488586, 'epoch': 3.77}
2025-05-10 22:19:47,107 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8604166666666666, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.875, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8872916666666667}
2025-05-10 22:19:50,705 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6354166666666666, 'avg_raw_dharma_score': 0.4791666666666667, 'avg_raw_helpfulness_score': 0.5416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5447916666666668}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 22:20:42,971 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7320833333333332, 'avg_raw_dharma_score': 0.7375000000000002, 'avg_raw_helpfulness_score': 0.8083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7571249999999999}
2025-05-10 22:20:51,772 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7194444444444444, 'avg_raw_dharma_score': 0.8625000000000002, 'avg_raw_helpfulness_score': 0.8583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8183333333333332}
2025-05-10 22:21:42,342 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6041666666666666, 'avg_raw_dharma_score': 0.5833333333333334, 'avg_raw_helpfulness_score': 0.625, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6020833333333333}
2025-05-10 22:21:45,557 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7291666666666665, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.7416666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7912500000000001}
2025-05-10 22:22:38,104 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5416666666666666, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.6249999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6166666666666667}
2025-05-10 22:22:38,833 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8333333333333334, 'avg_raw_dharma_score': 0.9666666666666668, 'avg_raw_helpfulness_score': 0.7833333333333332, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8716666666666667}
  warnings.warn(
2025-05-10 22:23:43,681 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6749999999999999, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.8083333333333332, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7783333333333333}
2025-05-10 22:23:45,228 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7708333333333334, 'avg_raw_dharma_score': 0.8416666666666667, 'avg_raw_helpfulness_score': 0.6833333333333332, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7729166666666666}
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 11521/24000 [4:40:01<31:19:42,  9.04s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 11522/24000 [4:40:01<22:31:07,  6.50s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 11523/24000 [4:40:02<16:21:03,  4.72s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 11524/24000 [4:40:02<12:02:05,  3.47s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 11525/24000 [4:40:03<9:00:50,  2.60s/it]                                                          {'loss': 0.1339, 'grad_norm': 17.0, 'learning_rate': 1.6139378831513754e-06, 'kl': 1.3387137949466705, 'clip_ratio/low_mean': 0.035129079507508626, 'clip_ratio/low_min': 0.0029795607272535564, 'clip_ratio/high_mean': 0.011807034832114975, 'clip_ratio/high_max': 0.014753813001637658, 'clip_ratio/region_mean': 0.04693611420225352, 'num_tokens': 2599574.0, 'completions/mean_length': 255.83334350585938, 'completions/min_length': 1.0, 'completions/max_length': 431.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 255.83334350585938, 'completions/min_terminated_length': 1.0, 'completions/max_terminated_length': 431.0, 'rewards/combined_reward_trl/mean': 0.7756250500679016, 'rewards/combined_reward_trl/std': 0.2547774612903595, 'reward': 0.7756249904632568, 'reward_std': 0.1880568116903305, 'epoch': 3.84}
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 11525/24000 [4:40:03<9:00:50,  2.60s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 11526/24000 [4:40:04<6:54:11,  1.99s/it]wandb: WARNING Tried to log to step 11525 that is less than the current step 105052. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-10 22:24:33,560 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.57375, 'avg_raw_dharma_score': 0.6875, 'avg_raw_helpfulness_score': 0.5916666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.624625}
2025-05-10 22:24:34,311 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5575, 'avg_raw_dharma_score': 0.625, 'avg_raw_helpfulness_score': 0.5416666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5797500000000001}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 22:25:23,632 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5499999999999999, 'avg_raw_dharma_score': 0.7541666666666668, 'avg_raw_helpfulness_score': 0.725, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6841666666666666}
2025-05-10 22:25:42,446 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5862499999999998, 'avg_raw_dharma_score': 0.6333333333333333, 'avg_raw_helpfulness_score': 0.6416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6217083333333333}
2025-05-10 22:26:32,957 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6041666666666666, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.6083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6804166666666668}
2025-05-10 22:26:33,586 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6791666666666667, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.7833333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7887500000000002}
2025-05-10 22:27:25,488 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6875, 'avg_raw_dharma_score': 0.9250000000000002, 'avg_raw_helpfulness_score': 0.7833333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8112499999999999}
2025-05-10 22:27:25,625 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7958333333333333, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.8000000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8454166666666666}
  warnings.warn(
2025-05-10 22:28:31,116 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7875, 'avg_raw_dharma_score': 0.8583333333333334, 'avg_raw_helpfulness_score': 0.8083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8220833333333335}
2025-05-10 22:28:32,317 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6866666666666666, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.7083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7851666666666667}
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 11721/24000 [4:44:48<30:56:34,  9.07s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 11722/24000 [4:44:48<22:18:16,  6.54s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 11723/24000 [4:44:49<16:15:31,  4.77s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 11724/24000 [4:44:50<12:01:36,  3.53s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 11725/24000 [4:44:50<9:03:53,  2.66s/it]                                                          {'loss': 0.0586, 'grad_norm': 24.5, 'learning_rate': 1.5744172648214153e-06, 'kl': 0.7478183197975159, 'clip_ratio/low_mean': 0.06966861199471168, 'clip_ratio/low_min': 0.044506583693437275, 'clip_ratio/high_mean': 0.01281387309000517, 'clip_ratio/high_max': 0.015045877862721681, 'clip_ratio/region_mean': 0.08248248388137047, 'num_tokens': 2641942.0, 'completions/mean_length': 307.54168701171875, 'completions/min_length': 70.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.08333333333333337, 'completions/mean_terminated_length': 288.9545593261719, 'completions/min_terminated_length': 70.0, 'completions/max_terminated_length': 393.0, 'rewards/combined_reward_trl/mean': 0.8036250472068787, 'rewards/combined_reward_trl/std': 0.22983133792877197, 'reward': 0.8036249876022339, 'reward_std': 0.2235586941242218, 'epoch': 3.91}
2025-05-10 22:29:23,793 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.75, 'avg_raw_dharma_score': 0.8875000000000001, 'avg_raw_helpfulness_score': 0.8583333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8375}
2025-05-10 22:29:24,229 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.665, 'avg_raw_dharma_score': 0.7583333333333333, 'avg_raw_helpfulness_score': 0.8000000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7428333333333335}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 22:30:16,781 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5791666666666667, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.6416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.66625}
2025-05-10 22:30:30,171 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7575000000000002, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.7333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7139166666666669}
2025-05-10 22:31:22,025 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.61375, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.65, 'avg_penalty': 0.0, 'avg_combined_reward': 0.679125}
2025-05-10 22:31:22,161 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5291666666666666, 'avg_raw_dharma_score': 0.6833333333333332, 'avg_raw_helpfulness_score': 0.49166666666666664, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5795833333333333}
2025-05-10 22:32:13,850 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6541666666666665, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.6916666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.75375}
2025-05-10 22:32:14,558 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7749999999999999, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.875, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8783333333333334}
  warnings.warn(
2025-05-10 22:33:19,446 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7345833333333333, 'avg_raw_dharma_score': 0.9833333333333334, 'avg_raw_helpfulness_score': 0.9, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8837083333333334}
2025-05-10 22:33:21,324 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7666666666666666, 'avg_raw_dharma_score': 0.8541666666666666, 'avg_raw_helpfulness_score': 0.75, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7966666666666667}
 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 11921/24000 [4:49:37<28:50:24,  8.60s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 11922/24000 [4:49:37<20:49:17,  6.21s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 11923/24000 [4:49:38<15:12:32,  4.53s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 11924/24000 [4:49:39<11:16:53,  3.36s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 11925/24000 [4:49:39<8:31:54,  2.54s/it]                                                          {'loss': 0.0698, 'grad_norm': 9.1875, 'learning_rate': 1.5348447838894058e-06, 'kl': 0.9694596960147221, 'clip_ratio/low_mean': 0.01894279915567798, 'clip_ratio/low_min': 0.002530184122733772, 'clip_ratio/high_mean': 0.06974123828733961, 'clip_ratio/high_max': 0.12285798901381592, 'clip_ratio/region_mean': 0.08868403712597986, 'num_tokens': 2689442.0, 'completions/mean_length': 332.66668701171875, 'completions/min_length': 187.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.04166666666666663, 'completions/mean_terminated_length': 324.86956787109375, 'completions/min_terminated_length': 187.0, 'completions/max_terminated_length': 466.0, 'rewards/combined_reward_trl/mean': 0.8401874899864197, 'rewards/combined_reward_trl/std': 0.11983037739992142, 'reward': 0.8401875495910645, 'reward_std': 0.05986780673265457, 'epoch': 3.98}
2025-05-10 22:34:11,820 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8381944444444445, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.8916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.9189583333333334}
2025-05-10 22:34:17,129 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.3791666666666667, 'avg_raw_dharma_score': 0.35833333333333334, 'avg_raw_helpfulness_score': 0.39166666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.3745833333333333}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 22:35:08,428 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7555555555555555, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.6749999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7791666666666667}
2025-05-10 22:35:23,360 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5625000000000001, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.6416666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6279166666666667}
2025-05-10 22:36:12,535 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7708333333333335, 'avg_raw_dharma_score': 0.8583333333333334, 'avg_raw_helpfulness_score': 0.7833333333333332, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8095833333333333}
2025-05-10 22:36:15,024 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7875, 'avg_raw_dharma_score': 0.8375, 'avg_raw_helpfulness_score': 0.8083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8137500000000001}
2025-05-10 22:37:06,048 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.28750000000000003, 'avg_raw_dharma_score': 0.375, 'avg_raw_helpfulness_score': 0.65, 'avg_penalty': 0.0, 'avg_combined_reward': 0.4312500000000001}
2025-05-10 22:37:07,008 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.61875, 'avg_raw_dharma_score': 0.6583333333333333, 'avg_raw_helpfulness_score': 0.6666666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6489583333333333}
  warnings.warn(
2025-05-10 22:38:13,767 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7041666666666667, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.7500000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7529166666666667}
2025-05-10 22:38:14,225 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.63875, 'avg_raw_dharma_score': 0.6875, 'avg_raw_helpfulness_score': 0.6583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6641250000000002}
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 12121/24000 [4:54:30<30:35:35,  9.27s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 12122/24000 [4:54:30<22:02:29,  6.68s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 12123/24000 [4:54:31<16:03:20,  4.87s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 12124/24000 [4:54:32<11:51:57,  3.60s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 12125/24000 [4:54:32<8:56:00,  2.71s/it]                                                          {'loss': 0.0876, 'grad_norm': 13.875, 'learning_rate': 1.495248019060847e-06, 'kl': 1.2278692785898844, 'clip_ratio/low_mean': 0.040063000827018795, 'clip_ratio/low_min': 0.013197564917306105, 'clip_ratio/high_mean': 0.012156014594559868, 'clip_ratio/high_max': 0.01684147574628393, 'clip_ratio/region_mean': 0.0522190149842451, 'num_tokens': 2732749.0, 'completions/mean_length': 332.125, 'completions/min_length': 55.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 306.4285888671875, 'completions/min_terminated_length': 55.0, 'completions/max_terminated_length': 455.0, 'rewards/combined_reward_trl/mean': 0.7085208296775818, 'rewards/combined_reward_trl/std': 0.2567169666290283, 'reward': 0.7085208296775818, 'reward_std': 0.24161283671855927, 'epoch': 4.04}
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 12125/24000 [4:54:32<8:56:00,  2.71s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 12126/24000 [4:54:33<6:53:09,  2.09s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 12127/24000 [4:54:34<5:26:50,  1.65s/it]wandb: WARNING Tried to log to step 12125 that is less than the current step 110521. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-10 22:39:08,302 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.45, 'avg_raw_dharma_score': 0.48333333333333334, 'avg_raw_helpfulness_score': 0.44166666666666665, 'avg_penalty': 0.0, 'avg_combined_reward': 0.46083333333333326}
2025-05-10 22:39:08,379 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.45250000000000007, 'avg_raw_dharma_score': 0.5583333333333333, 'avg_raw_helpfulness_score': 0.5583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5265833333333333}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 22:39:57,949 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7554166666666666, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.8833333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.891625}
2025-05-10 22:40:19,185 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7120833333333333, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.7916666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7511250000000002}
2025-05-10 22:41:12,131 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7487499999999999, 'avg_raw_dharma_score': 0.9416666666666668, 'avg_raw_helpfulness_score': 0.8083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8437916666666668}
2025-05-10 22:41:12,914 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7283333333333334, 'avg_raw_dharma_score': 0.8583333333333334, 'avg_raw_helpfulness_score': 0.8250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8093333333333333}
2025-05-10 22:42:04,350 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6508333333333334, 'avg_raw_dharma_score': 0.8583333333333334, 'avg_raw_helpfulness_score': 0.7333333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7585833333333335}
2025-05-10 22:42:05,611 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7833333333333332, 'avg_raw_dharma_score': 0.9, 'avg_raw_helpfulness_score': 0.8416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8475000000000001}
  warnings.warn(
2025-05-10 22:43:07,778 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.46249999999999997, 'avg_raw_dharma_score': 0.525, 'avg_raw_helpfulness_score': 0.55, 'avg_penalty': 0.0, 'avg_combined_reward': 0.51375}
2025-05-10 22:43:10,315 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6165277777777779, 'avg_raw_dharma_score': 0.775, 'avg_raw_helpfulness_score': 0.6500000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6899583333333333}
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 12321/24000 [4:59:26<27:46:14,  8.56s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 12322/24000 [4:59:26<20:03:16,  6.18s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 12323/24000 [4:59:27<14:39:14,  4.52s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 12324/24000 [4:59:28<10:52:42,  3.35s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 12325/24000 [4:59:28<8:13:54,  2.54s/it]                                                          {'loss': -0.0652, 'grad_norm': 13.5625, 'learning_rate': 1.455654565965083e-06, 'kl': 1.0124296168486278, 'clip_ratio/low_mean': 0.013415008049147824, 'clip_ratio/low_min': 0.010248244598818321, 'clip_ratio/high_mean': 0.07530226619448513, 'clip_ratio/high_max': 0.13350253077534338, 'clip_ratio/region_mean': 0.08871727331386259, 'num_tokens': 2777263.0, 'completions/mean_length': 301.625, 'completions/min_length': 1.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 271.5714416503906, 'completions/min_terminated_length': 1.0, 'completions/max_terminated_length': 471.0, 'rewards/combined_reward_trl/mean': 0.601854145526886, 'rewards/combined_reward_trl/std': 0.3157801330089569, 'reward': 0.6018542051315308, 'reward_std': 0.2604554295539856, 'epoch': 4.11}
2025-05-10 22:44:01,996 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.49333333333333335, 'avg_raw_dharma_score': 0.5166666666666667, 'avg_raw_helpfulness_score': 0.4833333333333332, 'avg_penalty': 0.0, 'avg_combined_reward': 0.49966666666666665}
2025-05-10 22:44:03,553 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7208333333333333, 'avg_raw_dharma_score': 0.9, 'avg_raw_helpfulness_score': 0.7666666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.80625}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 22:44:56,147 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8013888888888889, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.7416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7795833333333334}
2025-05-10 22:45:05,916 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6750000000000002, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.7500000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7775000000000002}
2025-05-10 22:45:58,388 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8375, 'avg_raw_dharma_score': 0.9833333333333334, 'avg_raw_helpfulness_score': 0.8916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.9120833333333335}
2025-05-10 22:45:59,883 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7000000000000001, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.6833333333333332, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7316666666666668}
2025-05-10 22:46:47,560 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7591666666666667, 'avg_raw_dharma_score': 0.9208333333333334, 'avg_raw_helpfulness_score': 0.8250000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8435833333333335}
2025-05-10 22:46:53,670 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.3958333333333333, 'avg_raw_dharma_score': 0.5416666666666666, 'avg_raw_helpfulness_score': 0.5333333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.49541666666666667}
  warnings.warn(
2025-05-10 22:48:01,118 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.505, 'avg_raw_dharma_score': 0.5666666666666667, 'avg_raw_helpfulness_score': 0.575, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5506666666666667}
2025-05-10 22:48:01,306 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.60625, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.6916666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7227083333333333}
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 12521/24000 [5:04:17<29:56:43,  9.39s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 12522/24000 [5:04:17<21:34:05,  6.76s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 12523/24000 [5:04:18<15:42:13,  4.93s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 12524/24000 [5:04:19<11:35:52,  3.64s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 12525/24000 [5:04:19<8:43:26,  2.74s/it]                                                          {'loss': 0.1745, 'grad_norm': 6.21875, 'learning_rate': 1.4160920179234565e-06, 'kl': 1.8622574297587078, 'clip_ratio/low_mean': 0.00642351655405946, 'clip_ratio/low_min': 0.00011998501528675358, 'clip_ratio/high_mean': 0.08936427135486155, 'clip_ratio/high_max': 0.14371080895575383, 'clip_ratio/region_mean': 0.09578778725583106, 'num_tokens': 2819931.0, 'completions/mean_length': 351.66668701171875, 'completions/min_length': 58.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.16666666666666663, 'completions/mean_terminated_length': 319.6000061035156, 'completions/min_terminated_length': 58.0, 'completions/max_terminated_length': 452.0, 'rewards/combined_reward_trl/mean': 0.6366874575614929, 'rewards/combined_reward_trl/std': 0.29993563890457153, 'reward': 0.6366876363754272, 'reward_std': 0.262991726398468, 'epoch': 4.17}
2025-05-10 22:48:52,610 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7133333333333334, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.8166666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8256666666666664}
2025-05-10 22:48:55,079 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6125, 'avg_raw_dharma_score': 0.7083333333333334, 'avg_raw_helpfulness_score': 0.65, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6620833333333332}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 22:49:46,249 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5666666666666665, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.6, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6666666666666666}
2025-05-10 22:50:01,734 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7916666666666666, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.8166666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8658333333333333}
2025-05-10 22:50:47,962 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7658333333333333, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.8583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8872500000000002}
2025-05-10 22:50:54,590 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7195833333333334, 'avg_raw_dharma_score': 0.8791666666666668, 'avg_raw_helpfulness_score': 0.6916666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7750416666666666}
2025-05-10 22:51:46,432 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.67625, 'avg_raw_dharma_score': 0.9416666666666668, 'avg_raw_helpfulness_score': 0.7333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7995416666666667}
2025-05-10 22:51:47,211 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4541666666666668, 'avg_raw_dharma_score': 0.225, 'avg_raw_helpfulness_score': 0.4916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.37375}
  warnings.warn(
2025-05-10 22:52:52,670 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6083333333333333, 'avg_raw_dharma_score': 0.9041666666666667, 'avg_raw_helpfulness_score': 0.7333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7641666666666667}
2025-05-10 22:52:53,683 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7583333333333333, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.8166666666666665, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8558333333333334}
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 12721/24000 [5:09:09<26:45:02,  8.54s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 12722/24000 [5:09:10<19:19:12,  6.17s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 12723/24000 [5:09:10<14:07:10,  4.51s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 12724/24000 [5:09:11<10:28:47,  3.35s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 12725/24000 [5:09:12<7:55:53,  2.53s/it]                                                          {'loss': 0.2281, 'grad_norm': 19.625, 'learning_rate': 1.376587946719076e-06, 'kl': 2.125812505582968, 'clip_ratio/low_mean': 0.030798590757573643, 'clip_ratio/low_min': 5.055292199055354e-05, 'clip_ratio/high_mean': 0.03078463264896224, 'clip_ratio/high_max': 0.054783222841409344, 'clip_ratio/region_mean': 0.061583223136452335, 'num_tokens': 2867359.0, 'completions/mean_length': 377.66668701171875, 'completions/min_length': 265.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.16666666666666663, 'completions/mean_terminated_length': 350.8000183105469, 'completions/min_terminated_length': 265.0, 'completions/max_terminated_length': 486.0, 'rewards/combined_reward_trl/mean': 0.809999942779541, 'rewards/combined_reward_trl/std': 0.18634353578090668, 'reward': 0.8100000619888306, 'reward_std': 0.12728944420814514, 'epoch': 4.24}
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 12725/24000 [5:09:12<7:55:53,  2.53s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 12726/24000 [5:09:12<6:09:10,  1.96s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 12727/24000 [5:09:13<4:54:11,  1.57s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 12728/24000 [5:09:14<4:01:39,  1.29s/it]wandb: WARNING Tried to log to step 12725 that is less than the current step 115990. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-10 22:53:45,544 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5916666666666667, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.65, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7558333333333332}
2025-05-10 22:53:45,666 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5708333333333334, 'avg_raw_dharma_score': 0.6041666666666666, 'avg_raw_helpfulness_score': 0.625, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6004166666666667}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 22:54:39,537 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5693055555555556, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.65, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6657916666666667}
2025-05-10 22:54:52,689 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7179166666666666, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.7333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8020416666666668}
2025-05-10 22:55:45,121 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5583333333333332, 'avg_raw_dharma_score': 0.7125, 'avg_raw_helpfulness_score': 0.5916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.63}
2025-05-10 22:55:45,419 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6333333333333333, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.7000000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7000000000000001}
2025-05-10 22:56:36,327 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6041666666666667, 'avg_raw_dharma_score': 0.8375, 'avg_raw_helpfulness_score': 0.7166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7312500000000001}
2025-05-10 22:56:37,504 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6499999999999999, 'avg_raw_dharma_score': 0.6333333333333333, 'avg_raw_helpfulness_score': 0.6750000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6508333333333334}
  warnings.warn(
2025-05-10 22:57:42,205 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6291666666666667, 'avg_raw_dharma_score': 0.7666666666666666, 'avg_raw_helpfulness_score': 0.5916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6729166666666666}
2025-05-10 22:57:43,124 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5866666666666668, 'avg_raw_dharma_score': 0.775, 'avg_raw_helpfulness_score': 0.6083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6685}
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 12921/24000 [5:13:59<26:59:57,  8.77s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 12922/24000 [5:13:59<19:28:44,  6.33s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 12923/24000 [5:14:00<14:12:53,  4.62s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 12924/24000 [5:14:01<10:31:50,  3.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 12925/24000 [5:14:01<7:57:05,  2.58s/it]                                                          {'loss': 0.081, 'grad_norm': 19.0, 'learning_rate': 1.3371698833815915e-06, 'kl': 1.3221993231773377, 'clip_ratio/low_mean': 0.032349960110150275, 'clip_ratio/low_min': 0.0005931605670290689, 'clip_ratio/high_mean': 0.03183291956200265, 'clip_ratio/high_max': 0.04787629468754555, 'clip_ratio/region_mean': 0.06418287943466566, 'num_tokens': 2913177.0, 'completions/mean_length': 370.375, 'completions/min_length': 168.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.16666666666666663, 'completions/mean_terminated_length': 342.0500183105469, 'completions/min_terminated_length': 168.0, 'completions/max_terminated_length': 475.0, 'rewards/combined_reward_trl/mean': 0.6707083582878113, 'rewards/combined_reward_trl/std': 0.29646793007850647, 'reward': 0.6707083582878113, 'reward_std': 0.3054641783237457, 'epoch': 4.31}
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 12925/24000 [5:14:01<7:57:05,  2.58s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 12926/24000 [5:14:02<6:09:12,  2.00s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 12927/24000 [5:14:02<4:53:18,  1.59s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 12928/24000 [5:14:03<4:00:11,  1.30s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 12929/24000 [5:14:04<3:23:00,  1.10s/it]wandb: WARNING Tried to log to step 12925 that is less than the current step 117813. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-10 22:58:33,855 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8499999999999998, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.8583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8958333333333331}
2025-05-10 22:58:34,229 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7912500000000001, 'avg_raw_dharma_score': 0.9250000000000002, 'avg_raw_helpfulness_score': 0.7916666666666669, 'avg_penalty': 0.0, 'avg_combined_reward': 0.844875}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 22:59:24,055 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8233333333333334, 'avg_raw_dharma_score': 0.9666666666666667, 'avg_raw_helpfulness_score': 0.9000000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.9036666666666667}
2025-05-10 22:59:40,984 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.76375, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.75, 'avg_penalty': 0.0, 'avg_combined_reward': 0.804125}
2025-05-10 23:00:31,546 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6583333333333333, 'avg_raw_dharma_score': 0.7583333333333333, 'avg_raw_helpfulness_score': 0.6333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6908333333333333}
2025-05-10 23:00:33,904 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5125000000000001, 'avg_raw_dharma_score': 0.625, 'avg_raw_helpfulness_score': 0.525, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5612499999999999}
2025-05-10 23:01:28,451 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7791666666666667, 'avg_raw_dharma_score': 0.9416666666666668, 'avg_raw_helpfulness_score': 0.8000000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8504166666666668}
2025-05-10 23:01:29,301 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.525, 'avg_raw_dharma_score': 0.65, 'avg_raw_helpfulness_score': 0.5916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5950000000000001}
  warnings.warn(
2025-05-10 23:02:38,568 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.46749999999999997, 'avg_raw_dharma_score': 0.6291666666666667, 'avg_raw_helpfulness_score': 0.4583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5294166666666666}
2025-05-10 23:02:39,807 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5083333333333334, 'avg_raw_dharma_score': 0.5375, 'avg_raw_helpfulness_score': 0.5333333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5275}
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 13121/24000 [5:18:55<30:57:31, 10.24s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 13122/24000 [5:18:56<22:14:30,  7.36s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 13123/24000 [5:18:57<16:08:25,  5.34s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 13124/24000 [5:18:57<11:52:11,  3.93s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 13125/24000 [5:18:58<8:52:50,  2.94s/it]                                                          {'loss': 0.221, 'grad_norm': 24.25, 'learning_rate': 1.2978652990003711e-06, 'kl': 2.381388313770294, 'clip_ratio/low_mean': 0.008496298198976243, 'clip_ratio/low_min': 2.55918106995523e-05, 'clip_ratio/high_mean': 0.012147496001950154, 'clip_ratio/high_max': 0.014914996704707544, 'clip_ratio/region_mean': 0.020643794046870122, 'num_tokens': 2957679.0, 'completions/mean_length': 323.125, 'completions/min_length': 30.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 296.1428527832031, 'completions/min_terminated_length': 30.0, 'completions/max_terminated_length': 458.0, 'rewards/combined_reward_trl/mean': 0.528458297252655, 'rewards/combined_reward_trl/std': 0.30864498019218445, 'reward': 0.5284583568572998, 'reward_std': 0.3250592052936554, 'epoch': 4.38}
2025-05-10 23:03:30,314 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6625, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.6166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7004166666666666}
2025-05-10 23:03:32,442 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6875, 'avg_raw_dharma_score': 0.7291666666666666, 'avg_raw_helpfulness_score': 0.6666666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6979166666666666}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 23:04:25,692 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5591666666666669, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.6000000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6144166666666665}
2025-05-10 23:04:37,741 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7041666666666666, 'avg_raw_dharma_score': 0.9, 'avg_raw_helpfulness_score': 0.7250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7887500000000002}
2025-05-10 23:05:27,385 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.46208333333333335, 'avg_raw_dharma_score': 0.4791666666666667, 'avg_raw_helpfulness_score': 0.47500000000000003, 'avg_penalty': 0.0, 'avg_combined_reward': 0.47279166666666667}
2025-05-10 23:05:30,525 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6041666666666666, 'avg_raw_dharma_score': 0.8583333333333334, 'avg_raw_helpfulness_score': 0.7000000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7345833333333335}
2025-05-10 23:06:22,824 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.46388888888888896, 'avg_raw_dharma_score': 0.5875, 'avg_raw_helpfulness_score': 0.5166666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5291666666666667}
2025-05-10 23:06:23,683 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8041666666666667, 'avg_raw_dharma_score': 0.9, 'avg_raw_helpfulness_score': 0.7833333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.83625}
  warnings.warn(
2025-05-10 23:07:28,299 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7512499999999999, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.8000000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8320416666666669}
2025-05-10 23:07:29,477 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.61875, 'avg_raw_dharma_score': 0.8541666666666666, 'avg_raw_helpfulness_score': 0.7250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7447916666666666}
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 13321/24000 [5:23:45<26:07:20,  8.81s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 13322/24000 [5:23:46<18:50:54,  6.35s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 13323/24000 [5:23:46<13:45:27,  4.64s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 13324/24000 [5:23:47<10:11:39,  3.44s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 13325/24000 [5:23:48<7:42:38,  2.60s/it]                                                          {'loss': 0.326, 'grad_norm': 6.21875, 'learning_rate': 1.2587015855794527e-06, 'kl': 2.407577736377716, 'clip_ratio/low_mean': 0.02024641387281008, 'clip_ratio/low_min': 0.0025879970154104133, 'clip_ratio/high_mean': 0.02328431943198666, 'clip_ratio/high_max': 0.0370697895794486, 'clip_ratio/region_mean': 0.04353073323261924, 'num_tokens': 3003965.0, 'completions/mean_length': 363.54168701171875, 'completions/min_length': 204.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 342.3333435058594, 'completions/min_terminated_length': 204.0, 'completions/max_terminated_length': 481.0, 'rewards/combined_reward_trl/mean': 0.7884166836738586, 'rewards/combined_reward_trl/std': 0.23783059418201447, 'reward': 0.7884167432785034, 'reward_std': 0.16123256087303162, 'epoch': 4.44}
2025-05-10 23:08:23,134 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7441666666666668, 'avg_raw_dharma_score': 0.7666666666666666, 'avg_raw_helpfulness_score': 0.7333333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7499166666666667}
2025-05-10 23:08:24,385 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6708333333333334, 'avg_raw_dharma_score': 0.7083333333333334, 'avg_raw_helpfulness_score': 0.7250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7020833333333333}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 23:09:16,735 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.47916666666666674, 'avg_raw_dharma_score': 0.8583333333333334, 'avg_raw_helpfulness_score': 0.6666666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6870833333333334}
2025-05-10 23:09:29,845 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5208333333333334, 'avg_raw_dharma_score': 0.6333333333333333, 'avg_raw_helpfulness_score': 0.42500000000000004, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5370833333333334}
2025-05-10 23:10:20,104 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7999999999999999, 'avg_raw_dharma_score': 0.9666666666666668, 'avg_raw_helpfulness_score': 0.8416666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8791666666666668}
2025-05-10 23:10:21,572 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6833333333333332, 'avg_raw_dharma_score': 0.6833333333333332, 'avg_raw_helpfulness_score': 0.6833333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6833333333333332}
2025-05-10 23:11:12,784 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.41458333333333336, 'avg_raw_dharma_score': 0.375, 'avg_raw_helpfulness_score': 0.48333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.41937500000000005}
2025-05-10 23:11:15,949 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6000000000000001, 'avg_raw_dharma_score': 0.6916666666666668, 'avg_raw_helpfulness_score': 0.6833333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6616666666666665}
  warnings.warn(
2025-05-10 23:12:16,139 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7333333333333334, 'avg_raw_dharma_score': 0.8208333333333333, 'avg_raw_helpfulness_score': 0.7416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7708333333333334}
2025-05-10 23:12:22,410 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6750000000000002, 'avg_raw_dharma_score': 0.7125, 'avg_raw_helpfulness_score': 0.7083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7000000000000001}
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 13521/24000 [5:28:38<26:25:42,  9.08s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 13522/24000 [5:28:39<19:02:59,  6.55s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 13523/24000 [5:28:39<13:53:07,  4.77s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 13524/24000 [5:28:40<10:16:15,  3.53s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 13525/24000 [5:28:40<7:44:28,  2.66s/it]                                                          {'loss': 0.2753, 'grad_norm': 19.625, 'learning_rate': 1.2197060369476111e-06, 'kl': 2.511215707461039, 'clip_ratio/low_mean': 0.0012889159905413786, 'clip_ratio/low_min': 0.0004675352976967891, 'clip_ratio/high_mean': 0.06375569799449295, 'clip_ratio/high_max': 0.1060331215399007, 'clip_ratio/region_mean': 0.06504461380497863, 'num_tokens': 3047168.0, 'completions/mean_length': 280.91668701171875, 'completions/min_length': 67.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.04166666666666663, 'completions/mean_terminated_length': 270.86956787109375, 'completions/min_terminated_length': 67.0, 'completions/max_terminated_length': 375.0, 'rewards/combined_reward_trl/mean': 0.7354167103767395, 'rewards/combined_reward_trl/std': 0.3055177927017212, 'reward': 0.7354167699813843, 'reward_std': 0.2788724899291992, 'epoch': 4.51}
2025-05-10 23:13:08,343 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8041666666666667, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.8500000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8795833333333335}
2025-05-10 23:13:10,564 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7833333333333333, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.7916666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8225000000000001}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 23:13:59,782 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5958333333333333, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.6750000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7312500000000001}
2025-05-10 23:14:14,474 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6666666666666666, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.6916666666666665, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7408333333333333}
2025-05-10 23:15:00,431 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8250000000000001, 'avg_raw_dharma_score': 0.8208333333333333, 'avg_raw_helpfulness_score': 0.7750000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8083333333333332}
2025-05-10 23:15:04,628 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7380555555555556, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.7833333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7897500000000001}
2025-05-10 23:15:55,549 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7541666666666668, 'avg_raw_dharma_score': 0.775, 'avg_raw_helpfulness_score': 0.8333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7862500000000002}
2025-05-10 23:15:59,612 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6220833333333334, 'avg_raw_dharma_score': 0.775, 'avg_raw_helpfulness_score': 0.6250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.684125}
  warnings.warn(
2025-05-10 23:17:05,349 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6625, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.775, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7812500000000001}
2025-05-10 23:17:05,428 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6999999999999998, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.7583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8041666666666666}
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 13721/24000 [5:33:21<25:29:28,  8.93s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 13722/24000 [5:33:22<18:23:08,  6.44s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 13723/24000 [5:33:22<13:24:44,  4.70s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 13724/24000 [5:33:23<9:55:53,  3.48s/it]  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 13725/24000 [5:33:23<7:29:40,  2.63s/it]                                                         {'loss': 0.1391, 'grad_norm': 6.53125, 'learning_rate': 1.180905829736847e-06, 'kl': 1.602413395444552, 'clip_ratio/low_mean': 0.006605707193569591, 'clip_ratio/low_min': 0.002789419742766768, 'clip_ratio/high_mean': 0.012005251452016334, 'clip_ratio/high_max': 0.01440859519643709, 'clip_ratio/region_mean': 0.01861095866188407, 'num_tokens': 3091825.0, 'completions/mean_length': 355.75, 'completions/min_length': 222.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 333.4285888671875, 'completions/min_terminated_length': 222.0, 'completions/max_terminated_length': 446.0, 'rewards/combined_reward_trl/mean': 0.7927083373069763, 'rewards/combined_reward_trl/std': 0.2123316526412964, 'reward': 0.7927083969116211, 'reward_std': 0.15407724678516388, 'epoch': 4.58}
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 13725/24000 [5:33:24<7:29:40,  2.63s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 13726/24000 [5:33:24<5:47:36,  2.03s/it]wandb: WARNING Tried to log to step 13725 that is less than the current step 125105. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-10 23:17:58,665 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5579166666666667, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.6083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6165416666666667}
2025-05-10 23:17:59,371 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.70125, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.8083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8195416666666667}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 23:18:51,842 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5791666666666667, 'avg_raw_dharma_score': 0.4458333333333333, 'avg_raw_helpfulness_score': 0.6583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5495833333333333}
2025-05-10 23:19:06,417 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5916666666666667, 'avg_raw_dharma_score': 0.7166666666666667, 'avg_raw_helpfulness_score': 0.5166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6191666666666668}
2025-05-10 23:19:57,578 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7208333333333333, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.7500000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7912500000000001}
2025-05-10 23:19:59,692 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5023611111111111, 'avg_raw_dharma_score': 0.6916666666666668, 'avg_raw_helpfulness_score': 0.5333333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5873749999999999}
2025-05-10 23:20:51,039 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7152777777777778, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.7666666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7779166666666667}
2025-05-10 23:20:52,202 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8375, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.8916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.9187500000000001}
  warnings.warn(
2025-05-10 23:21:55,238 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6291666666666665, 'avg_raw_dharma_score': 0.8916666666666666, 'avg_raw_helpfulness_score': 0.7333333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7654166666666665}
2025-05-10 23:21:57,154 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6929166666666666, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.7666666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8045416666666667}
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 13921/24000 [5:38:13<22:53:42,  8.18s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 13922/24000 [5:38:13<16:33:13,  5.91s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 13923/24000 [5:38:14<12:06:55,  4.33s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 13924/24000 [5:38:15<9:00:33,  3.22s/it]  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 13925/24000 [5:38:15<6:50:07,  2.44s/it]                                                         {'loss': 0.0905, 'grad_norm': 20.375, 'learning_rate': 1.1423280044425449e-06, 'kl': 1.1835882137219111, 'clip_ratio/low_mean': 0.011682316773415854, 'clip_ratio/low_min': 0.0007137546471009652, 'clip_ratio/high_mean': 0.012095459899865092, 'clip_ratio/high_max': 0.017933957925997675, 'clip_ratio/region_mean': 0.02377777675865218, 'num_tokens': 3135470.0, 'completions/mean_length': 341.54168701171875, 'completions/min_length': 98.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.04166666666666663, 'completions/mean_terminated_length': 334.13043212890625, 'completions/min_terminated_length': 98.0, 'completions/max_terminated_length': 503.0, 'rewards/combined_reward_trl/mean': 0.7849791646003723, 'rewards/combined_reward_trl/std': 0.20236168801784515, 'reward': 0.7849792242050171, 'reward_std': 0.1842760145664215, 'epoch': 4.64}
2025-05-10 23:22:47,364 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8483333333333335, 'avg_raw_dharma_score': 0.9416666666666668, 'avg_raw_helpfulness_score': 0.875, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8936666666666667}
2025-05-10 23:22:48,750 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6872222222222222, 'avg_raw_dharma_score': 0.8166666666666668, 'avg_raw_helpfulness_score': 0.6666666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7328333333333333}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 23:23:40,790 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.3083333333333333, 'avg_raw_dharma_score': 0.3958333333333333, 'avg_raw_helpfulness_score': 0.3333333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.3508333333333334}
2025-05-10 23:23:54,902 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7041666666666667, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.7166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7595833333333334}
2025-05-10 23:24:47,253 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7458333333333335, 'avg_raw_dharma_score': 0.9416666666666668, 'avg_raw_helpfulness_score': 0.8083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8429166666666665}
2025-05-10 23:24:52,997 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7208333333333332, 'avg_raw_dharma_score': 0.6416666666666667, 'avg_raw_helpfulness_score': 0.7416666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6954166666666667}
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 14041/24000 [5:41:09<28:57:27, 10.47s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 14042/24000 [5:41:09<20:47:43,  7.52s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 14043/24000 [5:41:10<15:04:57,  5.45s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 14044/24000 [5:41:10<11:05:03,  4.01s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 14045/24000 [5:41:11<8:17:11,  3.00s/it]  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 14046/24000 [5:41:12<6:19:38,  2.29s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 14047/24000 [5:41:12<4:57:21,  1.79s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 14048/24000 [5:41:13<3:59:44,  1.45s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 14049/24000 [5:41:14<3:19:23,  1.20s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 14050/24000 [5:41:14<2:51:10,  1.03s/it]                                                         {'loss': 0.2923, 'grad_norm': 17.625, 'learning_rate': 1.1183417451732147e-06, 'kl': 2.5489437966545423, 'clip_ratio/low_mean': 0.00010635170270688832, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.01805572218261659, 'clip_ratio/high_max': 0.03293075632148733, 'clip_ratio/region_mean': 0.018162073924516638, 'num_tokens': 3161239.0, 'completions/mean_length': 363.41668701171875, 'completions/min_length': 135.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.04166666666666663, 'completions/mean_terminated_length': 356.95654296875, 'completions/min_terminated_length': 135.0, 'completions/max_terminated_length': 503.0, 'rewards/combined_reward_trl/mean': 0.7691666483879089, 'rewards/combined_reward_trl/std': 0.20646962523460388, 'reward': 0.7691667079925537, 'reward_std': 0.14878544211387634, 'epoch': 4.68}
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 14050/24000 [5:41:14<2:51:10,  1.03s/it]wandb: WARNING Tried to log to step 14050 that is less than the current step 128067. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-10 23:25:45,754 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4173611111111111, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.5333333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.551875}
2025-05-10 23:25:46,981 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7291666666666665, 'avg_raw_dharma_score': 0.9, 'avg_raw_helpfulness_score': 0.7666666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.80875}
  warnings.warn(
2025-05-10 23:26:51,243 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7583333333333333, 'avg_raw_dharma_score': 0.9041666666666667, 'avg_raw_helpfulness_score': 0.8416666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8416666666666667}
2025-05-10 23:26:52,441 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6916666666666668, 'avg_raw_dharma_score': 0.9, 'avg_raw_helpfulness_score': 0.7083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7799999999999999}
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 14121/24000 [5:43:08<24:01:29,  8.75s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 14122/24000 [5:43:09<17:20:50,  6.32s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 14123/24000 [5:43:09<12:39:44,  4.62s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 14124/24000 [5:43:10<9:22:59,  3.42s/it]  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 14125/24000 [5:43:11<7:05:15,  2.58s/it]                                                         {'loss': 0.1247, 'grad_norm': 15.5625, 'learning_rate': 1.1039994465785163e-06, 'kl': 1.7640084505081177, 'clip_ratio/low_mean': 0.00173454830617023, 'clip_ratio/low_min': 0.0004244121901380519, 'clip_ratio/high_mean': 0.04109428746703391, 'clip_ratio/high_max': 0.07384808072199424, 'clip_ratio/region_mean': 0.042828836005646735, 'num_tokens': 3178594.0, 'completions/mean_length': 333.875, 'completions/min_length': 210.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.08333333333333337, 'completions/mean_terminated_length': 317.68182373046875, 'completions/min_terminated_length': 210.0, 'completions/max_terminated_length': 511.0, 'rewards/combined_reward_trl/mean': 0.8108332753181458, 'rewards/combined_reward_trl/std': 0.1343071311712265, 'reward': 0.8108333945274353, 'reward_std': 0.11986576020717621, 'epoch': 4.71}
2025-05-10 23:27:42,404 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7861111111111111, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.8083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8283333333333333}
2025-05-10 23:27:46,916 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6916666666666668, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.7916666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8116666666666666}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 23:28:39,380 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6933333333333334, 'avg_raw_dharma_score': 0.8375, 'avg_raw_helpfulness_score': 0.725, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7605}
2025-05-10 23:28:49,710 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6416666666666666, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.7833333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8108333333333332}
2025-05-10 23:29:41,849 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4833333333333334, 'avg_raw_dharma_score': 0.6166666666666667, 'avg_raw_helpfulness_score': 0.5083333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5441666666666667}
2025-05-10 23:29:45,117 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7958333333333333, 'avg_raw_dharma_score': 0.8375, 'avg_raw_helpfulness_score': 0.7999999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8137500000000001}
2025-05-10 23:30:37,498 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6749999999999999, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.625, 'avg_penalty': 0.0, 'avg_combined_reward': 0.69}
2025-05-10 23:30:37,997 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6166666666666666, 'avg_raw_dharma_score': 0.5625, 'avg_raw_helpfulness_score': 0.6583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6075}
  warnings.warn(
2025-05-10 23:31:43,698 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.45458333333333334, 'avg_raw_dharma_score': 0.625, 'avg_raw_helpfulness_score': 0.49166666666666675, 'avg_penalty': 0.0, 'avg_combined_reward': 0.533875}
2025-05-10 23:31:44,364 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4583333333333333, 'avg_raw_dharma_score': 0.6541666666666667, 'avg_raw_helpfulness_score': 0.575, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5716666666666667}
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 14321/24000 [5:48:00<24:11:24,  9.00s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 14322/24000 [5:48:01<17:26:33,  6.49s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 14323/24000 [5:48:01<12:43:11,  4.73s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 14324/24000 [5:48:02<9:24:49,  3.50s/it]  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 14325/24000 [5:48:02<7:06:00,  2.64s/it]                                                         {'loss': 0.2334, 'grad_norm': 11.9375, 'learning_rate': 1.065946867940048e-06, 'kl': 2.5065555040041607, 'clip_ratio/low_mean': 0.009450632776909818, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.010160355521366, 'clip_ratio/high_max': 0.014900425643815348, 'clip_ratio/region_mean': 0.019610988156249124, 'num_tokens': 3220459.0, 'completions/mean_length': 318.5833435058594, 'completions/min_length': 66.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 290.952392578125, 'completions/min_terminated_length': 66.0, 'completions/max_terminated_length': 464.0, 'rewards/combined_reward_trl/mean': 0.5527708530426025, 'rewards/combined_reward_trl/std': 0.3220898509025574, 'reward': 0.5527709126472473, 'reward_std': 0.3319095969200134, 'epoch': 4.78}
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 14325/24000 [5:48:02<7:06:00,  2.64s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 14326/24000 [5:48:03<5:29:05,  2.04s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 14327/24000 [5:48:04<4:21:00,  1.62s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 14328/24000 [5:48:04<3:33:20,  1.32s/it]wandb: WARNING Tried to log to step 14325 that is less than the current step 130574. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-10 23:32:37,238 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6666666666666665, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.7166666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7650000000000001}
2025-05-10 23:32:38,346 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5404166666666667, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.6416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.654625}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 23:33:28,519 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6791666666666667, 'avg_raw_dharma_score': 0.7999999999999999, 'avg_raw_helpfulness_score': 0.7083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7362500000000001}
2025-05-10 23:33:45,012 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6670833333333334, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.7083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7959583333333332}
2025-05-10 23:34:36,359 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7399999999999999, 'avg_raw_dharma_score': 0.8166666666666668, 'avg_raw_helpfulness_score': 0.7416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7711666666666668}
2025-05-10 23:34:36,465 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7429166666666668, 'avg_raw_dharma_score': 0.8958333333333334, 'avg_raw_helpfulness_score': 0.7666666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8112083333333332}
2025-05-10 23:35:27,928 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7058333333333335, 'avg_raw_dharma_score': 0.625, 'avg_raw_helpfulness_score': 0.6583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.65925}
2025-05-10 23:35:28,326 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8287499999999999, 'avg_raw_dharma_score': 0.9375, 'avg_raw_helpfulness_score': 0.8416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8761250000000002}
  warnings.warn(
2025-05-10 23:36:34,218 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7041666666666666, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.7166666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7595833333333335}
2025-05-10 23:36:35,456 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6749999999999999, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.5583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6699999999999999}
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 14521/24000 [5:52:51<22:51:38,  8.68s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 14522/24000 [5:52:52<16:29:59,  6.27s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 14523/24000 [5:52:52<12:02:52,  4.58s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 14524/24000 [5:52:53<8:55:55,  3.39s/it]  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 14525/24000 [5:52:53<6:45:04,  2.57s/it]                                                         {'loss': 0.1653, 'grad_norm': 7.9375, 'learning_rate': 1.0281967879880163e-06, 'kl': 1.8217113284269968, 'clip_ratio/low_mean': 0.02380784831320246, 'clip_ratio/low_min': 0.0007943262446982165, 'clip_ratio/high_mean': 0.00721810676700746, 'clip_ratio/high_max': 0.008864370499116678, 'clip_ratio/region_mean': 0.03102595540927723, 'num_tokens': 3264833.0, 'completions/mean_length': 327.66668701171875, 'completions/min_length': 1.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 301.3333435058594, 'completions/min_terminated_length': 1.0, 'completions/max_terminated_length': 455.0, 'rewards/combined_reward_trl/mean': 0.7147917151451111, 'rewards/combined_reward_trl/std': 0.2733228802680969, 'reward': 0.7147916555404663, 'reward_std': 0.2248304784297943, 'epoch': 4.84}
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 14525/24000 [5:52:54<6:45:04,  2.57s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 14526/24000 [5:52:54<5:13:41,  1.99s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 14527/24000 [5:52:55<4:09:30,  1.58s/it]wandb: WARNING Tried to log to step 14525 that is less than the current step 132397. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-10 23:37:27,206 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6166666666666666, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.7083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7474999999999999}
2025-05-10 23:37:29,046 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6916666666666668, 'avg_raw_dharma_score': 0.8291666666666666, 'avg_raw_helpfulness_score': 0.7666666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7691666666666667}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 23:38:21,002 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4791666666666667, 'avg_raw_dharma_score': 0.5916666666666667, 'avg_raw_helpfulness_score': 0.4916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5279166666666667}
2025-05-10 23:38:38,437 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7458333333333332, 'avg_raw_dharma_score': 0.9, 'avg_raw_helpfulness_score': 0.7500000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8087500000000002}
2025-05-10 23:39:31,118 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5958333333333332, 'avg_raw_dharma_score': 0.5416666666666666, 'avg_raw_helpfulness_score': 0.6416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5879166666666666}
2025-05-10 23:39:31,804 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5333333333333333, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.55, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5916666666666667}
2025-05-10 23:40:25,171 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7041666666666667, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.7416666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7670833333333333}
2025-05-10 23:40:26,105 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6712500000000001, 'avg_raw_dharma_score': 0.625, 'avg_raw_helpfulness_score': 0.6583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6488750000000001}
  warnings.warn(
2025-05-10 23:41:32,481 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6666666666666666, 'avg_raw_dharma_score': 0.625, 'avg_raw_helpfulness_score': 0.8000000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.69}
2025-05-10 23:41:32,938 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5750000000000001, 'avg_raw_dharma_score': 0.5333333333333333, 'avg_raw_helpfulness_score': 0.525, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5433333333333333}
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 14721/24000 [5:57:48<23:33:39,  9.14s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 14722/24000 [5:57:49<16:58:43,  6.59s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 14723/24000 [5:57:50<12:22:19,  4.80s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 14724/24000 [5:57:50<9:08:50,  3.55s/it]  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 14725/24000 [5:57:51<6:53:25,  2.67s/it]                                                         {'loss': 0.2523, 'grad_norm': 10.5, 'learning_rate': 9.90775515367042e-07, 'kl': 2.4404722982645035, 'clip_ratio/low_mean': 0.0018386786691068362, 'clip_ratio/low_min': 0.0004340798291377723, 'clip_ratio/high_mean': 0.004739072675583884, 'clip_ratio/high_max': 0.007135880635275195, 'clip_ratio/region_mean': 0.00657775134119826, 'num_tokens': 3308900.0, 'completions/mean_length': 314.3333435058594, 'completions/min_length': 93.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.16666666666666663, 'completions/mean_terminated_length': 274.8000183105469, 'completions/min_terminated_length': 93.0, 'completions/max_terminated_length': 476.0, 'rewards/combined_reward_trl/mean': 0.6166666746139526, 'rewards/combined_reward_trl/std': 0.24984197318553925, 'reward': 0.6166666746139526, 'reward_std': 0.2434387505054474, 'epoch': 4.91}
2025-05-10 23:42:25,030 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7166666666666667, 'avg_raw_dharma_score': 0.7333333333333334, 'avg_raw_helpfulness_score': 0.6583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7058333333333332}
2025-05-10 23:42:28,540 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5537500000000001, 'avg_raw_dharma_score': 0.65, 'avg_raw_helpfulness_score': 0.5083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5786250000000001}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 23:43:20,879 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6958333333333334, 'avg_raw_dharma_score': 0.7791666666666667, 'avg_raw_helpfulness_score': 0.7833333333333332, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7554166666666666}
2025-05-10 23:43:33,873 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.49541666666666667, 'avg_raw_dharma_score': 0.5416666666666666, 'avg_raw_helpfulness_score': 0.45, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5002916666666667}
2025-05-10 23:44:25,194 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5722222222222223, 'avg_raw_dharma_score': 0.6916666666666668, 'avg_raw_helpfulness_score': 0.5750000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6208333333333332}
2025-05-10 23:44:26,779 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5404166666666668, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.5583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5962916666666668}
2025-05-10 23:45:18,465 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5941666666666666, 'avg_raw_dharma_score': 0.7083333333333334, 'avg_raw_helpfulness_score': 0.5916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6390833333333333}
2025-05-10 23:45:19,375 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8458333333333335, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.8583333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.91125}
  warnings.warn(
2025-05-10 23:46:26,002 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6845833333333334, 'avg_raw_dharma_score': 0.7291666666666666, 'avg_raw_helpfulness_score': 0.75, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7220416666666667}
2025-05-10 23:46:30,364 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7333333333333334, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.6250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7908333333333334}
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 14921/24000 [6:02:46<24:45:13,  9.82s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 14922/24000 [6:02:46<17:48:05,  7.06s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 14923/24000 [6:02:47<12:56:08,  5.13s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 14924/24000 [6:02:48<9:31:45,  3.78s/it]  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 14925/24000 [6:02:48<7:08:44,  2.83s/it]                                                         {'loss': 0.0272, 'grad_norm': 19.25, 'learning_rate': 9.537091295705703e-07, 'kl': 0.771345740656058, 'clip_ratio/low_mean': 0.0012723417789675296, 'clip_ratio/low_min': 0.0003830731334164739, 'clip_ratio/high_mean': 0.010058959749682496, 'clip_ratio/high_max': 0.017866917679396768, 'clip_ratio/region_mean': 0.01133130155193309, 'num_tokens': 3351048.0, 'completions/mean_length': 284.29168701171875, 'completions/min_length': 46.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.04166666666666663, 'completions/mean_terminated_length': 274.39129638671875, 'completions/min_terminated_length': 46.0, 'completions/max_terminated_length': 437.0, 'rewards/combined_reward_trl/mean': 0.7564374804496765, 'rewards/combined_reward_trl/std': 0.2535753548145294, 'reward': 0.7564374804496765, 'reward_std': 0.22726377844810486, 'epoch': 4.97}
2025-05-10 23:47:21,075 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5708333333333334, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.775, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7704166666666667}
2025-05-10 23:47:23,896 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7120833333333335, 'avg_raw_dharma_score': 0.8083333333333332, 'avg_raw_helpfulness_score': 0.6916666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7444583333333333}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 23:48:15,869 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.48875, 'avg_raw_dharma_score': 0.5666666666666667, 'avg_raw_helpfulness_score': 0.5583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5407916666666667}
2025-05-10 23:48:30,785 - openai._base_client - INFO - Retrying request to /chat/completions in 0.420072 seconds
2025-05-10 23:48:35,656 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6875, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.7250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7570833333333334}
2025-05-10 23:49:27,672 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.2370833333333334, 'avg_raw_dharma_score': 0.2916666666666667, 'avg_raw_helpfulness_score': 0.25, 'avg_penalty': 0.0, 'avg_combined_reward': 0.26279166666666665}
2025-05-10 23:49:28,188 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5437500000000001, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.6083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.645625}
2025-05-10 23:50:19,091 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4791666666666667, 'avg_raw_dharma_score': 0.6333333333333333, 'avg_raw_helpfulness_score': 0.5416666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5595833333333333}
2025-05-10 23:50:19,948 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6916666666666668, 'avg_raw_dharma_score': 0.775, 'avg_raw_helpfulness_score': 0.6916666666666665, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7250000000000001}
  warnings.warn(
2025-05-10 23:51:27,482 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5929166666666666, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.7666666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7412083333333334}
2025-05-10 23:51:29,218 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5258333333333334, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.6000000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6044166666666667}
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 15121/24000 [6:07:45<22:52:41,  9.28s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 15122/24000 [6:07:45<16:28:55,  6.68s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 15123/24000 [6:07:46<12:00:19,  4.87s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 15124/24000 [6:07:47<8:52:21,  3.60s/it]  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 15125/24000 [6:07:47<6:40:45,  2.71s/it]                                                         {'loss': 0.0978, 'grad_norm': 7.59375, 'learning_rate': 9.170234627656488e-07, 'kl': 1.8982244020700454, 'clip_ratio/low_mean': 0.00024771058621505897, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.005535154890579482, 'clip_ratio/high_max': 0.009133267777506261, 'clip_ratio/region_mean': 0.005782865448854864, 'num_tokens': 3393328.0, 'completions/mean_length': 316.66668701171875, 'completions/min_length': 164.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.08333333333333337, 'completions/mean_terminated_length': 298.9090881347656, 'completions/min_terminated_length': 164.0, 'completions/max_terminated_length': 491.0, 'rewards/combined_reward_trl/mean': 0.6728124618530273, 'rewards/combined_reward_trl/std': 0.334562748670578, 'reward': 0.6728125810623169, 'reward_std': 0.21718786656856537, 'epoch': 5.04}
2025-05-10 23:52:20,873 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6787500000000001, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.7416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7427916666666667}
2025-05-10 23:52:21,220 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5308333333333333, 'avg_raw_dharma_score': 0.5916666666666667, 'avg_raw_helpfulness_score': 0.525, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5534166666666667}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 23:53:13,268 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7554166666666667, 'avg_raw_dharma_score': 0.8291666666666666, 'avg_raw_helpfulness_score': 0.7916666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7957916666666668}
2025-05-10 23:53:25,485 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7083333333333335, 'avg_raw_dharma_score': 0.8375, 'avg_raw_helpfulness_score': 0.6416666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7400000000000001}
2025-05-10 23:54:13,788 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.53875, 'avg_raw_dharma_score': 0.45416666666666666, 'avg_raw_helpfulness_score': 0.6166666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5282916666666667}
2025-05-10 23:54:16,474 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7137500000000001, 'avg_raw_dharma_score': 0.8583333333333334, 'avg_raw_helpfulness_score': 0.7583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7849583333333334}
2025-05-10 23:55:06,886 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4666666666666666, 'avg_raw_dharma_score': 0.6541666666666667, 'avg_raw_helpfulness_score': 0.5750000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5741666666666666}
2025-05-10 23:55:07,266 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4891666666666666, 'avg_raw_dharma_score': 0.6333333333333333, 'avg_raw_helpfulness_score': 0.5166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5550833333333334}
  warnings.warn(
2025-05-10 23:56:14,449 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5833333333333333, 'avg_raw_dharma_score': 0.8583333333333334, 'avg_raw_helpfulness_score': 0.6583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7158333333333333}
2025-05-10 23:56:14,941 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5377777777777778, 'avg_raw_dharma_score': 0.6833333333333332, 'avg_raw_helpfulness_score': 0.5666666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6046666666666667}
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 15321/24000 [6:12:30<21:15:39,  8.82s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 15322/24000 [6:12:31<15:20:22,  6.36s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 15323/24000 [6:12:32<11:11:46,  4.65s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 15324/24000 [6:12:32<8:17:39,  3.44s/it]  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 15325/24000 [6:12:33<6:15:49,  2.60s/it]                                                         {'loss': 0.2523, 'grad_norm': 6.1875, 'learning_rate': 8.807440817900663e-07, 'kl': 2.4228325859705606, 'clip_ratio/low_mean': 7.563898572698235e-05, 'clip_ratio/low_min': 2.358618580425779e-05, 'clip_ratio/high_mean': 0.012270934371820962, 'clip_ratio/high_max': 0.02211200338245059, 'clip_ratio/region_mean': 0.012346573354443535, 'num_tokens': 3435901.0, 'completions/mean_length': 306.4583435058594, 'completions/min_length': 69.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.08333333333333337, 'completions/mean_terminated_length': 287.7727355957031, 'completions/min_terminated_length': 69.0, 'completions/max_terminated_length': 464.0, 'rewards/combined_reward_trl/mean': 0.6602500081062317, 'rewards/combined_reward_trl/std': 0.2985970079898834, 'reward': 0.6602500677108765, 'reward_std': 0.2986743152141571, 'epoch': 5.11}
2025-05-10 23:57:02,988 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7816666666666667, 'avg_raw_dharma_score': 0.8958333333333334, 'avg_raw_helpfulness_score': 0.775, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8253333333333334}
2025-05-10 23:57:05,772 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6570833333333335, 'avg_raw_dharma_score': 0.5458333333333333, 'avg_raw_helpfulness_score': 0.7000000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6254583333333333}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-10 23:57:57,913 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5345833333333334, 'avg_raw_dharma_score': 0.5416666666666666, 'avg_raw_helpfulness_score': 0.4583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5145416666666667}
2025-05-10 23:58:13,472 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8041666666666666, 'avg_raw_dharma_score': 0.9416666666666668, 'avg_raw_helpfulness_score': 0.8250000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8654166666666666}
2025-05-10 23:59:04,123 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7520833333333335, 'avg_raw_dharma_score': 0.9416666666666668, 'avg_raw_helpfulness_score': 0.8166666666666669, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8472916666666666}
2025-05-10 23:59:05,554 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7316666666666668, 'avg_raw_dharma_score': 0.9, 'avg_raw_helpfulness_score': 0.7833333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8145000000000001}
2025-05-10 23:59:55,967 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7416666666666666, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.7416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8116666666666669}
2025-05-10 23:59:57,151 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4833333333333332, 'avg_raw_dharma_score': 0.6083333333333333, 'avg_raw_helpfulness_score': 0.43333333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5183333333333334}
  warnings.warn(
2025-05-11 00:01:04,189 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.525, 'avg_raw_dharma_score': 0.6916666666666668, 'avg_raw_helpfulness_score': 0.5916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6116666666666667}
2025-05-11 00:01:04,581 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7000000000000001, 'avg_raw_dharma_score': 0.7041666666666666, 'avg_raw_helpfulness_score': 0.7166666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7066666666666667}
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 15521/24000 [6:17:20<20:22:43,  8.65s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 15522/24000 [6:17:21<14:42:41,  6.25s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 15523/24000 [6:17:21<10:44:40,  4.56s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 15524/24000 [6:17:22<7:58:05,  3.38s/it]  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 15525/24000 [6:17:23<6:01:28,  2.56s/it]                                                         {'loss': 0.3842, 'grad_norm': 9.8125, 'learning_rate': 8.448962703344112e-07, 'kl': 2.602907419204712, 'clip_ratio/low_mean': 8.804989163763822e-05, 'clip_ratio/low_min': 2.844950184226036e-05, 'clip_ratio/high_mean': 0.008836570500861854, 'clip_ratio/high_max': 0.016673776539197813, 'clip_ratio/region_mean': 0.00892462038823093, 'num_tokens': 3478459.0, 'completions/mean_length': 314.0, 'completions/min_length': 31.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.08333333333333337, 'completions/mean_terminated_length': 296.0, 'completions/min_terminated_length': 31.0, 'completions/max_terminated_length': 506.0, 'rewards/combined_reward_trl/mean': 0.6591666340827942, 'rewards/combined_reward_trl/std': 0.26349106431007385, 'reward': 0.659166693687439, 'reward_std': 0.19824853539466858, 'epoch': 5.17}
2025-05-11 00:01:58,345 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5083333333333333, 'avg_raw_dharma_score': 0.5625, 'avg_raw_helpfulness_score': 0.525, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5349999999999999}
2025-05-11 00:01:59,477 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5195833333333334, 'avg_raw_dharma_score': 0.7333333333333334, 'avg_raw_helpfulness_score': 0.525, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6067083333333334}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 00:02:54,257 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5499999999999999, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.6666666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6983333333333334}
2025-05-11 00:03:10,017 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.35791666666666666, 'avg_raw_dharma_score': 0.6083333333333333, 'avg_raw_helpfulness_score': 0.4416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.4832083333333334}
2025-05-11 00:03:57,022 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7661111111111111, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.7666666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8431666666666667}
2025-05-11 00:04:03,893 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6845833333333333, 'avg_raw_dharma_score': 0.8166666666666668, 'avg_raw_helpfulness_score': 0.7416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7545416666666668}
2025-05-11 00:04:54,610 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6541666666666667, 'avg_raw_dharma_score': 0.8125, 'avg_raw_helpfulness_score': 0.6916666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7287499999999999}
2025-05-11 00:04:55,389 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.775, 'avg_raw_dharma_score': 0.9833333333333334, 'avg_raw_helpfulness_score': 0.8416666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8783333333333333}
  warnings.warn(
2025-05-11 00:05:58,663 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6704166666666667, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.7000000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7444583333333333}
2025-05-11 00:06:01,093 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6354166666666666, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.6750000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.743125}
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 15721/24000 [6:22:17<19:11:46,  8.35s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 15722/24000 [6:22:17<13:52:17,  6.03s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 15723/24000 [6:22:18<10:08:32,  4.41s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 15724/24000 [6:22:18<7:32:04,  3.28s/it]  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 15725/24000 [6:22:19<5:42:27,  2.48s/it]                                                         {'loss': 0.0785, 'grad_norm': 15.8125, 'learning_rate': 8.095050113214553e-07, 'kl': 1.2755470526218415, 'clip_ratio/low_mean': 0.007688577622951318, 'clip_ratio/low_min': 0.001196990478783846, 'clip_ratio/high_mean': 0.004275407509412616, 'clip_ratio/high_max': 0.006319600553251803, 'clip_ratio/region_mean': 0.01196398498257622, 'num_tokens': 3519286.0, 'completions/mean_length': 319.3333435058594, 'completions/min_length': 54.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.04166666666666663, 'completions/mean_terminated_length': 310.9565124511719, 'completions/min_terminated_length': 54.0, 'completions/max_terminated_length': 454.0, 'rewards/combined_reward_trl/mean': 0.7437916398048401, 'rewards/combined_reward_trl/std': 0.23241892457008362, 'reward': 0.7437916994094849, 'reward_std': 0.23210477828979492, 'epoch': 5.24}
2025-05-11 00:06:53,997 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6749999999999999, 'avg_raw_dharma_score': 0.7625000000000001, 'avg_raw_helpfulness_score': 0.6916666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.715}
2025-05-11 00:06:55,489 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5541666666666667, 'avg_raw_dharma_score': 0.6749999999999999, 'avg_raw_helpfulness_score': 0.5916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.61375}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 00:07:46,262 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6291666666666665, 'avg_raw_dharma_score': 0.7541666666666668, 'avg_raw_helpfulness_score': 0.6750000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6929166666666667}
2025-05-11 00:08:01,593 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5595833333333334, 'avg_raw_dharma_score': 0.525, 'avg_raw_helpfulness_score': 0.5916666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.555375}
2025-05-11 00:08:52,215 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7083333333333334, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.7416666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7516666666666668}
2025-05-11 00:08:56,287 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6000000000000001, 'avg_raw_dharma_score': 0.6916666666666668, 'avg_raw_helpfulness_score': 0.6, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6366666666666666}
2025-05-11 00:09:45,598 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7958333333333333, 'avg_raw_dharma_score': 0.9833333333333334, 'avg_raw_helpfulness_score': 0.8500000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8870833333333334}
2025-05-11 00:09:48,556 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7233333333333333, 'avg_raw_dharma_score': 0.9083333333333333, 'avg_raw_helpfulness_score': 0.775, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8128333333333334}
  warnings.warn(
2025-05-11 00:10:54,269 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5208333333333334, 'avg_raw_dharma_score': 0.5416666666666666, 'avg_raw_helpfulness_score': 0.6750000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5754166666666667}
2025-05-11 00:10:54,535 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.43569444444444444, 'avg_raw_dharma_score': 0.425, 'avg_raw_helpfulness_score': 0.4666666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.4407083333333333}
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 15921/24000 [6:27:10<20:03:21,  8.94s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 15922/24000 [6:27:11<14:28:01,  6.45s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 15923/24000 [6:27:11<10:33:24,  4.71s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 15924/24000 [6:27:12<7:49:02,  3.48s/it]  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 15925/24000 [6:27:13<5:54:03,  2.63s/it]                                                         {'loss': 0.1084, 'grad_norm': 11.9375, 'learning_rate': 7.745949694951473e-07, 'kl': 0.963780262072881, 'clip_ratio/low_mean': 0.0038607281500784058, 'clip_ratio/low_min': 0.002093704806175083, 'clip_ratio/high_mean': 0.004281367988248045, 'clip_ratio/high_max': 0.0065601954841986295, 'clip_ratio/region_mean': 0.008142096139102554, 'num_tokens': 3563956.0, 'completions/mean_length': 331.54168701171875, 'completions/min_length': 1.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 271.3888854980469, 'completions/min_terminated_length': 1.0, 'completions/max_terminated_length': 450.0, 'rewards/combined_reward_trl/mean': 0.5080625414848328, 'rewards/combined_reward_trl/std': 0.327608197927475, 'reward': 0.5080625414848328, 'reward_std': 0.25759896636009216, 'epoch': 5.31}
2025-05-11 00:11:48,876 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5583333333333335, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.5500000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5991666666666667}
2025-05-11 00:11:49,418 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6201388888888889, 'avg_raw_dharma_score': 0.5666666666666667, 'avg_raw_helpfulness_score': 0.6750000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6152083333333334}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 00:12:46,007 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5729166666666666, 'avg_raw_dharma_score': 0.7083333333333334, 'avg_raw_helpfulness_score': 0.5333333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6152083333333334}
2025-05-11 00:12:55,284 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4916666666666667, 'avg_raw_dharma_score': 0.5, 'avg_raw_helpfulness_score': 0.5, 'avg_penalty': 0.0, 'avg_combined_reward': 0.4975}
2025-05-11 00:13:47,506 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6416666666666667, 'avg_raw_dharma_score': 0.6083333333333333, 'avg_raw_helpfulness_score': 0.6583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6333333333333332}
2025-05-11 00:13:48,309 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6691666666666668, 'avg_raw_dharma_score': 0.8416666666666667, 'avg_raw_helpfulness_score': 0.65, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7324166666666666}
2025-05-11 00:14:40,145 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4208333333333334, 'avg_raw_dharma_score': 0.27499999999999997, 'avg_raw_helpfulness_score': 0.5333333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.39625}
2025-05-11 00:14:41,399 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5708333333333334, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.6916666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7120833333333333}
  warnings.warn(
2025-05-11 00:15:49,847 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5770833333333334, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.6333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.663125}
2025-05-11 00:15:51,015 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5279166666666667, 'avg_raw_dharma_score': 0.6916666666666668, 'avg_raw_helpfulness_score': 0.5583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6025416666666666}
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 16121/24000 [6:32:07<20:50:50,  9.53s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 16122/24000 [6:32:07<15:00:23,  6.86s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 16123/24000 [6:32:08<10:55:05,  4.99s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 16124/24000 [6:32:08<8:03:25,  3.68s/it]  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 16125/24000 [6:32:09<6:03:15,  2.77s/it]                                                         {'loss': 0.3128, 'grad_norm': 22.75, 'learning_rate': 7.401904742313551e-07, 'kl': 2.941035494804382, 'clip_ratio/low_mean': 0.009655731421274443, 'clip_ratio/low_min': 8.714597206562758e-06, 'clip_ratio/high_mean': 0.001724639596650377, 'clip_ratio/high_max': 0.002572343044448644, 'clip_ratio/region_mean': 0.01138037100705939, 'num_tokens': 3606209.0, 'completions/mean_length': 307.625, 'completions/min_length': 18.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.20833333333333337, 'completions/mean_terminated_length': 253.84210205078125, 'completions/min_terminated_length': 18.0, 'completions/max_terminated_length': 444.0, 'rewards/combined_reward_trl/mean': 0.6328333020210266, 'rewards/combined_reward_trl/std': 0.3162739872932434, 'reward': 0.6328333616256714, 'reward_std': 0.3309829831123352, 'epoch': 5.38}
2025-05-11 00:16:41,004 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7333333333333334, 'avg_raw_dharma_score': 0.8125, 'avg_raw_helpfulness_score': 0.7916666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7825000000000001}
2025-05-11 00:16:43,206 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8041666666666667, 'avg_raw_dharma_score': 0.9416666666666668, 'avg_raw_helpfulness_score': 0.8750000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8804166666666667}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 00:17:34,605 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7179166666666666, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.775, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8145416666666668}
2025-05-11 00:17:52,618 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6152777777777777, 'avg_raw_dharma_score': 0.6333333333333333, 'avg_raw_helpfulness_score': 0.5666666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6079166666666667}
2025-05-11 00:18:40,146 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6483333333333333, 'avg_raw_dharma_score': 0.85, 'avg_raw_helpfulness_score': 0.7999999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7745000000000001}
2025-05-11 00:18:47,504 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.3916666666666668, 'avg_raw_dharma_score': 0.5791666666666667, 'avg_raw_helpfulness_score': 0.5166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5041666666666668}
2025-05-11 00:19:40,272 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5708333333333334, 'avg_raw_dharma_score': 0.6583333333333333, 'avg_raw_helpfulness_score': 0.6166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6195833333333333}
2025-05-11 00:19:40,864 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5845833333333333, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.6166666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6603749999999999}
  warnings.warn(
2025-05-11 00:20:46,681 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8125, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.8916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8945833333333333}
2025-05-11 00:20:47,300 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6458333333333334, 'avg_raw_dharma_score': 0.8125, 'avg_raw_helpfulness_score': 0.6833333333333332, 'avg_penalty': 0.0, 'avg_combined_reward': 0.72375}
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 16321/24000 [6:37:03<18:21:33,  8.61s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 16322/24000 [6:37:03<13:15:28,  6.22s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 16323/24000 [6:37:04<9:41:14,  4.54s/it]  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 16324/24000 [6:37:05<7:11:14,  3.37s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 16325/24000 [6:37:05<5:26:16,  2.55s/it]                                                         {'loss': 0.2353, 'grad_norm': 11.375, 'learning_rate': 7.063155025823224e-07, 'kl': 2.464888385931651, 'clip_ratio/low_mean': 8.980695779124895e-05, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0031270533722514908, 'clip_ratio/high_max': 0.0050610235015240805, 'clip_ratio/region_mean': 0.00321686031219239, 'num_tokens': 3648491.0, 'completions/mean_length': 321.25, 'completions/min_length': 108.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.08333333333333337, 'completions/mean_terminated_length': 303.9090881347656, 'completions/min_terminated_length': 108.0, 'completions/max_terminated_length': 461.0, 'rewards/combined_reward_trl/mean': 0.809166669845581, 'rewards/combined_reward_trl/std': 0.24715456366539001, 'reward': 0.8091667890548706, 'reward_std': 0.21156427264213562, 'epoch': 5.44}
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 16325/24000 [6:37:05<5:26:16,  2.55s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 16326/24000 [6:37:06<4:12:58,  1.98s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 16327/24000 [6:37:07<3:21:29,  1.58s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 16328/24000 [6:37:07<2:45:28,  1.29s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 16329/24000 [6:37:08<2:20:13,  1.10s/it]wandb: WARNING Tried to log to step 16325 that is less than the current step 148804. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-11 00:21:38,536 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6458333333333334, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.7083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6729166666666667}
2025-05-11 00:21:39,210 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4291666666666667, 'avg_raw_dharma_score': 0.5750000000000001, 'avg_raw_helpfulness_score': 0.3833333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.47375000000000006}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 00:22:29,982 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7708333333333334, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.8416666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8504166666666665}
2025-05-11 00:22:43,152 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7891666666666669, 'avg_raw_dharma_score': 0.9416666666666668, 'avg_raw_helpfulness_score': 0.8666666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8734166666666666}
2025-05-11 00:23:35,036 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6659722222222223, 'avg_raw_dharma_score': 0.7583333333333333, 'avg_raw_helpfulness_score': 0.65, 'avg_penalty': 0.0, 'avg_combined_reward': 0.698125}
2025-05-11 00:23:35,703 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7041666666666667, 'avg_raw_dharma_score': 0.6625, 'avg_raw_helpfulness_score': 0.65, 'avg_penalty': 0.0, 'avg_combined_reward': 0.67125}
2025-05-11 00:24:27,145 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8516666666666669, 'avg_raw_dharma_score': 0.775, 'avg_raw_helpfulness_score': 0.7666666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7955}
2025-05-11 00:24:31,740 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4333333333333333, 'avg_raw_dharma_score': 0.525, 'avg_raw_helpfulness_score': 0.40833333333333327, 'avg_penalty': 0.0, 'avg_combined_reward': 0.46249999999999997}
  warnings.warn(
2025-05-11 00:25:36,701 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6749999999999999, 'avg_raw_dharma_score': 0.65, 'avg_raw_helpfulness_score': 0.625, 'avg_penalty': 0.0, 'avg_combined_reward': 0.65}
2025-05-11 00:25:38,082 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5708333333333333, 'avg_raw_dharma_score': 0.7708333333333334, 'avg_raw_helpfulness_score': 0.6749999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6820833333333334}
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 16521/24000 [6:41:54<18:45:26,  9.03s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 16522/24000 [6:41:54<13:31:20,  6.51s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 16523/24000 [6:41:55<9:51:30,  4.75s/it]  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 16524/24000 [6:41:55<7:17:36,  3.51s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 16525/24000 [6:41:56<5:29:54,  2.65s/it]                                                         {'loss': 0.3508, 'grad_norm': 11.375, 'learning_rate': 6.729936625666768e-07, 'kl': 2.834952826499939, 'clip_ratio/low_mean': 0.00021848542615771294, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0015014451191139718, 'clip_ratio/high_max': 0.002492756723271062, 'clip_ratio/region_mean': 0.0017199305382867654, 'num_tokens': 3692497.0, 'completions/mean_length': 368.54168701171875, 'completions/min_length': 174.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.20833333333333337, 'completions/mean_terminated_length': 330.78948974609375, 'completions/min_terminated_length': 174.0, 'completions/max_terminated_length': 461.0, 'rewards/combined_reward_trl/mean': 0.6660416722297668, 'rewards/combined_reward_trl/std': 0.24926403164863586, 'reward': 0.6660416722297668, 'reward_std': 0.24184775352478027, 'epoch': 5.51}
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 16525/24000 [6:41:56<5:29:54,  2.65s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 16526/24000 [6:41:57<4:14:42,  2.04s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 16527/24000 [6:41:57<3:21:55,  1.62s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 16528/24000 [6:41:58<2:44:58,  1.32s/it]wandb: WARNING Tried to log to step 16525 that is less than the current step 150627. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-11 00:26:31,679 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6986111111111112, 'avg_raw_dharma_score': 0.8083333333333332, 'avg_raw_helpfulness_score': 0.6499999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7279166666666667}
2025-05-11 00:26:31,832 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.71875, 'avg_raw_dharma_score': 0.7208333333333333, 'avg_raw_helpfulness_score': 0.7666666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7339583333333334}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 00:27:24,794 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7198611111111113, 'avg_raw_dharma_score': 0.7291666666666666, 'avg_raw_helpfulness_score': 0.65, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7026249999999999}
2025-05-11 00:27:38,295 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5875, 'avg_raw_dharma_score': 0.7166666666666667, 'avg_raw_helpfulness_score': 0.7083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6754166666666669}
2025-05-11 00:28:30,155 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5333333333333333, 'avg_raw_dharma_score': 0.5333333333333333, 'avg_raw_helpfulness_score': 0.6, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5533333333333333}
2025-05-11 00:28:30,429 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5083333333333333, 'avg_raw_dharma_score': 0.6749999999999999, 'avg_raw_helpfulness_score': 0.5666666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5925000000000001}
2025-05-11 00:29:21,329 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4845833333333334, 'avg_raw_dharma_score': 0.6708333333333334, 'avg_raw_helpfulness_score': 0.5416666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5762083333333333}
2025-05-11 00:29:23,191 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6145833333333334, 'avg_raw_dharma_score': 0.7833333333333332, 'avg_raw_helpfulness_score': 0.6083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6802083333333333}
  warnings.warn(
2025-05-11 00:30:23,213 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7416666666666666, 'avg_raw_dharma_score': 0.7999999999999999, 'avg_raw_helpfulness_score': 0.725, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7599999999999999}
2025-05-11 00:30:29,971 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5124999999999998, 'avg_raw_dharma_score': 0.5833333333333334, 'avg_raw_helpfulness_score': 0.5416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5495833333333332}
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 16721/24000 [6:46:45<18:22:13,  9.09s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 16722/24000 [6:46:46<13:12:51,  6.54s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 16723/24000 [6:46:47<9:36:17,  4.75s/it]  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 16724/24000 [6:46:47<7:04:59,  3.50s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 16725/24000 [6:46:48<5:18:51,  2.63s/it]                                                         {'loss': 0.373, 'grad_norm': 9.6875, 'learning_rate': 6.402481767166169e-07, 'kl': 3.3939037783940633, 'clip_ratio/low_mean': 0.00019341807657231888, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0031995975594812385, 'clip_ratio/high_max': 0.004968551561857263, 'clip_ratio/region_mean': 0.003393015636053557, 'num_tokens': 3734329.0, 'completions/mean_length': 244.5416717529297, 'completions/min_length': 4.0, 'completions/max_length': 473.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 244.5416717529297, 'completions/min_terminated_length': 4.0, 'completions/max_terminated_length': 473.0, 'rewards/combined_reward_trl/mean': 0.6547916531562805, 'rewards/combined_reward_trl/std': 0.3549692928791046, 'reward': 0.6547917127609253, 'reward_std': 0.3006249666213989, 'epoch': 5.58}
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 16725/24000 [6:46:48<5:18:51,  2.63s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 16726/24000 [6:46:48<4:04:45,  2.02s/it]wandb: WARNING Tried to log to step 16725 that is less than the current step 152450. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-11 00:31:18,489 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7291666666666666, 'avg_raw_dharma_score': 0.8166666666666668, 'avg_raw_helpfulness_score': 0.7416666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7679166666666668}
2025-05-11 00:31:24,547 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4962500000000001, 'avg_raw_dharma_score': 0.7333333333333334, 'avg_raw_helpfulness_score': 0.5583333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6097083333333333}
                                                         {'loss': 0.0944, 'grad_norm': 10.25, 'learning_rate': 6.321545439663054e-07, 'kl': 1.9018347652753194, 'clip_ratio/low_mean': 0.00024066218989901244, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0014024700934533029, 'clip_ratio/high_max': 0.002284824972351392, 'clip_ratio/region_mean': 0.001643132286456724, 'num_tokens': 3741935.0, 'completions/mean_length': 281.41668701171875, 'completions/min_length': 1.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.08333333333333337, 'completions/mean_terminated_length': 260.4545593261719, 'completions/min_terminated_length': 1.0, 'completions/max_terminated_length': 462.0, 'rewards/combined_reward_trl/mean': 0.6888124942779541, 'rewards/combined_reward_trl/std': 0.29765596985816956, 'reward': 0.6888126134872437, 'reward_std': 0.27095484733581543, 'epoch': 5.59}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 00:32:15,384 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8638888888888888, 'avg_raw_dharma_score': 0.8916666666666667, 'avg_raw_helpfulness_score': 0.7666666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8458333333333335}
2025-05-11 00:32:32,067 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.37500000000000006, 'avg_raw_dharma_score': 0.5666666666666667, 'avg_raw_helpfulness_score': 0.4333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.4691666666666667}
2025-05-11 00:33:24,379 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4916666666666667, 'avg_raw_dharma_score': 0.775, 'avg_raw_helpfulness_score': 0.6250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.645}
2025-05-11 00:33:25,045 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4141666666666666, 'avg_raw_dharma_score': 0.5916666666666667, 'avg_raw_helpfulness_score': 0.4333333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.49091666666666667}
2025-05-11 00:34:11,204 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6091666666666666, 'avg_raw_dharma_score': 0.8125, 'avg_raw_helpfulness_score': 0.7166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.72275}
2025-05-11 00:34:17,958 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6870833333333333, 'avg_raw_dharma_score': 0.775, 'avg_raw_helpfulness_score': 0.6416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.708625}
  warnings.warn(
2025-05-11 00:35:22,390 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7295833333333334, 'avg_raw_dharma_score': 0.7958333333333333, 'avg_raw_helpfulness_score': 0.8416666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7897083333333333}
2025-05-11 00:35:23,095 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7320833333333333, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.7083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7654583333333335}
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 16921/24000 [6:51:39<17:20:29,  8.82s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 16922/24000 [6:51:39<12:30:39,  6.36s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 16923/24000 [6:51:40<9:07:47,  4.64s/it]  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 16924/24000 [6:51:40<6:45:50,  3.44s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 16925/24000 [6:51:41<5:06:31,  2.60s/it]                                                         {'loss': 0.165, 'grad_norm': 14.4375, 'learning_rate': 6.081018658937466e-07, 'kl': 1.2931612036625544, 'clip_ratio/low_mean': 0.000154572994603465, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.001473431756021455, 'clip_ratio/high_max': 0.0021859631850384177, 'clip_ratio/region_mean': 0.0016280047413116943, 'num_tokens': 3778135.0, 'completions/mean_length': 371.9583435058594, 'completions/min_length': 128.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 325.27777099609375, 'completions/min_terminated_length': 128.0, 'completions/max_terminated_length': 479.0, 'rewards/combined_reward_trl/mean': 0.7775833606719971, 'rewards/combined_reward_trl/std': 0.2170165628194809, 'reward': 0.7775834798812866, 'reward_std': 0.19833943247795105, 'epoch': 5.64}
2025-05-11 00:36:15,922 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5766666666666667, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.6666666666666669, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6396666666666667}
2025-05-11 00:36:16,526 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5458333333333334, 'avg_raw_dharma_score': 0.7333333333333334, 'avg_raw_helpfulness_score': 0.5833333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6320833333333334}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 00:37:09,273 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.65125, 'avg_raw_dharma_score': 0.85, 'avg_raw_helpfulness_score': 0.7000000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.745375}
2025-05-11 00:37:23,263 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5733333333333333, 'avg_raw_dharma_score': 0.625, 'avg_raw_helpfulness_score': 0.5750000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5944999999999999}
2025-05-11 00:38:11,389 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5375, 'avg_raw_dharma_score': 0.7083333333333334, 'avg_raw_helpfulness_score': 0.625, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6320833333333334}
2025-05-11 00:38:16,332 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5475, 'avg_raw_dharma_score': 0.7666666666666666, 'avg_raw_helpfulness_score': 0.6083333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6534166666666666}
2025-05-11 00:39:08,170 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5395833333333334, 'avg_raw_dharma_score': 0.7083333333333334, 'avg_raw_helpfulness_score': 0.5833333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6202083333333333}
2025-05-11 00:39:08,680 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.75, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.7916666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8291666666666669}
  warnings.warn(
2025-05-11 00:40:14,588 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5291666666666667, 'avg_raw_dharma_score': 0.5833333333333334, 'avg_raw_helpfulness_score': 0.6666666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5920833333333334}
2025-05-11 00:40:15,051 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6708333333333333, 'avg_raw_dharma_score': 0.6875, 'avg_raw_helpfulness_score': 0.7416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.69875}
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 17121/24000 [6:56:31<16:11:17,  8.47s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 17122/24000 [6:56:31<11:41:31,  6.12s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 17123/24000 [6:56:32<8:32:44,  4.47s/it]  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 17124/24000 [6:56:32<6:20:34,  3.32s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 17125/24000 [6:56:33<4:48:04,  2.51s/it]                                                         {'loss': 0.0861, 'grad_norm': 12.1875, 'learning_rate': 5.76577133384852e-07, 'kl': 1.458686300913493, 'clip_ratio/low_mean': 0.00021994372907405097, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.002107190394308418, 'clip_ratio/high_max': 0.0033485108567401765, 'clip_ratio/region_mean': 0.0023271341202780603, 'num_tokens': 3822523.0, 'completions/mean_length': 339.16668701171875, 'completions/min_length': 131.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.08333333333333337, 'completions/mean_terminated_length': 323.4545593261719, 'completions/min_terminated_length': 131.0, 'completions/max_terminated_length': 482.0, 'rewards/combined_reward_trl/mean': 0.6454166769981384, 'rewards/combined_reward_trl/std': 0.24001774191856384, 'reward': 0.6454167366027832, 'reward_std': 0.17189458012580872, 'epoch': 5.71}
2025-05-11 00:41:05,768 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6145833333333334, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.7416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7235416666666667}
2025-05-11 00:41:06,791 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5083333333333333, 'avg_raw_dharma_score': 0.65, 'avg_raw_helpfulness_score': 0.5833333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5875000000000001}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 00:41:56,291 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5345833333333333, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.6749999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.662875}
2025-05-11 00:42:14,165 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5625, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.6750000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6879166666666667}
2025-05-11 00:43:06,201 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7666666666666666, 'avg_raw_dharma_score': 0.8208333333333334, 'avg_raw_helpfulness_score': 0.75, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7833333333333332}
2025-05-11 00:43:06,382 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5425, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.5916666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6069166666666667}
2025-05-11 00:43:57,652 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.45125, 'avg_raw_dharma_score': 0.5583333333333333, 'avg_raw_helpfulness_score': 0.43333333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.48870833333333347}
2025-05-11 00:43:58,250 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5625, 'avg_raw_dharma_score': 0.725, 'avg_raw_helpfulness_score': 0.525, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6162500000000001}
  warnings.warn(
2025-05-11 00:45:02,749 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.3875, 'avg_raw_dharma_score': 0.5916666666666667, 'avg_raw_helpfulness_score': 0.4833333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.49791666666666673}
2025-05-11 00:45:03,718 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5558333333333333, 'avg_raw_dharma_score': 0.7333333333333334, 'avg_raw_helpfulness_score': 0.5416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6225833333333333}
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 17321/24000 [7:01:19<16:11:22,  8.73s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 17322/24000 [7:01:20<11:41:17,  6.30s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 17323/24000 [7:01:21<8:32:04,  4.60s/it]  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 17324/24000 [7:01:21<6:19:37,  3.41s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 17325/24000 [7:01:22<4:46:55,  2.58s/it]                                                         {'loss': 0.3217, 'grad_norm': 12.3125, 'learning_rate': 5.456959492886835e-07, 'kl': 3.338077520529429, 'clip_ratio/low_mean': 3.885875572450459e-05, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0010025744966696947, 'clip_ratio/high_max': 0.0015433594033432503, 'clip_ratio/region_mean': 0.001041433250841995, 'num_tokens': 3866567.0, 'completions/mean_length': 330.9583435058594, 'completions/min_length': 7.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 305.0952453613281, 'completions/min_terminated_length': 7.0, 'completions/max_terminated_length': 462.0, 'rewards/combined_reward_trl/mean': 0.5602499842643738, 'rewards/combined_reward_trl/std': 0.3256269097328186, 'reward': 0.5602500438690186, 'reward_std': 0.3398270606994629, 'epoch': 5.78}
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 17325/24000 [7:01:22<4:46:55,  2.58s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 17326/24000 [7:01:22<3:42:13,  2.00s/it]wandb: WARNING Tried to log to step 17325 that is less than the current step 157919. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-11 00:45:48,898 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6291666666666667, 'avg_raw_dharma_score': 0.9, 'avg_raw_helpfulness_score': 0.6916666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7562500000000001}
2025-05-11 00:45:56,693 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4166666666666667, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.5333333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5516666666666666}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 00:46:48,496 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7333333333333334, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.7416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7091666666666666}
2025-05-11 00:47:01,838 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6500000000000001, 'avg_raw_dharma_score': 0.8166666666666668, 'avg_raw_helpfulness_score': 0.6833333333333332, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7266666666666667}
2025-05-11 00:47:53,749 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8041666666666666, 'avg_raw_dharma_score': 0.9416666666666668, 'avg_raw_helpfulness_score': 0.8083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8604166666666667}
2025-05-11 00:47:56,536 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6041666666666667, 'avg_raw_dharma_score': 0.6291666666666667, 'avg_raw_helpfulness_score': 0.6083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6154166666666667}
2025-05-11 00:48:49,120 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8083333333333332, 'avg_raw_dharma_score': 0.9083333333333333, 'avg_raw_helpfulness_score': 0.8166666666666669, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8508333333333334}
2025-05-11 00:48:49,328 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.525, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.6, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6375000000000001}
  warnings.warn(
2025-05-11 00:49:54,733 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6604166666666668, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.6416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7406250000000001}
2025-05-11 00:49:55,757 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8125, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.7333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7970833333333333}
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 17521/24000 [7:06:11<16:12:45,  9.01s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 17522/24000 [7:06:12<11:41:18,  6.50s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 17523/24000 [7:06:13<8:31:19,  4.74s/it]  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 17524/24000 [7:06:13<6:18:21,  3.51s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 17525/24000 [7:06:14<4:45:17,  2.64s/it]                                                         {'loss': 0.2979, 'grad_norm': 8.875, 'learning_rate': 5.154798352046367e-07, 'kl': 2.3861486128966014, 'clip_ratio/low_mean': 1.6130474007998904e-05, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.001753313890658319, 'clip_ratio/high_max': 0.0028044017901023227, 'clip_ratio/region_mean': 0.0017694443666065732, 'num_tokens': 3909177.0, 'completions/mean_length': 319.79168701171875, 'completions/min_length': 1.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.16666666666666663, 'completions/mean_terminated_length': 281.3500061035156, 'completions/min_terminated_length': 1.0, 'completions/max_terminated_length': 492.0, 'rewards/combined_reward_trl/mean': 0.7688541412353516, 'rewards/combined_reward_trl/std': 0.2741924822330475, 'reward': 0.7688541412353516, 'reward_std': 0.2757965922355652, 'epoch': 5.84}
2025-05-11 00:50:50,420 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6316666666666667, 'avg_raw_dharma_score': 0.7958333333333334, 'avg_raw_helpfulness_score': 0.6583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7053333333333333}
2025-05-11 00:50:53,526 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5762499999999999, 'avg_raw_dharma_score': 0.6083333333333333, 'avg_raw_helpfulness_score': 0.6, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5962083333333333}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 00:51:45,484 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5916666666666667, 'avg_raw_dharma_score': 0.7999999999999999, 'avg_raw_helpfulness_score': 0.65, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6925}
2025-05-11 00:51:58,251 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.58625, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.5916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6700416666666668}
2025-05-11 00:52:47,357 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8270833333333334, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.8916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.9156249999999999}
2025-05-11 00:52:52,251 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6262500000000001, 'avg_raw_dharma_score': 0.8583333333333334, 'avg_raw_helpfulness_score': 0.65, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7262083333333335}
2025-05-11 00:53:38,276 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6458333333333334, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.7583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7545833333333335}
2025-05-11 00:53:45,442 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5416666666666667, 'avg_raw_dharma_score': 0.7333333333333334, 'avg_raw_helpfulness_score': 0.6666666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6558333333333334}
  warnings.warn(
2025-05-11 00:54:49,706 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6241666666666668, 'avg_raw_dharma_score': 0.6375000000000001, 'avg_raw_helpfulness_score': 0.5666666666666665, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6122500000000001}
2025-05-11 00:54:52,236 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5625, 'avg_raw_dharma_score': 0.7625000000000001, 'avg_raw_helpfulness_score': 0.5333333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.63375}
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 17721/24000 [7:11:08<16:00:57,  9.18s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 17722/24000 [7:11:08<11:32:25,  6.62s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 17723/24000 [7:11:09<8:24:28,  4.82s/it]  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 17724/24000 [7:11:10<6:12:55,  3.57s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 17725/24000 [7:11:10<4:40:51,  2.69s/it]                                                         {'loss': 0.2008, 'grad_norm': 9.5, 'learning_rate': 4.859498492340008e-07, 'kl': 2.1014546608924864, 'clip_ratio/low_mean': 9.842519648373127e-05, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.001253372262775277, 'clip_ratio/high_max': 0.0018165913495856026, 'clip_ratio/region_mean': 0.0013517974600351106, 'num_tokens': 3950756.0, 'completions/mean_length': 326.66668701171875, 'completions/min_length': 15.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.20833333333333337, 'completions/mean_terminated_length': 277.8947448730469, 'completions/min_terminated_length': 15.0, 'completions/max_terminated_length': 431.0, 'rewards/combined_reward_trl/mean': 0.6229999661445618, 'rewards/combined_reward_trl/std': 0.2497100979089737, 'reward': 0.6230000257492065, 'reward_std': 0.25977492332458496, 'epoch': 5.91}
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 17725/24000 [7:11:10<4:40:51,  2.69s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 17726/24000 [7:11:11<3:36:34,  2.07s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 17727/24000 [7:11:12<2:51:24,  1.64s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 17728/24000 [7:11:12<2:19:48,  1.34s/it]wandb: WARNING Tried to log to step 17725 that is less than the current step 161565. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-11 00:55:42,926 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.48125, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.5416666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5735416666666667}
2025-05-11 00:55:45,187 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4708333333333334, 'avg_raw_dharma_score': 0.6083333333333333, 'avg_raw_helpfulness_score': 0.5333333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5445833333333334}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 00:56:37,193 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6416666666666666, 'avg_raw_dharma_score': 0.8166666666666668, 'avg_raw_helpfulness_score': 0.7083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7316666666666668}
2025-05-11 00:56:50,081 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6191666666666668, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.6166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7207499999999999}
2025-05-11 00:57:36,693 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6875, 'avg_raw_dharma_score': 0.8166666666666668, 'avg_raw_helpfulness_score': 0.7750000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7654166666666667}
2025-05-11 00:57:44,196 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5791666666666666, 'avg_raw_dharma_score': 0.575, 'avg_raw_helpfulness_score': 0.5166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.55875}
2025-05-11 00:58:34,957 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6166666666666667, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.5416666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6808333333333333}
2025-05-11 00:58:36,739 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7123611111111113, 'avg_raw_dharma_score': 0.8833333333333333, 'avg_raw_helpfulness_score': 0.75, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7920416666666666}
  warnings.warn(
2025-05-11 00:59:43,403 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4791666666666667, 'avg_raw_dharma_score': 0.5666666666666667, 'avg_raw_helpfulness_score': 0.5083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5229166666666666}
2025-05-11 00:59:43,791 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5283333333333334, 'avg_raw_dharma_score': 0.625, 'avg_raw_helpfulness_score': 0.525, 'avg_penalty': 0.0, 'avg_combined_reward': 0.566}
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 17921/24000 [7:15:59<14:37:12,  8.66s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 17922/24000 [7:16:00<10:33:04,  6.25s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 17923/24000 [7:16:01<7:42:12,  4.56s/it]  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 17924/24000 [7:16:01<5:42:37,  3.38s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 17925/24000 [7:16:02<4:18:55,  2.56s/it]                                                         {'loss': 0.166, 'grad_norm': 14.1875, 'learning_rate': 4.57126571304223e-07, 'kl': 1.9479093988736471, 'clip_ratio/low_mean': 0.00040567095507867637, 'clip_ratio/low_min': 1.95954879745841e-05, 'clip_ratio/high_mean': 0.001708099232443298, 'clip_ratio/high_max': 0.002391025018102179, 'clip_ratio/region_mean': 0.0021137701941188426, 'num_tokens': 3992373.0, 'completions/mean_length': 328.54168701171875, 'completions/min_length': 22.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 302.3333435058594, 'completions/min_terminated_length': 22.0, 'completions/max_terminated_length': 497.0, 'rewards/combined_reward_trl/mean': 0.5444583296775818, 'rewards/combined_reward_trl/std': 0.39199569821357727, 'reward': 0.5444583892822266, 'reward_std': 0.30656591057777405, 'epoch': 5.97}
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 17925/24000 [7:16:02<4:18:55,  2.56s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 17926/24000 [7:16:02<3:20:29,  1.98s/it]wandb: WARNING Tried to log to step 17925 that is less than the current step 163388. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-11 01:00:35,871 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6390277777777778, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.6, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6717083333333335}
2025-05-11 01:00:38,281 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7083333333333334, 'avg_raw_dharma_score': 0.8583333333333334, 'avg_raw_helpfulness_score': 0.775, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7883333333333334}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 01:01:34,391 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6320833333333334, 'avg_raw_dharma_score': 0.7333333333333334, 'avg_raw_helpfulness_score': 0.6083333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6654583333333333}
2025-05-11 01:01:43,760 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5991666666666665, 'avg_raw_dharma_score': 0.47500000000000003, 'avg_raw_helpfulness_score': 0.6333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.55975}
2025-05-11 01:02:36,408 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6368055555555556, 'avg_raw_dharma_score': 0.65, 'avg_raw_helpfulness_score': 0.6083333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6335416666666667}
2025-05-11 01:02:36,762 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7033333333333335, 'avg_raw_dharma_score': 0.8416666666666667, 'avg_raw_helpfulness_score': 0.7083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7601666666666668}
2025-05-11 01:03:31,146 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7158333333333333, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.7583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7922500000000001}
2025-05-11 01:03:31,241 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5937499999999999, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.6750000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7139583333333334}
  warnings.warn(
2025-05-11 01:04:35,964 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6429166666666667, 'avg_raw_dharma_score': 0.7291666666666666, 'avg_raw_helpfulness_score': 0.7333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7045416666666666}
2025-05-11 01:04:37,413 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6300000000000001, 'avg_raw_dharma_score': 0.7999999999999999, 'avg_raw_helpfulness_score': 0.55, 'avg_penalty': 0.0, 'avg_combined_reward': 0.674}
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 18121/24000 [7:20:53<14:38:29,  8.97s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 18122/24000 [7:20:54<10:33:32,  6.47s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 18123/24000 [7:20:54<7:42:04,  4.72s/it]  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 18124/24000 [7:20:55<5:42:04,  3.49s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 18125/24000 [7:20:55<4:18:04,  2.64s/it]                                                         {'loss': 0.2854, 'grad_norm': 9.3125, 'learning_rate': 4.2903008882642715e-07, 'kl': 2.4437259666124977, 'clip_ratio/low_mean': 8.0612658833464e-06, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0009743973131602009, 'clip_ratio/high_max': 0.0015474892112736901, 'clip_ratio/region_mean': 0.0009824585790435473, 'num_tokens': 4034379.0, 'completions/mean_length': 299.66668701171875, 'completions/min_length': 1.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.08333333333333337, 'completions/mean_terminated_length': 280.3636474609375, 'completions/min_terminated_length': 1.0, 'completions/max_terminated_length': 483.0, 'rewards/combined_reward_trl/mean': 0.6892707943916321, 'rewards/combined_reward_trl/std': 0.2781331241130829, 'reward': 0.6892708539962769, 'reward_std': 0.259314626455307, 'epoch': 6.04}
2025-05-11 01:05:27,225 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7666666666666666, 'avg_raw_dharma_score': 0.9, 'avg_raw_helpfulness_score': 0.7416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8125}
2025-05-11 01:05:30,630 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5625, 'avg_raw_dharma_score': 0.6083333333333333, 'avg_raw_helpfulness_score': 0.8083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6545833333333334}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 01:06:24,142 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7695833333333333, 'avg_raw_dharma_score': 0.9249999999999999, 'avg_raw_helpfulness_score': 0.8166666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8458749999999999}
2025-05-11 01:06:39,649 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6986111111111111, 'avg_raw_dharma_score': 0.7416666666666667, 'avg_raw_helpfulness_score': 0.725, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7237499999999999}
2025-05-11 01:07:31,693 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6791666666666666, 'avg_raw_dharma_score': 0.8416666666666667, 'avg_raw_helpfulness_score': 0.7333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7604166666666666}
2025-05-11 01:07:34,395 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7333333333333334, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.8250000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8508333333333334}
2025-05-11 01:08:31,473 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6145833333333334, 'avg_raw_dharma_score': 0.625, 'avg_raw_helpfulness_score': 0.6166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6193750000000001}
2025-05-11 01:08:32,552 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5000000000000001, 'avg_raw_dharma_score': 0.65, 'avg_raw_helpfulness_score': 0.45833333333333326, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5475}
  warnings.warn(
2025-05-11 01:09:38,099 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.31250000000000006, 'avg_raw_dharma_score': 0.35000000000000003, 'avg_raw_helpfulness_score': 0.4083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.35625}
2025-05-11 01:09:39,672 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5916666666666667, 'avg_raw_dharma_score': 0.7125, 'avg_raw_helpfulness_score': 0.6833333333333332, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6675000000000001}
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 18321/24000 [7:25:55<14:33:50,  9.23s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 18322/24000 [7:25:56<10:29:36,  6.65s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 18323/24000 [7:25:56<7:38:40,  4.85s/it]  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 18324/24000 [7:25:57<5:39:06,  3.58s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 18325/24000 [7:25:58<4:15:21,  2.70s/it]                                                         {'loss': 0.4081, 'grad_norm': 16.625, 'learning_rate': 4.016799826961642e-07, 'kl': 3.889198811848958, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0009250954014714808, 'clip_ratio/high_max': 0.0014961044971520702, 'clip_ratio/region_mean': 0.0009250954014714808, 'num_tokens': 4079371.0, 'completions/mean_length': 364.66668701171875, 'completions/min_length': 20.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.20833333333333337, 'completions/mean_terminated_length': 325.8947448730469, 'completions/min_terminated_length': 20.0, 'completions/max_terminated_length': 503.0, 'rewards/combined_reward_trl/mean': 0.5118749737739563, 'rewards/combined_reward_trl/std': 0.29124030470848083, 'reward': 0.5118750333786011, 'reward_std': 0.2515130043029785, 'epoch': 6.11}
2025-05-11 01:10:23,096 - openai._base_client - INFO - Retrying request to /chat/completions in 0.442183 seconds
2025-05-11 01:10:32,450 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7008333333333333, 'avg_raw_dharma_score': 0.7041666666666666, 'avg_raw_helpfulness_score': 0.6249999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6794166666666667}
2025-05-11 01:10:36,766 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4708333333333334, 'avg_raw_dharma_score': 0.7583333333333333, 'avg_raw_helpfulness_score': 0.5333333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6045833333333334}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 01:11:30,999 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6375000000000001, 'avg_raw_dharma_score': 0.8000000000000002, 'avg_raw_helpfulness_score': 0.6083333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.69375}
2025-05-11 01:11:43,093 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6929166666666667, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.7749999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8070416666666667}
2025-05-11 01:12:35,500 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5804166666666667, 'avg_raw_dharma_score': 0.7083333333333334, 'avg_raw_helpfulness_score': 0.65, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6524583333333333}
2025-05-11 01:12:38,469 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6041666666666666, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.5583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6487499999999999}
2025-05-11 01:13:29,153 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.75, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.8750000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8875000000000002}
2025-05-11 01:13:29,709 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7624999999999998, 'avg_raw_dharma_score': 0.7166666666666667, 'avg_raw_helpfulness_score': 0.7166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7304166666666667}
  warnings.warn(
2025-05-11 01:14:32,135 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7608333333333334, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.7916666666666669, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8324166666666667}
2025-05-11 01:14:35,976 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6, 'avg_raw_dharma_score': 0.625, 'avg_raw_helpfulness_score': 0.5833333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.605}
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 18521/24000 [7:30:51<13:38:15,  8.96s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 18522/24000 [7:30:52<9:49:53,  6.46s/it]  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 18523/24000 [7:30:53<7:10:04,  4.71s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 18524/24000 [7:30:53<5:18:20,  3.49s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 18525/24000 [7:30:54<4:00:01,  2.63s/it]                                                         {'loss': 0.0502, 'grad_norm': 10.9375, 'learning_rate': 3.750953136471725e-07, 'kl': 0.6799040563901265, 'clip_ratio/low_mean': 0.0001610770379193127, 'clip_ratio/low_min': 3.3362897423406445e-05, 'clip_ratio/high_mean': 0.0015025696010949711, 'clip_ratio/high_max': 0.002455960332105557, 'clip_ratio/region_mean': 0.0016636466227161388, 'num_tokens': 4123220.0, 'completions/mean_length': 317.66668701171875, 'completions/min_length': 37.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 289.9047546386719, 'completions/min_terminated_length': 37.0, 'completions/max_terminated_length': 487.0, 'rewards/combined_reward_trl/mean': 0.718708336353302, 'rewards/combined_reward_trl/std': 0.27809759974479675, 'reward': 0.7187083959579468, 'reward_std': 0.2161104381084442, 'epoch': 6.17}
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 18525/24000 [7:30:54<4:00:01,  2.63s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 18526/24000 [7:30:55<3:05:20,  2.03s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 18527/24000 [7:30:55<2:26:55,  1.61s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 18528/24000 [7:30:56<2:00:01,  1.32s/it]wandb: WARNING Tried to log to step 18525 that is less than the current step 168857. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-11 01:15:22,405 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5258333333333334, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.5416666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5869166666666666}
2025-05-11 01:15:24,764 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.43749999999999994, 'avg_raw_dharma_score': 0.48333333333333334, 'avg_raw_helpfulness_score': 0.5666666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.4945833333333333}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 01:16:10,234 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.65, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.7083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7241666666666666}
2025-05-11 01:16:30,726 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.525, 'avg_raw_dharma_score': 0.7666666666666666, 'avg_raw_helpfulness_score': 0.5666666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6341666666666667}
2025-05-11 01:17:23,167 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6416666666666666, 'avg_raw_dharma_score': 0.7708333333333334, 'avg_raw_helpfulness_score': 0.7583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7283333333333334}
2025-05-11 01:17:23,219 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7812500000000001, 'avg_raw_dharma_score': 0.9333333333333332, 'avg_raw_helpfulness_score': 0.8333333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8577083333333334}
2025-05-11 01:18:13,327 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4854166666666668, 'avg_raw_dharma_score': 0.5833333333333334, 'avg_raw_helpfulness_score': 0.47500000000000003, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5214583333333334}
2025-05-11 01:18:15,180 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.57875, 'avg_raw_dharma_score': 0.7333333333333334, 'avg_raw_helpfulness_score': 0.5750000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6394583333333334}
  warnings.warn(
2025-05-11 01:19:18,216 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.64375, 'avg_raw_dharma_score': 0.7291666666666666, 'avg_raw_helpfulness_score': 0.75, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7097916666666667}
2025-05-11 01:19:19,522 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.3804166666666667, 'avg_raw_dharma_score': 0.39999999999999997, 'avg_raw_helpfulness_score': 0.5, 'avg_penalty': 0.0, 'avg_combined_reward': 0.42412500000000003}
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 18721/24000 [7:35:35<12:19:04,  8.40s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 18722/24000 [7:35:36<8:53:55,  6.07s/it]  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 18723/24000 [7:35:36<6:30:21,  4.44s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 18724/24000 [7:35:37<4:49:53,  3.30s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 18725/24000 [7:35:38<3:39:33,  2.50s/it]                                                         {'loss': 0.279, 'grad_norm': 5.4375, 'learning_rate': 3.4929460896764034e-07, 'kl': 2.8776989459991453, 'clip_ratio/low_mean': 3.5308998776599764e-05, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0009783132603236784, 'clip_ratio/high_max': 0.001535568182201435, 'clip_ratio/region_mean': 0.001013622257936125, 'num_tokens': 4164703.0, 'completions/mean_length': 336.5, 'completions/min_length': 82.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.08333333333333337, 'completions/mean_terminated_length': 320.54547119140625, 'completions/min_terminated_length': 82.0, 'completions/max_terminated_length': 505.0, 'rewards/combined_reward_trl/mean': 0.5669583678245544, 'rewards/combined_reward_trl/std': 0.27473896741867065, 'reward': 0.5669583678245544, 'reward_std': 0.2324114441871643, 'epoch': 6.24}
2025-05-11 01:20:13,157 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6833333333333332, 'avg_raw_dharma_score': 0.7999999999999999, 'avg_raw_helpfulness_score': 0.6250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7125}
2025-05-11 01:20:14,934 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6083333333333333, 'avg_raw_dharma_score': 0.7208333333333333, 'avg_raw_helpfulness_score': 0.6, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6508333333333334}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 01:21:09,117 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.45999999999999996, 'avg_raw_dharma_score': 0.5, 'avg_raw_helpfulness_score': 0.4916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.48550000000000004}
2025-05-11 01:21:19,769 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5833333333333334, 'avg_raw_dharma_score': 0.6124999999999999, 'avg_raw_helpfulness_score': 0.6750000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6224999999999999}
2025-05-11 01:22:10,022 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6345833333333334, 'avg_raw_dharma_score': 0.7833333333333333, 'avg_raw_helpfulness_score': 0.7250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7212083333333333}
2025-05-11 01:22:10,040 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6583333333333333, 'avg_raw_dharma_score': 0.8541666666666666, 'avg_raw_helpfulness_score': 0.6166666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7241666666666667}
2025-05-11 01:22:59,173 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7270833333333334, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.8250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8489583333333335}
2025-05-11 01:23:01,230 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5875, 'avg_raw_dharma_score': 0.7083333333333334, 'avg_raw_helpfulness_score': 0.5333333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6195833333333334}
  warnings.warn(
2025-05-11 01:24:04,088 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5029166666666667, 'avg_raw_dharma_score': 0.7083333333333334, 'avg_raw_helpfulness_score': 0.5166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5892083333333333}
2025-05-11 01:24:06,825 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6333333333333333, 'avg_raw_dharma_score': 0.6875, 'avg_raw_helpfulness_score': 0.6833333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6699999999999999}
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 18921/24000 [7:40:22<12:21:48,  8.76s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 18922/24000 [7:40:23<8:55:17,  6.32s/it]  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 18923/24000 [7:40:24<6:30:45,  4.62s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 18924/24000 [7:40:24<4:49:35,  3.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 18925/24000 [7:40:25<3:38:47,  2.59s/it]                                                         {'loss': 0.1438, 'grad_norm': 9.3125, 'learning_rate': 3.242958495882375e-07, 'kl': 1.483273410797119, 'clip_ratio/low_mean': 2.6796895156924923e-05, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.001494961699936539, 'clip_ratio/high_max': 0.002211732045592119, 'clip_ratio/region_mean': 0.0015217585939293107, 'num_tokens': 4207273.0, 'completions/mean_length': 286.125, 'completions/min_length': 1.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.04166666666666663, 'completions/mean_terminated_length': 276.3043518066406, 'completions/min_terminated_length': 1.0, 'completions/max_terminated_length': 485.0, 'rewards/combined_reward_trl/mean': 0.629604160785675, 'rewards/combined_reward_trl/std': 0.34630733728408813, 'reward': 0.6296042203903198, 'reward_std': 0.3300587832927704, 'epoch': 6.31}
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 18925/24000 [7:40:25<3:38:47,  2.59s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 18926/24000 [7:40:26<2:49:21,  2.00s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 18927/24000 [7:40:26<2:14:37,  1.59s/it]wandb: WARNING Tried to log to step 18925 that is less than the current step 172503. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-11 01:24:52,422 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8958333333333334, 'avg_raw_dharma_score': 0.9833333333333334, 'avg_raw_helpfulness_score': 0.8833333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.9270833333333334}
2025-05-11 01:24:58,174 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7875, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.8000000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8262499999999999}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 01:25:49,576 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6854166666666668, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.7416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7447916666666669}
2025-05-11 01:26:04,744 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6208333333333332, 'avg_raw_dharma_score': 0.7541666666666668, 'avg_raw_helpfulness_score': 0.6416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6804166666666668}
2025-05-11 01:26:51,493 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7666666666666666, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.8583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8375}
2025-05-11 01:26:55,528 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.47541666666666665, 'avg_raw_dharma_score': 0.7333333333333334, 'avg_raw_helpfulness_score': 0.5916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6134583333333333}
2025-05-11 01:27:45,263 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6999999999999998, 'avg_raw_dharma_score': 0.8583333333333334, 'avg_raw_helpfulness_score': 0.7500000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7783333333333334}
2025-05-11 01:27:46,209 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5929166666666666, 'avg_raw_dharma_score': 0.6583333333333333, 'avg_raw_helpfulness_score': 0.6416666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6337083333333334}
  warnings.warn(
2025-05-11 01:28:49,815 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6208333333333335, 'avg_raw_dharma_score': 0.8000000000000002, 'avg_raw_helpfulness_score': 0.6416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.69875}
2025-05-11 01:28:50,421 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6041666666666666, 'avg_raw_dharma_score': 0.7333333333333334, 'avg_raw_helpfulness_score': 0.5916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6520833333333332}
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 19121/24000 [7:45:06<11:19:43,  8.36s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 19122/24000 [7:45:07<8:11:09,  6.04s/it]  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 19123/24000 [7:45:07<5:59:10,  4.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 19124/24000 [7:45:08<4:26:49,  3.28s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 19125/24000 [7:45:08<3:22:11,  2.49s/it]                                                         {'loss': 0.0108, 'grad_norm': 15.625, 'learning_rate': 3.0011645755091285e-07, 'kl': 1.477808630069097, 'clip_ratio/low_mean': 2.2367440396919847e-05, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0011490751899934063, 'clip_ratio/high_max': 0.002090980096254498, 'clip_ratio/region_mean': 0.0011714426303903263, 'num_tokens': 4247688.0, 'completions/mean_length': 306.25, 'completions/min_length': 114.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 276.8571472167969, 'completions/min_terminated_length': 114.0, 'completions/max_terminated_length': 490.0, 'rewards/combined_reward_trl/mean': 0.6754166483879089, 'rewards/combined_reward_trl/std': 0.17091134190559387, 'reward': 0.6754167079925537, 'reward_std': 0.15574438869953156, 'epoch': 6.38}
2025-05-11 01:29:42,349 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.44999999999999996, 'avg_raw_dharma_score': 0.5, 'avg_raw_helpfulness_score': 0.525, 'avg_penalty': 0.0, 'avg_combined_reward': 0.49249999999999994}
2025-05-11 01:29:45,079 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.65, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.6583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7091666666666666}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 01:30:37,698 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6133333333333334, 'avg_raw_dharma_score': 0.7333333333333334, 'avg_raw_helpfulness_score': 0.6083333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6598333333333334}
2025-05-11 01:30:50,029 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6749999999999999, 'avg_raw_dharma_score': 0.8166666666666668, 'avg_raw_helpfulness_score': 0.7333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7491666666666666}
2025-05-11 01:31:40,621 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.31666666666666665, 'avg_raw_dharma_score': 0.25, 'avg_raw_helpfulness_score': 0.3999999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.315}
2025-05-11 01:31:42,295 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4527777777777778, 'avg_raw_dharma_score': 0.5, 'avg_raw_helpfulness_score': 0.4750000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.47833333333333333}
2025-05-11 01:32:32,444 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7875, 'avg_raw_dharma_score': 0.9333333333333332, 'avg_raw_helpfulness_score': 0.8000000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8495833333333335}
2025-05-11 01:32:34,608 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.665, 'avg_raw_dharma_score': 0.8166666666666668, 'avg_raw_helpfulness_score': 0.6916666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7336666666666667}
  warnings.warn(
2025-05-11 01:33:40,072 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.549861111111111, 'avg_raw_dharma_score': 0.7333333333333334, 'avg_raw_helpfulness_score': 0.6333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6482916666666667}
2025-05-11 01:33:40,226 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5791666666666667, 'avg_raw_dharma_score': 0.6041666666666666, 'avg_raw_helpfulness_score': 0.6083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5979166666666665}
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 19321/24000 [7:49:56<10:45:53,  8.28s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 19322/24000 [7:49:56<7:46:48,  5.99s/it]  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 19323/24000 [7:49:57<5:41:28,  4.38s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 19324/24000 [7:49:58<4:13:44,  3.26s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 19325/24000 [7:49:58<3:12:20,  2.47s/it]                                                         {'loss': 0.2148, 'grad_norm': 8.75, 'learning_rate': 2.767732838671901e-07, 'kl': 2.0055379537741342, 'clip_ratio/low_mean': 2.727165740604202e-05, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0006887392144805442, 'clip_ratio/high_max': 0.0010538546655637522, 'clip_ratio/region_mean': 0.0007160108726626883, 'num_tokens': 4292309.0, 'completions/mean_length': 328.16668701171875, 'completions/min_length': 147.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 301.9047546386719, 'completions/min_terminated_length': 147.0, 'completions/max_terminated_length': 509.0, 'rewards/combined_reward_trl/mean': 0.6231041550636292, 'rewards/combined_reward_trl/std': 0.3321310579776764, 'reward': 0.6231042146682739, 'reward_std': 0.3343313932418823, 'epoch': 6.44}
2025-05-11 01:34:32,233 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6179166666666668, 'avg_raw_dharma_score': 0.8166666666666668, 'avg_raw_helpfulness_score': 0.6583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7095416666666666}
2025-05-11 01:34:32,952 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4666666666666666, 'avg_raw_dharma_score': 0.6583333333333333, 'avg_raw_helpfulness_score': 0.4833333333333332, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5483333333333333}
                                                       {'loss': 0.3096, 'grad_norm': 9.5625, 'learning_rate': 2.7107006896680953e-07, 'kl': 2.6496182084083557, 'clip_ratio/low_mean': 9.098092404504617e-05, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0009704646270256489, 'clip_ratio/high_max': 0.0014379980127948026, 'clip_ratio/region_mean': 0.0010614455553392568, 'num_tokens': 4301236.0, 'completions/mean_length': 334.2083435058594, 'completions/min_length': 85.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 308.8095397949219, 'completions/min_terminated_length': 85.0, 'completions/max_terminated_length': 476.0, 'rewards/combined_reward_trl/mean': 0.6289374828338623, 'rewards/combined_reward_trl/std': 0.26659613847732544, 'reward': 0.6289374828338623, 'reward_std': 0.24605834484100342, 'epoch': 6.46}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 01:35:24,529 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5604166666666667, 'avg_raw_dharma_score': 0.6708333333333334, 'avg_raw_helpfulness_score': 0.5750000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6089583333333333}
2025-05-11 01:35:40,658 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6275000000000001, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.6583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7357499999999999}
2025-05-11 01:36:36,737 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6583333333333333, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.6833333333333332, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7358333333333333}
2025-05-11 01:36:36,926 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.44750000000000006, 'avg_raw_dharma_score': 0.65, 'avg_raw_helpfulness_score': 0.44166666666666665, 'avg_penalty': 0.0, 'avg_combined_reward': 0.52675}
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 19441/24000 [7:52:52<12:33:28,  9.92s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 19442/24000 [7:52:53<9:01:46,  7.13s/it]  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 19443/24000 [7:52:54<6:33:36,  5.18s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 19444/24000 [7:52:54<4:49:55,  3.82s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 19445/24000 [7:52:55<3:37:20,  2.86s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 19446/24000 [7:52:56<2:46:33,  2.19s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 19447/24000 [7:52:56<2:11:00,  1.73s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 19448/24000 [7:52:57<1:46:07,  1.40s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 19449/24000 [7:52:58<1:28:42,  1.17s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 19450/24000 [7:52:58<1:16:31,  1.01s/it]                                                         {'loss': 0.2162, 'grad_norm': 22.125, 'learning_rate': 2.626156956316306e-07, 'kl': 2.812169764439265, 'clip_ratio/low_mean': 0.0001969574783773472, 'clip_ratio/low_min': 6.0661050180594124e-05, 'clip_ratio/high_mean': 0.0006367128140603503, 'clip_ratio/high_max': 0.0010063259885646403, 'clip_ratio/region_mean': 0.0008336702920496464, 'num_tokens': 4318126.0, 'completions/mean_length': 320.625, 'completions/min_length': 46.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.08333333333333337, 'completions/mean_terminated_length': 303.227294921875, 'completions/min_terminated_length': 46.0, 'completions/max_terminated_length': 476.0, 'rewards/combined_reward_trl/mean': 0.6312916874885559, 'rewards/combined_reward_trl/std': 0.2718554437160492, 'reward': 0.6312917470932007, 'reward_std': 0.2382994145154953, 'epoch': 6.48}
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 19450/24000 [7:52:58<1:16:31,  1.01s/it]wandb: WARNING Tried to log to step 19450 that is less than the current step 177288. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-11 01:37:28,892 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6666666666666666, 'avg_raw_dharma_score': 0.8166666666666668, 'avg_raw_helpfulness_score': 0.6083333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7091666666666665}
2025-05-11 01:37:29,572 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.46527777777777785, 'avg_raw_dharma_score': 0.6916666666666668, 'avg_raw_helpfulness_score': 0.6249999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.60375}
  warnings.warn(
2025-05-11 01:38:34,916 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6112500000000001, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.5416666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6125416666666668}
2025-05-11 01:38:35,026 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.41041666666666665, 'avg_raw_dharma_score': 0.5416666666666666, 'avg_raw_helpfulness_score': 0.4749999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.4822916666666666}
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 19521/24000 [7:54:51<10:53:42,  8.76s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 19522/24000 [7:54:51<7:51:45,  6.32s/it]  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 19523/24000 [7:54:52<5:44:28,  4.62s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 19524/24000 [7:54:52<4:15:20,  3.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 19525/24000 [7:54:53<3:12:58,  2.59s/it]                                                         {'loss': 0.4162, 'grad_norm': 29.5, 'learning_rate': 2.54282596774423e-07, 'kl': 3.1160338878631593, 'clip_ratio/low_mean': 5.062009440734983e-06, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.000763670673671489, 'clip_ratio/high_max': 0.0013198441119554143, 'clip_ratio/region_mean': 0.0007687326842763771, 'num_tokens': 4335114.0, 'completions/mean_length': 309.3333435058594, 'completions/min_length': 21.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.16666666666666663, 'completions/mean_terminated_length': 268.8000183105469, 'completions/min_terminated_length': 21.0, 'completions/max_terminated_length': 453.0, 'rewards/combined_reward_trl/mean': 0.547416627407074, 'rewards/combined_reward_trl/std': 0.35869458317756653, 'reward': 0.5474166870117188, 'reward_std': 0.21685175597667694, 'epoch': 6.51}
2025-05-11 01:39:28,468 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5845833333333333, 'avg_raw_dharma_score': 0.775, 'avg_raw_helpfulness_score': 0.6416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6778749999999999}
2025-05-11 01:39:28,583 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7083333333333334, 'avg_raw_dharma_score': 0.9416666666666668, 'avg_raw_helpfulness_score': 0.8333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8391666666666667}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 01:40:18,016 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7300000000000001, 'avg_raw_dharma_score': 0.8583333333333334, 'avg_raw_helpfulness_score': 0.7333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7823333333333333}
2025-05-11 01:40:36,875 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6375, 'avg_raw_dharma_score': 0.7291666666666666, 'avg_raw_helpfulness_score': 0.6166666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6679166666666666}
2025-05-11 01:41:23,152 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5152777777777778, 'avg_raw_dharma_score': 0.525, 'avg_raw_helpfulness_score': 0.5833333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5395833333333333}
2025-05-11 01:41:31,122 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4966666666666666, 'avg_raw_dharma_score': 0.6083333333333333, 'avg_raw_helpfulness_score': 0.4833333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5373333333333333}
2025-05-11 01:42:22,172 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7611111111111111, 'avg_raw_dharma_score': 0.8791666666666668, 'avg_raw_helpfulness_score': 0.7999999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8200000000000002}
2025-05-11 01:42:22,581 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5791666666666666, 'avg_raw_dharma_score': 0.8416666666666667, 'avg_raw_helpfulness_score': 0.7833333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7454166666666667}
  warnings.warn(
2025-05-11 01:43:28,886 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.65, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7250000000000001}
2025-05-11 01:43:29,646 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.576388888888889, 'avg_raw_dharma_score': 0.6875, 'avg_raw_helpfulness_score': 0.6166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6329166666666667}
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 19721/24000 [7:59:45<10:19:22,  8.68s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 19722/24000 [7:59:46<7:26:58,  6.27s/it]  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 19723/24000 [7:59:46<5:26:16,  4.58s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 19724/24000 [7:59:47<4:01:49,  3.39s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 19725/24000 [7:59:48<3:02:41,  2.56s/it]                                                         {'loss': 0.1589, 'grad_norm': 17.75, 'learning_rate': 2.326600703981972e-07, 'kl': 1.3255075732866923, 'clip_ratio/low_mean': 2.529842973065873e-05, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0008919245000773419, 'clip_ratio/high_max': 0.0014002865467530985, 'clip_ratio/region_mean': 0.0009172229298080008, 'num_tokens': 4374890.0, 'completions/mean_length': 326.8333435058594, 'completions/min_length': 70.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.16666666666666663, 'completions/mean_terminated_length': 289.8000183105469, 'completions/min_terminated_length': 70.0, 'completions/max_terminated_length': 500.0, 'rewards/combined_reward_trl/mean': 0.6789583563804626, 'rewards/combined_reward_trl/std': 0.30098021030426025, 'reward': 0.6789583563804626, 'reward_std': 0.2837066352367401, 'epoch': 6.58}
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 19725/24000 [7:59:48<3:02:41,  2.56s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 19726/24000 [7:59:48<2:21:26,  1.99s/it]wandb: WARNING Tried to log to step 19725 that is less than the current step 179795. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-11 01:44:21,520 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7304166666666667, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.8083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8449583333333335}
2025-05-11 01:44:21,851 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4625000000000001, 'avg_raw_dharma_score': 0.7083333333333334, 'avg_raw_helpfulness_score': 0.5916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5995833333333334}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 01:45:16,766 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5533333333333333, 'avg_raw_dharma_score': 0.7125, 'avg_raw_helpfulness_score': 0.6166666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.636}
2025-05-11 01:45:30,189 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6666666666666666, 'avg_raw_dharma_score': 0.7083333333333334, 'avg_raw_helpfulness_score': 0.6000000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6633333333333333}
2025-05-11 01:46:25,079 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7020833333333334, 'avg_raw_dharma_score': 0.9416666666666668, 'avg_raw_helpfulness_score': 0.7333333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8072916666666669}
2025-05-11 01:46:25,719 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5245833333333334, 'avg_raw_dharma_score': 0.7083333333333334, 'avg_raw_helpfulness_score': 0.6000000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6207083333333333}
2025-05-11 01:47:17,468 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6208333333333333, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.7083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7154166666666667}
2025-05-11 01:47:17,788 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.67625, 'avg_raw_dharma_score': 0.7458333333333332, 'avg_raw_helpfulness_score': 0.6749999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7037083333333333}
  warnings.warn(
2025-05-11 01:48:23,136 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.625, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.5333333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6141666666666666}
2025-05-11 01:48:24,769 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6291666666666668, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.5666666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6254166666666666}
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 19921/24000 [8:04:40<10:24:44,  9.19s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 19922/24000 [8:04:41<7:30:05,  6.62s/it]  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 19923/24000 [8:04:42<5:27:51,  4.82s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 19924/24000 [8:04:42<4:02:19,  3.57s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 19925/24000 [8:04:43<3:02:27,  2.69s/it]                                                         {'loss': 0.3147, 'grad_norm': 20.625, 'learning_rate': 2.1192077382877566e-07, 'kl': 2.393027998606364, 'clip_ratio/low_mean': 9.248999801153938e-06, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0012299212875465553, 'clip_ratio/high_max': 0.0019072735325122872, 'clip_ratio/region_mean': 0.0012391702877357603, 'num_tokens': 4419052.0, 'completions/mean_length': 316.66668701171875, 'completions/min_length': 69.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 251.55555725097656, 'completions/min_terminated_length': 69.0, 'completions/max_terminated_length': 417.0, 'rewards/combined_reward_trl/mean': 0.6197916865348816, 'rewards/combined_reward_trl/std': 0.394347220659256, 'reward': 0.6197916865348816, 'reward_std': 0.3696916997432709, 'epoch': 6.64}
2025-05-11 01:49:18,341 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6291666666666665, 'avg_raw_dharma_score': 0.7708333333333334, 'avg_raw_helpfulness_score': 0.7083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7095833333333332}
2025-05-11 01:49:21,400 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6208333333333333, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.5750000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6254166666666667}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 01:50:07,441 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7833333333333333, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.8333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8683333333333333}
2025-05-11 01:50:29,528 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5499999999999999, 'avg_raw_dharma_score': 0.7333333333333334, 'avg_raw_helpfulness_score': 0.5750000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6308333333333334}
2025-05-11 01:51:21,919 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5195833333333332, 'avg_raw_dharma_score': 0.7000000000000001, 'avg_raw_helpfulness_score': 0.5750000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.608375}
2025-05-11 01:51:26,679 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5708333333333334, 'avg_raw_dharma_score': 0.5833333333333334, 'avg_raw_helpfulness_score': 0.5916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5820833333333333}
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 20041/24000 [8:07:42<11:10:29, 10.16s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 20042/24000 [8:07:43<8:01:41,  7.30s/it]  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 20043/24000 [8:07:43<5:49:33,  5.30s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 20044/24000 [8:07:44<4:17:03,  3.90s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 20045/24000 [8:07:45<3:12:20,  2.92s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 20046/24000 [8:07:45<2:27:03,  2.23s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 20047/24000 [8:07:46<1:55:20,  1.75s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 20048/24000 [8:07:47<1:33:09,  1.41s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 20049/24000 [8:07:47<1:17:39,  1.18s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 20050/24000 [8:07:48<1:06:48,  1.01s/it]                                                         {'loss': 0.3136, 'grad_norm': 9.1875, 'learning_rate': 1.9941367679053464e-07, 'kl': 2.44006853501002, 'clip_ratio/low_mean': 0.00013773909537121654, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0007031958864536136, 'clip_ratio/high_max': 0.0010777886995735268, 'clip_ratio/region_mean': 0.0008409349802726259, 'num_tokens': 4445026.0, 'completions/mean_length': 322.7083435058594, 'completions/min_length': 52.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.16666666666666663, 'completions/mean_terminated_length': 284.8500061035156, 'completions/min_terminated_length': 52.0, 'completions/max_terminated_length': 512.0, 'rewards/combined_reward_trl/mean': 0.5952292084693909, 'rewards/combined_reward_trl/std': 0.37038636207580566, 'reward': 0.5952292680740356, 'reward_std': 0.3248240649700165, 'epoch': 6.68}
2025-05-11 01:52:18,181 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.43333333333333335, 'avg_raw_dharma_score': 0.5833333333333334, 'avg_raw_helpfulness_score': 0.55, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5283333333333334}
2025-05-11 01:52:19,180 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6000000000000001, 'avg_raw_dharma_score': 0.9, 'avg_raw_helpfulness_score': 0.65, 'avg_penalty': 0.0, 'avg_combined_reward': 0.735}
  warnings.warn(
2025-05-11 01:53:25,034 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6708333333333334, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.7333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7379166666666666}
2025-05-11 01:53:25,400 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.725, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.7833333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8358333333333334}
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 20121/24000 [8:09:41<9:39:54,  8.97s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 20122/24000 [8:09:42<6:58:07,  6.47s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 20123/24000 [8:09:42<5:04:55,  4.72s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 20124/24000 [8:09:43<3:45:41,  3.49s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 20125/24000 [8:09:43<2:50:13,  2.64s/it]                                                         {'loss': 0.3276, 'grad_norm': 19.75, 'learning_rate': 1.9207916061920616e-07, 'kl': 2.421374550660451, 'clip_ratio/low_mean': 0.00011484576039947569, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0005518996455551435, 'clip_ratio/high_max': 0.000912340908156087, 'clip_ratio/region_mean': 0.0006667454067307214, 'num_tokens': 4462639.0, 'completions/mean_length': 325.79168701171875, 'completions/min_length': 187.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 299.19049072265625, 'completions/min_terminated_length': 187.0, 'completions/max_terminated_length': 428.0, 'rewards/combined_reward_trl/mean': 0.7868750095367432, 'rewards/combined_reward_trl/std': 0.2668488025665283, 'reward': 0.7868751287460327, 'reward_std': 0.24417802691459656, 'epoch': 6.71}
2025-05-11 01:54:18,685 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6716666666666667, 'avg_raw_dharma_score': 0.7999999999999999, 'avg_raw_helpfulness_score': 0.6666666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7215000000000001}
2025-05-11 01:54:20,289 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6083333333333334, 'avg_raw_dharma_score': 0.48333333333333334, 'avg_raw_helpfulness_score': 0.6083333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5583333333333332}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 01:55:15,497 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4708333333333334, 'avg_raw_dharma_score': 0.5833333333333334, 'avg_raw_helpfulness_score': 0.5166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5295833333333334}
2025-05-11 01:55:26,601 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6770833333333334, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.6916666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6772916666666667}
2025-05-11 01:56:17,325 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5791666666666666, 'avg_raw_dharma_score': 0.7291666666666666, 'avg_raw_helpfulness_score': 0.6250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6529166666666666}
2025-05-11 01:56:19,167 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6012500000000002, 'avg_raw_dharma_score': 0.7083333333333334, 'avg_raw_helpfulness_score': 0.5916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6412083333333333}
2025-05-11 01:57:12,137 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5908333333333334, 'avg_raw_dharma_score': 0.6041666666666666, 'avg_raw_helpfulness_score': 0.6166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6039166666666668}
2025-05-11 01:57:15,524 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6116666666666667, 'avg_raw_dharma_score': 0.7833333333333333, 'avg_raw_helpfulness_score': 0.6083333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6793333333333335}
  warnings.warn(
2025-05-11 01:58:24,232 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.6749999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7158333333333332}
2025-05-11 01:58:24,313 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6833333333333332, 'avg_raw_dharma_score': 0.8166666666666668, 'avg_raw_helpfulness_score': 0.7250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7491666666666666}
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 20321/24000 [8:14:40<9:54:24,  9.69s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 20322/24000 [8:14:40<7:07:38,  6.98s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 20323/24000 [8:14:41<5:10:57,  5.07s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 20324/24000 [8:14:42<3:49:15,  3.74s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 20325/24000 [8:14:42<2:52:05,  2.81s/it]                                                         {'loss': 0.2763, 'grad_norm': 14.6875, 'learning_rate': 1.7314905871240623e-07, 'kl': 2.0741346001625063, 'clip_ratio/low_mean': 4.4016573034847777e-05, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.000595138359349221, 'clip_ratio/high_max': 0.0009221423099127909, 'clip_ratio/region_mean': 0.0006391549319960176, 'num_tokens': 4508404.0, 'completions/mean_length': 296.66668701171875, 'completions/min_length': 89.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.08333333333333337, 'completions/mean_terminated_length': 277.0909118652344, 'completions/min_terminated_length': 89.0, 'completions/max_terminated_length': 480.0, 'rewards/combined_reward_trl/mean': 0.7325000166893005, 'rewards/combined_reward_trl/std': 0.23434460163116455, 'reward': 0.7325000166893005, 'reward_std': 0.21157900989055634, 'epoch': 6.78}
2025-05-11 01:59:16,406 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6416666666666667, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.6916666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7333333333333334}
2025-05-11 01:59:17,951 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7312500000000001, 'avg_raw_dharma_score': 0.9, 'avg_raw_helpfulness_score': 0.7416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.801875}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 02:00:09,253 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5770833333333333, 'avg_raw_dharma_score': 0.7583333333333333, 'avg_raw_helpfulness_score': 0.625, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6639583333333333}
2025-05-11 02:00:22,859 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.41541666666666677, 'avg_raw_dharma_score': 0.5416666666666666, 'avg_raw_helpfulness_score': 0.42500000000000004, 'avg_penalty': 0.0, 'avg_combined_reward': 0.4687916666666667}
2025-05-11 02:01:15,629 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.65625, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.65, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7252083333333333}
2025-05-11 02:01:16,343 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5487500000000001, 'avg_raw_dharma_score': 0.6625, 'avg_raw_helpfulness_score': 0.625, 'avg_penalty': 0.0, 'avg_combined_reward': 0.617125}
2025-05-11 02:02:08,790 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8275000000000001, 'avg_raw_dharma_score': 0.8166666666666668, 'avg_raw_helpfulness_score': 0.8583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8324166666666667}
2025-05-11 02:02:09,352 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5541666666666666, 'avg_raw_dharma_score': 0.7291666666666666, 'avg_raw_helpfulness_score': 0.5750000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6304166666666666}
  warnings.warn(
2025-05-11 02:03:15,050 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7200000000000001, 'avg_raw_dharma_score': 0.9, 'avg_raw_helpfulness_score': 0.75, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8010000000000002}
2025-05-11 02:03:15,523 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6291666666666665, 'avg_raw_dharma_score': 0.7583333333333333, 'avg_raw_helpfulness_score': 0.7583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7195833333333334}
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 20521/24000 [8:19:31<8:38:26,  8.94s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 20522/24000 [8:19:32<6:13:47,  6.45s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 20523/24000 [8:19:32<4:32:33,  4.70s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 20524/24000 [8:19:33<3:21:43,  3.48s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 20525/24000 [8:19:34<2:32:08,  2.63s/it]                                                         {'loss': 0.0874, 'grad_norm': 12.0625, 'learning_rate': 1.5514366080424025e-07, 'kl': 1.1645719162623087, 'clip_ratio/low_mean': 0.0003331549690725903, 'clip_ratio/low_min': 4.283446430539091e-05, 'clip_ratio/high_mean': 0.0007183633667106429, 'clip_ratio/high_max': 0.0011055528473419448, 'clip_ratio/region_mean': 0.0010515183381115396, 'num_tokens': 4547836.0, 'completions/mean_length': 322.29168701171875, 'completions/min_length': 153.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 295.19049072265625, 'completions/min_terminated_length': 153.0, 'completions/max_terminated_length': 424.0, 'rewards/combined_reward_trl/mean': 0.7602917551994324, 'rewards/combined_reward_trl/std': 0.25432685017585754, 'reward': 0.7602917551994324, 'reward_std': 0.17586755752563477, 'epoch': 6.84}
2025-05-11 02:03:58,937 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.9166666666666666, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.9083333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.9475000000000001}
2025-05-11 02:04:06,552 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7704166666666667, 'avg_raw_dharma_score': 0.9208333333333334, 'avg_raw_helpfulness_score': 0.8250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8469583333333334}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 02:04:56,923 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6695833333333333, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.75, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7925416666666667}
2025-05-11 02:05:10,396 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5729166666666666, 'avg_raw_dharma_score': 0.6083333333333333, 'avg_raw_helpfulness_score': 0.525, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5727083333333335}
2025-05-11 02:06:01,838 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5743055555555556, 'avg_raw_dharma_score': 0.8583333333333334, 'avg_raw_helpfulness_score': 0.7083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7281249999999999}
2025-05-11 02:06:02,611 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6733333333333333, 'avg_raw_dharma_score': 0.8833333333333334, 'avg_raw_helpfulness_score': 0.6833333333333332, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7603333333333334}
2025-05-11 02:06:59,026 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5666666666666668, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.5083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5891666666666667}
2025-05-11 02:07:02,331 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4725, 'avg_raw_dharma_score': 0.6458333333333334, 'avg_raw_helpfulness_score': 0.46666666666666673, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5400833333333334}
  warnings.warn(
2025-05-11 02:08:07,952 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6520833333333335, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.7166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7439583333333334}
2025-05-11 02:08:10,378 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5277777777777778, 'avg_raw_dharma_score': 0.625, 'avg_raw_helpfulness_score': 0.525, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5658333333333334}
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 20721/24000 [8:24:26<8:36:24,  9.45s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 20722/24000 [8:24:26<6:11:20,  6.80s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 20723/24000 [8:24:27<4:29:49,  4.94s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 20724/24000 [8:24:28<3:18:47,  3.64s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 20725/24000 [8:24:28<2:29:04,  2.73s/it]                                                         {'loss': 0.2932, 'grad_norm': 6.625, 'learning_rate': 1.3807551514932033e-07, 'kl': 3.36654882589976, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0006128267769236117, 'clip_ratio/high_max': 0.0010441377471822003, 'clip_ratio/region_mean': 0.0006128267769236117, 'num_tokens': 4589179.0, 'completions/mean_length': 333.54168701171875, 'completions/min_length': 157.0, 'completions/max_length': 474.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 333.54168701171875, 'completions/min_terminated_length': 157.0, 'completions/max_terminated_length': 474.0, 'rewards/combined_reward_trl/mean': 0.6548958420753479, 'rewards/combined_reward_trl/std': 0.3383339047431946, 'reward': 0.6548959016799927, 'reward_std': 0.2938687801361084, 'epoch': 6.91}
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 20725/24000 [8:24:28<2:29:04,  2.73s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 20726/24000 [8:24:29<1:54:23,  2.10s/it]wandb: WARNING Tried to log to step 20725 that is less than the current step 188910. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-11 02:08:59,277 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5384722222222222, 'avg_raw_dharma_score': 0.6708333333333334, 'avg_raw_helpfulness_score': 0.6, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6098750000000001}
2025-05-11 02:09:00,604 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4875, 'avg_raw_dharma_score': 0.49166666666666664, 'avg_raw_helpfulness_score': 0.5083333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.49541666666666667}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 02:09:54,622 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.48166666666666674, 'avg_raw_dharma_score': 0.5875, 'avg_raw_helpfulness_score': 0.49166666666666664, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5270000000000001}
2025-05-11 02:10:08,752 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5826388888888889, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.6416666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7006249999999999}
2025-05-11 02:11:00,787 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7062499999999999, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.7250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.779375}
2025-05-11 02:11:01,230 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7025, 'avg_raw_dharma_score': 0.8583333333333334, 'avg_raw_helpfulness_score': 0.7583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7815833333333333}
2025-05-11 02:11:48,628 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7208333333333333, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.7916666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8204166666666667}
2025-05-11 02:11:53,735 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.23124999999999998, 'avg_raw_dharma_score': 0.2916666666666667, 'avg_raw_helpfulness_score': 0.25833333333333336, 'avg_penalty': 0.0, 'avg_combined_reward': 0.2635416666666667}
  warnings.warn(
2025-05-11 02:12:57,353 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8275000000000001, 'avg_raw_dharma_score': 0.9791666666666666, 'avg_raw_helpfulness_score': 0.8416666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8924166666666667}
2025-05-11 02:13:01,414 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6875, 'avg_raw_dharma_score': 0.8624999999999999, 'avg_raw_helpfulness_score': 0.7916666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7887500000000002}
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 20921/24000 [8:29:17<7:56:48,  9.29s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 20922/24000 [8:29:18<5:43:23,  6.69s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 20923/24000 [8:29:18<4:09:59,  4.87s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 20924/24000 [8:29:19<3:04:40,  3.60s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 20925/24000 [8:29:19<2:18:56,  2.71s/it]                                                         {'loss': 0.2182, 'grad_norm': 6.3125, 'learning_rate': 1.2195651681592045e-07, 'kl': 2.443528982500235, 'clip_ratio/low_mean': 0.00014435462032755215, 'clip_ratio/low_min': 8.629988878965377e-06, 'clip_ratio/high_mean': 0.0008304952473069231, 'clip_ratio/high_max': 0.0014614540136729678, 'clip_ratio/region_mean': 0.0009748498707388838, 'num_tokens': 4631797.0, 'completions/mean_length': 313.625, 'completions/min_length': 123.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 285.28570556640625, 'completions/min_terminated_length': 123.0, 'completions/max_terminated_length': 444.0, 'rewards/combined_reward_trl/mean': 0.840583324432373, 'rewards/combined_reward_trl/std': 0.17838983237743378, 'reward': 0.840583324432373, 'reward_std': 0.12364306300878525, 'epoch': 6.97}
2025-05-11 02:13:53,246 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4937499999999999, 'avg_raw_dharma_score': 0.7166666666666667, 'avg_raw_helpfulness_score': 0.575, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6072916666666667}
2025-05-11 02:13:54,168 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.41958333333333336, 'avg_raw_dharma_score': 0.48333333333333334, 'avg_raw_helpfulness_score': 0.42500000000000004, 'avg_penalty': 0.0, 'avg_combined_reward': 0.4467083333333333}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 02:14:46,685 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7612500000000001, 'avg_raw_dharma_score': 0.7999999999999999, 'avg_raw_helpfulness_score': 0.65, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7433749999999999}
2025-05-11 02:15:02,750 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.59875, 'avg_raw_dharma_score': 0.7958333333333334, 'avg_raw_helpfulness_score': 0.6416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6904583333333333}
2025-05-11 02:15:53,467 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6833333333333332, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.6583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7691666666666667}
2025-05-11 02:15:56,542 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5845833333333333, 'avg_raw_dharma_score': 0.6166666666666666, 'avg_raw_helpfulness_score': 0.6000000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6020416666666666}
2025-05-11 02:16:47,482 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7041666666666666, 'avg_raw_dharma_score': 0.6291666666666667, 'avg_raw_helpfulness_score': 0.5916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6404166666666665}
2025-05-11 02:16:48,227 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7000000000000001, 'avg_raw_dharma_score': 0.85, 'avg_raw_helpfulness_score': 0.6749999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7525}
  warnings.warn(
2025-05-11 02:17:46,212 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5145833333333333, 'avg_raw_dharma_score': 0.7291666666666666, 'avg_raw_helpfulness_score': 0.6166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6310416666666666}
2025-05-11 02:17:52,902 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6166666666666667, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.6749999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7208333333333333}
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 21121/24000 [8:34:08<6:50:49,  8.56s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 21122/24000 [8:34:09<4:56:32,  6.18s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 21123/24000 [8:34:10<3:36:33,  4.52s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 21124/24000 [8:34:10<2:40:35,  3.35s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 21125/24000 [8:34:11<2:01:25,  2.53s/it]                                                         {'loss': 0.2565, 'grad_norm': 12.9375, 'learning_rate': 1.0679789939611156e-07, 'kl': 2.0261064155896507, 'clip_ratio/low_mean': 5.167958637078603e-05, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0009147436881903559, 'clip_ratio/high_max': 0.001469296512659639, 'clip_ratio/region_mean': 0.0009664232745611419, 'num_tokens': 4670518.0, 'completions/mean_length': 258.54168701171875, 'completions/min_length': 1.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.08333333333333337, 'completions/mean_terminated_length': 235.5, 'completions/min_terminated_length': 1.0, 'completions/max_terminated_length': 435.0, 'rewards/combined_reward_trl/mean': 0.6759374737739563, 'rewards/combined_reward_trl/std': 0.2547577917575836, 'reward': 0.6759375333786011, 'reward_std': 0.2342764139175415, 'epoch': 7.04}
2025-05-11 02:18:47,399 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5529166666666667, 'avg_raw_dharma_score': 0.6916666666666668, 'avg_raw_helpfulness_score': 0.6166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6275416666666667}
2025-05-11 02:18:48,498 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.47083333333333327, 'avg_raw_dharma_score': 0.5416666666666666, 'avg_raw_helpfulness_score': 0.5666666666666665, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5279166666666667}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 02:19:41,339 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5083333333333333, 'avg_raw_dharma_score': 0.6999999999999998, 'avg_raw_helpfulness_score': 0.5750000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.605}
2025-05-11 02:19:57,844 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6, 'avg_raw_dharma_score': 0.7583333333333333, 'avg_raw_helpfulness_score': 0.6833333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6883333333333334}
2025-05-11 02:20:50,394 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.425, 'avg_raw_dharma_score': 0.6083333333333333, 'avg_raw_helpfulness_score': 0.5249999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5283333333333333}
2025-05-11 02:20:51,370 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7958333333333334, 'avg_raw_dharma_score': 0.8583333333333334, 'avg_raw_helpfulness_score': 0.725, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7995833333333334}
2025-05-11 02:21:42,436 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6236111111111111, 'avg_raw_dharma_score': 0.7583333333333334, 'avg_raw_helpfulness_score': 0.6666666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6904166666666667}
2025-05-11 02:21:43,959 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6604166666666667, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.775, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7639583333333332}
  warnings.warn(
2025-05-11 02:22:49,337 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5595833333333333, 'avg_raw_dharma_score': 0.7833333333333333, 'avg_raw_helpfulness_score': 0.6916666666666665, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6887083333333334}
2025-05-11 02:22:49,995 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7645833333333333, 'avg_raw_dharma_score': 0.7083333333333334, 'avg_raw_helpfulness_score': 0.7916666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7502083333333335}
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 21321/24000 [8:39:06<6:35:32,  8.86s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 21322/24000 [8:39:06<4:45:15,  6.39s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 21323/24000 [8:39:07<3:28:05,  4.66s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 21324/24000 [8:39:07<2:34:06,  3.46s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 21325/24000 [8:39:08<1:56:19,  2.61s/it]                                                         {'loss': 0.1471, 'grad_norm': 11.6875, 'learning_rate': 9.261022717688733e-08, 'kl': 1.4570463792483013, 'clip_ratio/low_mean': 1.3704404312496383e-05, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.000995863559267794, 'clip_ratio/high_max': 0.001657324112796535, 'clip_ratio/region_mean': 0.0010095679647444437, 'num_tokens': 4715275.0, 'completions/mean_length': 369.625, 'completions/min_length': 176.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 349.28570556640625, 'completions/min_terminated_length': 176.0, 'completions/max_terminated_length': 510.0, 'rewards/combined_reward_trl/mean': 0.7194583415985107, 'rewards/combined_reward_trl/std': 0.25198838114738464, 'reward': 0.7194583415985107, 'reward_std': 0.19867560267448425, 'epoch': 7.11}
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 21325/24000 [8:39:08<1:56:19,  2.61s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 21326/24000 [8:39:09<1:29:55,  2.02s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 21327/24000 [8:39:09<1:11:24,  1.60s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 21328/24000 [8:39:10<58:26,  1.31s/it]   89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 21329/24000 [8:39:11<49:21,  1.11s/it]wandb: WARNING Tried to log to step 21325 that is less than the current step 194379. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-11 02:23:40,836 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7041666666666666, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.75, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7362500000000001}
2025-05-11 02:23:45,576 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.59375, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.5083333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6472916666666667}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 02:24:37,278 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8524999999999999, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.9083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.9115833333333335}
2025-05-11 02:24:51,227 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7041666666666666, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.7250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7287499999999999}
2025-05-11 02:25:37,981 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6458333333333334, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.725, 'avg_penalty': 0.0, 'avg_combined_reward': 0.71125}
2025-05-11 02:25:42,300 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6295833333333334, 'avg_raw_dharma_score': 0.6291666666666667, 'avg_raw_helpfulness_score': 0.625, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6280416666666667}
2025-05-11 02:26:32,670 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7833333333333332, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.8083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8608333333333333}
2025-05-11 02:26:34,286 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8054166666666666, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.8250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8557916666666668}
  warnings.warn(
2025-05-11 02:27:35,621 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7290277777777779, 'avg_raw_dharma_score': 0.8583333333333334, 'avg_raw_helpfulness_score': 0.75, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7870416666666668}
2025-05-11 02:27:39,023 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7554166666666667, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.7833333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8449583333333334}
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 21521/24000 [8:43:55<5:54:09,  8.57s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 21522/24000 [8:43:55<4:15:36,  6.19s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 21523/24000 [8:43:56<3:06:35,  4.52s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 21524/24000 [8:43:56<2:18:20,  3.35s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 21525/24000 [8:43:57<1:44:32,  2.53s/it]                                                         {'loss': 0.1118, 'grad_norm': 18.5, 'learning_rate': 7.940338777774142e-08, 'kl': 0.8768125142653783, 'clip_ratio/low_mean': 0.00013738103831807772, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0012081697055449088, 'clip_ratio/high_max': 0.0017220972082577647, 'clip_ratio/region_mean': 0.0013455507477434974, 'num_tokens': 4755694.0, 'completions/mean_length': 323.79168701171875, 'completions/min_length': 201.0, 'completions/max_length': 501.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 323.79168701171875, 'completions/min_terminated_length': 201.0, 'completions/max_terminated_length': 501.0, 'rewards/combined_reward_trl/mean': 0.8159999847412109, 'rewards/combined_reward_trl/std': 0.1990981251001358, 'reward': 0.8159999847412109, 'reward_std': 0.18626877665519714, 'epoch': 7.17}
2025-05-11 02:28:31,645 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6554166666666666, 'avg_raw_dharma_score': 0.7999999999999999, 'avg_raw_helpfulness_score': 0.7166666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7316250000000001}
2025-05-11 02:28:32,648 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6208333333333333, 'avg_raw_dharma_score': 0.8083333333333332, 'avg_raw_helpfulness_score': 0.7083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7220833333333333}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 02:29:25,480 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5211111111111111, 'avg_raw_dharma_score': 0.6333333333333333, 'avg_raw_helpfulness_score': 0.4833333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5546666666666668}
2025-05-11 02:29:32,511 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7916666666666666, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.7500000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8291666666666667}
2025-05-11 02:30:27,429 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.63125, 'avg_raw_dharma_score': 0.9416666666666668, 'avg_raw_helpfulness_score': 0.7583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7935416666666667}
2025-05-11 02:30:31,501 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6304166666666666, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.7083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7516250000000001}
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 21641/24000 [8:46:47<7:03:46, 10.78s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 21642/24000 [8:46:48<5:04:00,  7.74s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 21643/24000 [8:46:48<3:40:08,  5.60s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 21644/24000 [8:46:49<2:41:26,  4.11s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 21645/24000 [8:46:50<2:00:22,  3.07s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 21646/24000 [8:46:50<1:31:38,  2.34s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 21647/24000 [8:46:51<1:11:31,  1.82s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 21648/24000 [8:46:51<57:26,  1.47s/it]   90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 21649/24000 [8:46:52<47:36,  1.21s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 21650/24000 [8:46:53<40:42,  1.04s/it]                                                       {'loss': 0.2344, 'grad_norm': 9.6875, 'learning_rate': 7.16513106865464e-08, 'kl': 2.0936707973480226, 'clip_ratio/low_mean': 0.00013522492139600217, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0006333193799946457, 'clip_ratio/high_max': 0.0010899031814187764, 'clip_ratio/region_mean': 0.0007685442998384436, 'num_tokens': 4781537.0, 'completions/mean_length': 359.79168701171875, 'completions/min_length': 208.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.20833333333333337, 'completions/mean_terminated_length': 319.7368469238281, 'completions/min_terminated_length': 208.0, 'completions/max_terminated_length': 471.0, 'rewards/combined_reward_trl/mean': 0.7725833058357239, 'rewards/combined_reward_trl/std': 0.20377591252326965, 'reward': 0.7725833654403687, 'reward_std': 0.1525348424911499, 'epoch': 7.22}
2025-05-11 02:31:23,037 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6375, 'avg_raw_dharma_score': 0.8416666666666667, 'avg_raw_helpfulness_score': 0.6666666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7279166666666668}
2025-05-11 02:31:24,454 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.33125000000000004, 'avg_raw_dharma_score': 0.39999999999999997, 'avg_raw_helpfulness_score': 0.3666666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.369375}
  warnings.warn(
2025-05-11 02:32:30,710 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6679166666666667, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.7333333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7703750000000001}
2025-05-11 02:32:31,138 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7458333333333335, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.725, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8079166666666668}
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 21721/24000 [8:48:47<5:45:58,  9.11s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 21722/24000 [8:48:47<4:09:18,  6.57s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 21723/24000 [8:48:48<3:01:39,  4.79s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 21724/24000 [8:48:49<2:14:19,  3.54s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 21725/24000 [8:48:49<1:41:11,  2.67s/it]                                                         {'loss': 0.2959, 'grad_norm': 24.5, 'learning_rate': 6.718658525982474e-08, 'kl': 2.7362808243433636, 'clip_ratio/low_mean': 1.8302447473009427e-05, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.00042903742636553945, 'clip_ratio/high_max': 0.0007383720149906973, 'clip_ratio/region_mean': 0.000447339874614651, 'num_tokens': 4798312.0, 'completions/mean_length': 310.41668701171875, 'completions/min_length': 1.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.08333333333333337, 'completions/mean_terminated_length': 292.0909118652344, 'completions/min_terminated_length': 1.0, 'completions/max_terminated_length': 504.0, 'rewards/combined_reward_trl/mean': 0.7891458868980408, 'rewards/combined_reward_trl/std': 0.2500515580177307, 'reward': 0.7891458868980408, 'reward_std': 0.20173990726470947, 'epoch': 7.24}
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 21725/24000 [8:48:49<1:41:11,  2.67s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 21726/24000 [8:48:50<1:18:04,  2.06s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 21727/24000 [8:48:50<1:01:50,  1.63s/it]wandb: WARNING Tried to log to step 21725 that is less than the current step 198025. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-11 02:33:23,011 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6416666666666667, 'avg_raw_dharma_score': 0.7374999999999999, 'avg_raw_helpfulness_score': 0.6416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.68}
2025-05-11 02:33:26,138 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7220833333333334, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.7250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7674583333333335}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 02:34:19,883 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5495833333333334, 'avg_raw_dharma_score': 0.5666666666666667, 'avg_raw_helpfulness_score': 0.6166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5765416666666666}
2025-05-11 02:34:35,215 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5929166666666666, 'avg_raw_dharma_score': 0.65, 'avg_raw_helpfulness_score': 0.5416666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.600375}
2025-05-11 02:35:26,745 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5370833333333334, 'avg_raw_dharma_score': 0.6916666666666668, 'avg_raw_helpfulness_score': 0.5833333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6127916666666667}
2025-05-11 02:35:28,594 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.54, 'avg_raw_dharma_score': 0.7000000000000001, 'avg_raw_helpfulness_score': 0.5833333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.617}
2025-05-11 02:36:22,288 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6749999999999999, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.6750000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7216666666666667}
2025-05-11 02:36:23,006 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5666666666666668, 'avg_raw_dharma_score': 0.7999999999999999, 'avg_raw_helpfulness_score': 0.6333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.68}
  warnings.warn(
2025-05-11 02:37:26,981 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5861111111111111, 'avg_raw_dharma_score': 0.5583333333333333, 'avg_raw_helpfulness_score': 0.5416666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5616666666666668}
2025-05-11 02:37:29,988 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6791666666666666, 'avg_raw_dharma_score': 0.9, 'avg_raw_helpfulness_score': 0.7250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7812500000000001}
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 21921/24000 [8:53:45<4:59:47,  8.65s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 21922/24000 [8:53:46<3:36:22,  6.25s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 21923/24000 [8:53:47<2:38:03,  4.57s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 21924/24000 [8:53:47<1:57:11,  3.39s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 21925/24000 [8:53:48<1:28:36,  2.56s/it]                                                         {'loss': 0.1844, 'grad_norm': 15.625, 'learning_rate': 5.5968333711485466e-08, 'kl': 1.957160017490387, 'clip_ratio/low_mean': 3.253140098725756e-05, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0008616403478663415, 'clip_ratio/high_max': 0.0012957031605765224, 'clip_ratio/region_mean': 0.0008941717488535991, 'num_tokens': 4841629.0, 'completions/mean_length': 299.7083435058594, 'completions/min_length': 36.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.04166666666666663, 'completions/mean_terminated_length': 290.478271484375, 'completions/min_terminated_length': 36.0, 'completions/max_terminated_length': 457.0, 'rewards/combined_reward_trl/mean': 0.6714583039283752, 'rewards/combined_reward_trl/std': 0.28958919644355774, 'reward': 0.6714584231376648, 'reward_std': 0.22483567893505096, 'epoch': 7.31}
2025-05-11 02:38:19,573 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7229166666666665, 'avg_raw_dharma_score': 1.0, 'avg_raw_helpfulness_score': 0.8500000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8718750000000002}
2025-05-11 02:38:21,535 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6816666666666668, 'avg_raw_dharma_score': 0.8416666666666667, 'avg_raw_helpfulness_score': 0.7250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7586666666666667}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 02:39:12,658 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4637500000000001, 'avg_raw_dharma_score': 0.7333333333333334, 'avg_raw_helpfulness_score': 0.575, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6049583333333334}
2025-05-11 02:39:27,733 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6083333333333333, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.625, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7033333333333333}
2025-05-11 02:40:19,556 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6995833333333334, 'avg_raw_dharma_score': 0.7083333333333334, 'avg_raw_helpfulness_score': 0.7166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7082083333333333}
2025-05-11 02:40:20,476 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5333333333333333, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.6, 'avg_penalty': 0.0, 'avg_combined_reward': 0.64}
                                                       {'loss': 0.1957, 'grad_norm': 9.3125, 'learning_rate': 4.946750621416252e-08, 'kl': 2.1763009532292683, 'clip_ratio/low_mean': 5.373176730548342e-05, 'clip_ratio/low_min': 1.8277359195053578e-05, 'clip_ratio/high_mean': 0.0006679178619136413, 'clip_ratio/high_max': 0.0010557721679409346, 'clip_ratio/region_mean': 0.0007216496276669204, 'num_tokens': 4868081.0, 'completions/mean_length': 339.9583435058594, 'completions/min_length': 1.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.16666666666666663, 'completions/mean_terminated_length': 305.5500183105469, 'completions/min_terminated_length': 1.0, 'completions/max_terminated_length': 484.0, 'rewards/combined_reward_trl/mean': 0.6741042137145996, 'rewards/combined_reward_trl/std': 0.27897152304649353, 'reward': 0.6741042137145996, 'reward_std': 0.18840736150741577, 'epoch': 7.35}
2025-05-11 02:41:12,881 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7895833333333333, 'avg_raw_dharma_score': 0.8375, 'avg_raw_helpfulness_score': 0.725, 'avg_penalty': 0.0, 'avg_combined_reward': 0.789375}
2025-05-11 02:41:13,224 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6483333333333333, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.7416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.767}
  warnings.warn(
2025-05-11 02:42:19,206 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7416666666666667, 'avg_raw_dharma_score': 0.9833333333333334, 'avg_raw_helpfulness_score': 0.8416666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8683333333333333}
2025-05-11 02:42:22,944 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5208333333333334, 'avg_raw_dharma_score': 0.28750000000000003, 'avg_raw_helpfulness_score': 0.6083333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.4537500000000001}
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 22121/24000 [8:58:38<4:56:24,  9.46s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 22122/24000 [8:58:39<3:33:24,  6.82s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 22123/24000 [8:58:40<2:35:16,  4.96s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 22124/24000 [8:58:40<1:54:37,  3.67s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 22125/24000 [8:58:41<1:26:09,  2.76s/it]                                                         {'loss': 0.172, 'grad_norm': 12.1875, 'learning_rate': 4.5756451314662275e-08, 'kl': 1.4639456129074098, 'clip_ratio/low_mean': 1.771735221457978e-05, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0011161815219869217, 'clip_ratio/high_max': 0.0016481951538783808, 'clip_ratio/region_mean': 0.0011338988742015015, 'num_tokens': 4885742.0, 'completions/mean_length': 363.04168701171875, 'completions/min_length': 191.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 341.76190185546875, 'completions/min_terminated_length': 191.0, 'completions/max_terminated_length': 510.0, 'rewards/combined_reward_trl/mean': 0.6610416769981384, 'rewards/combined_reward_trl/std': 0.2772064805030823, 'reward': 0.6610417366027832, 'reward_std': 0.13391169905662537, 'epoch': 7.38}
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 22125/24000 [8:58:41<1:26:09,  2.76s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 22126/24000 [8:58:42<1:06:18,  2.12s/it]wandb: WARNING Tried to log to step 22125 that is less than the current step 201671. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-11 02:43:15,433 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6916666666666668, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.7333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7608333333333333}
2025-05-11 02:43:16,467 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5479166666666666, 'avg_raw_dharma_score': 0.5958333333333333, 'avg_raw_helpfulness_score': 0.5666666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5727083333333334}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 02:44:12,544 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6124999999999999, 'avg_raw_dharma_score': 0.7999999999999999, 'avg_raw_helpfulness_score': 0.6583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.70125}
2025-05-11 02:44:22,387 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6708333333333333, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.6666666666666669, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7512500000000001}
2025-05-11 02:45:13,743 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.525, 'avg_raw_dharma_score': 0.7083333333333334, 'avg_raw_helpfulness_score': 0.5833333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6158333333333333}
2025-05-11 02:45:15,402 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4166666666666667, 'avg_raw_dharma_score': 0.4666666666666666, 'avg_raw_helpfulness_score': 0.44166666666666665, 'avg_penalty': 0.0, 'avg_combined_reward': 0.44416666666666665}
2025-05-11 02:46:08,776 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5041666666666665, 'avg_raw_dharma_score': 0.7000000000000001, 'avg_raw_helpfulness_score': 0.5833333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.60625}
2025-05-11 02:46:10,396 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6041666666666667, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.6333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7212500000000001}
  warnings.warn(
2025-05-11 02:47:14,883 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7583333333333333, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.8250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8250000000000001}
2025-05-11 02:47:16,110 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6029166666666667, 'avg_raw_dharma_score': 0.7333333333333334, 'avg_raw_helpfulness_score': 0.6250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6617083333333333}
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 22321/24000 [9:03:32<4:06:57,  8.83s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 22322/24000 [9:03:32<2:58:04,  6.37s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 22323/24000 [9:03:33<2:09:51,  4.65s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 22324/24000 [9:03:34<1:36:09,  3.44s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 22325/24000 [9:03:34<1:12:33,  2.60s/it]                                                         {'loss': 0.4069, 'grad_norm': 11.1875, 'learning_rate': 3.6558054896266293e-08, 'kl': 2.5513477381070455, 'clip_ratio/low_mean': 7.95819874232014e-06, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0006642784636157255, 'clip_ratio/high_max': 0.000917893978767097, 'clip_ratio/region_mean': 0.0006722366627460966, 'num_tokens': 4929640.0, 'completions/mean_length': 343.54168701171875, 'completions/min_length': 143.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.16666666666666663, 'completions/mean_terminated_length': 309.8500061035156, 'completions/min_terminated_length': 143.0, 'completions/max_terminated_length': 449.0, 'rewards/combined_reward_trl/mean': 0.7433541417121887, 'rewards/combined_reward_trl/std': 0.2964690923690796, 'reward': 0.7433542013168335, 'reward_std': 0.2853527069091797, 'epoch': 7.44}
2025-05-11 02:48:02,380 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6387499999999999, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.6916666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7324583333333333}
2025-05-11 02:48:09,126 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7275, 'avg_raw_dharma_score': 0.9458333333333333, 'avg_raw_helpfulness_score': 0.7999999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8365833333333335}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 02:49:00,834 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7395833333333334, 'avg_raw_dharma_score': 0.9416666666666668, 'avg_raw_helpfulness_score': 0.7583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8260416666666667}
2025-05-11 02:49:14,674 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6083333333333334, 'avg_raw_dharma_score': 0.7000000000000001, 'avg_raw_helpfulness_score': 0.6749999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.665}
2025-05-11 02:50:04,841 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8250000000000001, 'avg_raw_dharma_score': 0.9833333333333334, 'avg_raw_helpfulness_score': 0.8583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8983333333333334}
2025-05-11 02:50:09,987 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5370833333333334, 'avg_raw_dharma_score': 0.625, 'avg_raw_helpfulness_score': 0.525, 'avg_penalty': 0.0, 'avg_combined_reward': 0.568625}
2025-05-11 02:51:00,963 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5583333333333332, 'avg_raw_dharma_score': 0.6916666666666668, 'avg_raw_helpfulness_score': 0.5750000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6166666666666666}
2025-05-11 02:51:03,084 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.625, 'avg_raw_dharma_score': 0.6333333333333333, 'avg_raw_helpfulness_score': 0.6416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6333333333333333}
  warnings.warn(
2025-05-11 02:52:08,416 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6954166666666667, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.75, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7669583333333332}
2025-05-11 02:52:08,689 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6029166666666667, 'avg_raw_dharma_score': 0.6625, 'avg_raw_helpfulness_score': 0.6333333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6358750000000001}
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 22521/24000 [9:08:24<3:34:03,  8.68s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 22522/24000 [9:08:25<2:34:25,  6.27s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 22523/24000 [9:08:25<1:52:42,  4.58s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 22524/24000 [9:08:26<1:23:31,  3.40s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 22525/24000 [9:08:27<1:03:10,  2.57s/it]                                                         {'loss': 0.2036, 'grad_norm': 14.6875, 'learning_rate': 2.837955496834821e-08, 'kl': 1.936781078974406, 'clip_ratio/low_mean': 8.612682577222586e-06, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0009671264029263208, 'clip_ratio/high_max': 0.0013456125472051403, 'clip_ratio/region_mean': 0.0009757390866676967, 'num_tokens': 4974750.0, 'completions/mean_length': 362.5, 'completions/min_length': 213.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 341.1428527832031, 'completions/min_terminated_length': 213.0, 'completions/max_terminated_length': 506.0, 'rewards/combined_reward_trl/mean': 0.7014166712760925, 'rewards/combined_reward_trl/std': 0.2311316877603531, 'reward': 0.7014166712760925, 'reward_std': 0.20715372264385223, 'epoch': 7.51}
2025-05-11 02:52:59,712 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6429166666666668, 'avg_raw_dharma_score': 0.65, 'avg_raw_helpfulness_score': 0.6416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.645375}
2025-05-11 02:53:02,394 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5583333333333332, 'avg_raw_dharma_score': 0.7083333333333334, 'avg_raw_helpfulness_score': 0.6, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6308333333333335}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 02:53:58,976 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4708333333333334, 'avg_raw_dharma_score': 0.625, 'avg_raw_helpfulness_score': 0.6083333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.57375}
2025-05-11 02:54:10,249 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6458333333333334, 'avg_raw_dharma_score': 0.7583333333333333, 'avg_raw_helpfulness_score': 0.7166666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7120833333333333}
2025-05-11 02:54:58,299 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7691666666666669, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.775, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8299166666666667}
2025-05-11 02:55:02,857 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.67625, 'avg_raw_dharma_score': 0.7333333333333334, 'avg_raw_helpfulness_score': 0.7833333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7312083333333333}
2025-05-11 02:55:53,244 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5333333333333333, 'avg_raw_dharma_score': 0.48333333333333334, 'avg_raw_helpfulness_score': 0.6416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5458333333333333}
2025-05-11 02:55:54,602 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6708333333333334, 'avg_raw_dharma_score': 0.8083333333333332, 'avg_raw_helpfulness_score': 0.7166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7395833333333334}
  warnings.warn(
2025-05-11 02:56:57,125 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5708333333333334, 'avg_raw_dharma_score': 0.44166666666666665, 'avg_raw_helpfulness_score': 0.6083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5304166666666666}
2025-05-11 02:57:00,054 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5895833333333335, 'avg_raw_dharma_score': 0.7749999999999999, 'avg_raw_helpfulness_score': 0.5833333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6618750000000001}
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 22721/24000 [9:13:16<3:06:04,  8.73s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 22722/24000 [9:13:16<2:14:12,  6.30s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 22723/24000 [9:13:17<1:37:55,  4.60s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 22724/24000 [9:13:17<1:12:33,  3.41s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 22725/24000 [9:13:18<54:47,  2.58s/it]                                                         {'loss': 0.1881, 'grad_norm': 16.25, 'learning_rate': 2.122665126050949e-08, 'kl': 1.5553418427705765, 'clip_ratio/low_mean': 4.7365305945277215e-05, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0006308577240755161, 'clip_ratio/high_max': 0.001122459537970523, 'clip_ratio/region_mean': 0.0006782230292446911, 'num_tokens': 5018521.0, 'completions/mean_length': 333.4583435058594, 'completions/min_length': 2.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.08333333333333337, 'completions/mean_terminated_length': 317.227294921875, 'completions/min_terminated_length': 2.0, 'completions/max_terminated_length': 494.0, 'rewards/combined_reward_trl/mean': 0.5961458086967468, 'rewards/combined_reward_trl/std': 0.26277363300323486, 'reward': 0.5961458683013916, 'reward_std': 0.24759364128112793, 'epoch': 7.58}
2025-05-11 02:57:52,068 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6770833333333334, 'avg_raw_dharma_score': 0.9583333333333334, 'avg_raw_helpfulness_score': 0.8250000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8339583333333334}
2025-05-11 02:57:52,820 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6570833333333334, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.7000000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7404583333333333}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 02:58:46,613 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7125, 'avg_raw_dharma_score': 0.7458333333333332, 'avg_raw_helpfulness_score': 0.775, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7445833333333334}
2025-05-11 02:59:02,707 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7187500000000001, 'avg_raw_dharma_score': 0.7083333333333334, 'avg_raw_helpfulness_score': 0.7166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7139583333333334}
2025-05-11 02:59:54,647 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5666666666666667, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.6416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6625}
2025-05-11 02:59:54,773 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5783333333333335, 'avg_raw_dharma_score': 0.7375000000000002, 'avg_raw_helpfulness_score': 0.625, 'avg_penalty': 0.0, 'avg_combined_reward': 0.656}
2025-05-11 03:00:52,938 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7375000000000002, 'avg_raw_dharma_score': 0.7999999999999999, 'avg_raw_helpfulness_score': 0.7333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.76125}
2025-05-11 03:00:53,211 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.49124999999999996, 'avg_raw_dharma_score': 0.625, 'avg_raw_helpfulness_score': 0.575, 'avg_penalty': 0.0, 'avg_combined_reward': 0.569875}
  warnings.warn(
2025-05-11 03:02:04,837 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6541666666666667, 'avg_raw_dharma_score': 0.7541666666666668, 'avg_raw_helpfulness_score': 0.5916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6754166666666667}
2025-05-11 03:02:06,105 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6720833333333335, 'avg_raw_dharma_score': 0.8000000000000002, 'avg_raw_helpfulness_score': 0.6749999999999999, 'avg_penalty': 0.0, 'avg_combined_reward': 0.724125}
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 22921/24000 [9:18:22<3:17:17, 10.97s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 22922/24000 [9:18:22<2:21:23,  7.87s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 22923/24000 [9:18:23<1:42:17,  5.70s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 22924/24000 [9:18:24<1:14:56,  4.18s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 22925/24000 [9:18:24<55:48,  3.11s/it]                                                         {'loss': 0.2412, 'grad_norm': 17.875, 'learning_rate': 1.510432874766665e-08, 'kl': 2.413711915810903, 'clip_ratio/low_mean': 1.0887865598003069e-05, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0007625464567293723, 'clip_ratio/high_max': 0.0011868364076750974, 'clip_ratio/region_mean': 0.0007734343223273754, 'num_tokens': 5061914.0, 'completions/mean_length': 276.91668701171875, 'completions/min_length': 67.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 243.33334350585938, 'completions/min_terminated_length': 67.0, 'completions/max_terminated_length': 449.0, 'rewards/combined_reward_trl/mean': 0.6997708678245544, 'rewards/combined_reward_trl/std': 0.27467164397239685, 'reward': 0.6997709274291992, 'reward_std': 0.1866021752357483, 'epoch': 7.64}
2025-05-11 03:03:00,718 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.3875, 'avg_raw_dharma_score': 0.33749999999999997, 'avg_raw_helpfulness_score': 0.4666666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.39125000000000004}
2025-05-11 03:03:02,406 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7000000000000001, 'avg_raw_dharma_score': 0.8249999999999998, 'avg_raw_helpfulness_score': 0.7166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7549999999999999}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 03:03:57,069 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6791666666666667, 'avg_raw_dharma_score': 0.8166666666666668, 'avg_raw_helpfulness_score': 0.7333333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7504166666666667}
2025-05-11 03:04:08,065 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6749999999999998, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.7666666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7658333333333333}
2025-05-11 03:04:55,660 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6375000000000002, 'avg_raw_dharma_score': 0.7958333333333334, 'avg_raw_helpfulness_score': 0.6833333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7145833333333332}
2025-05-11 03:05:03,820 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.65, 'avg_raw_dharma_score': 0.8125, 'avg_raw_helpfulness_score': 0.6250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7075}
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 23041/24000 [9:21:19<2:36:53,  9.82s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 23042/24000 [9:21:20<1:52:43,  7.06s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 23043/24000 [9:21:21<1:21:50,  5.13s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 23044/24000 [9:21:21<1:00:14,  3.78s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 23045/24000 [9:21:22<45:08,  2.84s/it]   96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 23046/24000 [9:21:22<34:34,  2.18s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 23047/24000 [9:21:23<27:11,  1.71s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 23048/24000 [9:21:24<22:01,  1.39s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 23049/24000 [9:21:24<18:24,  1.16s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 23050/24000 [9:21:25<15:52,  1.00s/it]                                                       {'loss': 0.1212, 'grad_norm': 11.0, 'learning_rate': 1.1803145071034305e-08, 'kl': 1.3025508761405944, 'clip_ratio/low_mean': 8.772680613522728e-05, 'clip_ratio/low_min': 2.0449897274374962e-05, 'clip_ratio/high_mean': 0.0014398031417901316, 'clip_ratio/high_max': 0.0021237440795327227, 'clip_ratio/region_mean': 0.0015275299510297677, 'num_tokens': 5086612.0, 'completions/mean_length': 306.75, 'completions/min_length': 29.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 277.4285888671875, 'completions/min_terminated_length': 29.0, 'completions/max_terminated_length': 429.0, 'rewards/combined_reward_trl/mean': 0.7110416889190674, 'rewards/combined_reward_trl/std': 0.24158844351768494, 'reward': 0.7110416889190674, 'reward_std': 0.18108263611793518, 'epoch': 7.68}
2025-05-11 03:05:56,491 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5708333333333334, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.5750000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6437499999999999}
2025-05-11 03:05:56,498 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7958333333333333, 'avg_raw_dharma_score': 0.9500000000000001, 'avg_raw_helpfulness_score': 0.8250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.86625}
  warnings.warn(
2025-05-11 03:07:02,556 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7541666666666668, 'avg_raw_dharma_score': 0.8125, 'avg_raw_helpfulness_score': 0.7666666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.78125}
2025-05-11 03:07:03,633 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5055555555555555, 'avg_raw_dharma_score': 0.7583333333333333, 'avg_raw_helpfulness_score': 0.6833333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.66}
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 23121/24000 [9:23:19<2:14:51,  9.21s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 23122/24000 [9:23:20<1:37:05,  6.63s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 23123/24000 [9:23:20<1:10:39,  4.83s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 23124/24000 [9:23:21<52:11,  3.57s/it]   96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 23125/24000 [9:23:22<39:16,  2.69s/it]                                                       {'loss': 0.209, 'grad_norm': 8.625, 'learning_rate': 1.001685417594178e-08, 'kl': 1.9647105087836583, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0012014095326109478, 'clip_ratio/high_max': 0.0017534776676135758, 'clip_ratio/region_mean': 0.0012014095326109478, 'num_tokens': 5103844.0, 'completions/mean_length': 279.41668701171875, 'completions/min_length': 1.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.04166666666666663, 'completions/mean_terminated_length': 269.3043518066406, 'completions/min_terminated_length': 1.0, 'completions/max_terminated_length': 461.0, 'rewards/combined_reward_trl/mean': 0.7206249833106995, 'rewards/combined_reward_trl/std': 0.21386867761611938, 'reward': 0.7206250429153442, 'reward_std': 0.19903108477592468, 'epoch': 7.71}
2025-05-11 03:07:54,613 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.53625, 'avg_raw_dharma_score': 0.75, 'avg_raw_helpfulness_score': 0.65, 'avg_penalty': 0.0, 'avg_combined_reward': 0.655875}
2025-05-11 03:07:55,990 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.3770833333333334, 'avg_raw_dharma_score': 0.44166666666666665, 'avg_raw_helpfulness_score': 0.4000000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.4097916666666666}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 03:08:48,500 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.625, 'avg_raw_dharma_score': 0.6458333333333334, 'avg_raw_helpfulness_score': 0.6083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6283333333333334}
2025-05-11 03:09:02,915 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6763888888888888, 'avg_raw_dharma_score': 0.9, 'avg_raw_helpfulness_score': 0.7916666666666669, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8004166666666667}
2025-05-11 03:09:55,226 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.50625, 'avg_raw_dharma_score': 0.5208333333333334, 'avg_raw_helpfulness_score': 0.5083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5127083333333333}
2025-05-11 03:09:59,457 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.8166666666666665, 'avg_raw_dharma_score': 0.6458333333333334, 'avg_raw_helpfulness_score': 0.75, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7283333333333334}
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 23241/24000 [9:26:15<2:06:24,  9.99s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 23242/24000 [9:26:16<1:30:45,  7.18s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 23243/24000 [9:26:16<1:05:50,  5.22s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 23244/24000 [9:26:17<48:25,  3.84s/it]   97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 23245/24000 [9:26:17<36:15,  2.88s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 23246/24000 [9:26:18<27:43,  2.21s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 23247/24000 [9:26:19<21:46,  1.73s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 23248/24000 [9:26:19<17:35,  1.40s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 23249/24000 [9:26:20<14:40,  1.17s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 23250/24000 [9:26:21<12:38,  1.01s/it]                                                       {'loss': 0.1098, 'grad_norm': 9.1875, 'learning_rate': 7.364296822098549e-09, 'kl': 1.6833010935783386, 'clip_ratio/low_mean': 0.00016298111140107115, 'clip_ratio/low_min': 2.4668561139454444e-05, 'clip_ratio/high_mean': 0.0009479850879870356, 'clip_ratio/high_max': 0.0015229427783439557, 'clip_ratio/region_mean': 0.0011109661986120046, 'num_tokens': 5132099.0, 'completions/mean_length': 376.29168701171875, 'completions/min_length': 71.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 356.9047546386719, 'completions/min_terminated_length': 71.0, 'completions/max_terminated_length': 498.0, 'rewards/combined_reward_trl/mean': 0.620520830154419, 'rewards/combined_reward_trl/std': 0.2827504277229309, 'reward': 0.6205209493637085, 'reward_std': 0.2283896654844284, 'epoch': 7.75}
2025-05-11 03:10:51,914 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6262500000000001, 'avg_raw_dharma_score': 0.7958333333333334, 'avg_raw_helpfulness_score': 0.6750000000000002, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7087083333333334}
2025-05-11 03:10:52,794 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6754166666666667, 'avg_raw_dharma_score': 0.8833333333333333, 'avg_raw_helpfulness_score': 0.7416666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7784583333333334}
  warnings.warn(
2025-05-11 03:11:57,566 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6625, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.75, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7404166666666666}
2025-05-11 03:11:57,760 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5648611111111113, 'avg_raw_dharma_score': 0.5833333333333334, 'avg_raw_helpfulness_score': 0.5583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5702916666666668}
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 23321/24000 [9:28:13<1:37:06,  8.58s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 23322/24000 [9:28:14<1:10:01,  6.20s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 23323/24000 [9:28:15<51:04,  4.53s/it]   97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 23324/24000 [9:28:15<37:50,  3.36s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 23325/24000 [9:28:16<28:34,  2.54s/it]                                                       {'loss': 0.3396, 'grad_norm': 20.5, 'learning_rate': 5.967773089098294e-09, 'kl': 2.37567944308122, 'clip_ratio/low_mean': 5.4841821159546575e-05, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0006611608120147139, 'clip_ratio/high_max': 0.0011221117751362424, 'clip_ratio/region_mean': 0.0007160026358906179, 'num_tokens': 5148529.0, 'completions/mean_length': 308.0833435058594, 'completions/min_length': 76.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.16666666666666663, 'completions/mean_terminated_length': 267.3000183105469, 'completions/min_terminated_length': 76.0, 'completions/max_terminated_length': 407.0, 'rewards/combined_reward_trl/mean': 0.6553542017936707, 'rewards/combined_reward_trl/std': 0.3606528639793396, 'reward': 0.6553542017936707, 'reward_std': 0.2431390881538391, 'epoch': 7.78}
2025-05-11 03:12:48,317 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6111111111111112, 'avg_raw_dharma_score': 0.7083333333333334, 'avg_raw_helpfulness_score': 0.625, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6541666666666667}
2025-05-11 03:12:49,047 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7054166666666667, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.7666666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7916250000000001}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 03:13:40,124 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6833333333333335, 'avg_raw_dharma_score': 0.8125, 'avg_raw_helpfulness_score': 0.6416666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7225000000000001}
2025-05-11 03:13:52,952 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.775, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.8333333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7491666666666669}
2025-05-11 03:14:44,741 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6683333333333334, 'avg_raw_dharma_score': 0.8833333333333333, 'avg_raw_helpfulness_score': 0.7583333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7813333333333334}
2025-05-11 03:14:44,906 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5775000000000001, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.6583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6374166666666666}
2025-05-11 03:15:36,186 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6333333333333333, 'avg_raw_dharma_score': 0.6666666666666666, 'avg_raw_helpfulness_score': 0.6166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6416666666666666}
2025-05-11 03:15:37,555 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7458333333333335, 'avg_raw_dharma_score': 0.9166666666666666, 'avg_raw_helpfulness_score': 0.6916666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7979166666666667}
  warnings.warn(
2025-05-11 03:16:40,533 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6312500000000001, 'avg_raw_dharma_score': 0.65, 'avg_raw_helpfulness_score': 0.6416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6418750000000001}
2025-05-11 03:16:42,464 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5931944444444445, 'avg_raw_dharma_score': 0.5166666666666667, 'avg_raw_helpfulness_score': 0.6083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.567125}
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 23521/24000 [9:32:58<1:08:12,  8.54s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 23522/24000 [9:32:59<49:09,  6.17s/it]   98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 23523/24000 [9:32:59<35:51,  4.51s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 23524/24000 [9:33:00<26:33,  3.35s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 23525/24000 [9:33:01<20:03,  2.53s/it]                                                       {'loss': 0.2679, 'grad_norm': 6.71875, 'learning_rate': 2.9599073575926614e-09, 'kl': 2.1525744066635766, 'clip_ratio/low_mean': 6.502631236799062e-05, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0005951097425228606, 'clip_ratio/high_max': 0.0009657786049259206, 'clip_ratio/region_mean': 0.0006601360545028001, 'num_tokens': 5193077.0, 'completions/mean_length': 338.8333435058594, 'completions/min_length': 37.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.08333333333333337, 'completions/mean_terminated_length': 323.0909118652344, 'completions/min_terminated_length': 37.0, 'completions/max_terminated_length': 510.0, 'rewards/combined_reward_trl/mean': 0.6045000553131104, 'rewards/combined_reward_trl/std': 0.30729347467422485, 'reward': 0.6045000553131104, 'reward_std': 0.2696344256401062, 'epoch': 7.84}
2025-05-11 03:17:29,607 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.975, 'avg_raw_dharma_score': 0.9041666666666667, 'avg_raw_helpfulness_score': 0.9083333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.9266666666666666}
2025-05-11 03:17:35,168 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.52625, 'avg_raw_dharma_score': 0.6083333333333333, 'avg_raw_helpfulness_score': 0.6083333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5837083333333333}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 03:18:28,784 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.4770833333333333, 'avg_raw_dharma_score': 0.6458333333333334, 'avg_raw_helpfulness_score': 0.525, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5589583333333333}
2025-05-11 03:18:43,181 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6875, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.7250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7570833333333334}
2025-05-11 03:19:33,848 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5729166666666666, 'avg_raw_dharma_score': 0.7916666666666666, 'avg_raw_helpfulness_score': 0.5833333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6635416666666667}
2025-05-11 03:19:35,268 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7416666666666667, 'avg_raw_dharma_score': 0.8416666666666668, 'avg_raw_helpfulness_score': 0.7000000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7691666666666667}
2025-05-11 03:20:26,082 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5720833333333334, 'avg_raw_dharma_score': 0.6416666666666667, 'avg_raw_helpfulness_score': 0.6083333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6107916666666667}
2025-05-11 03:20:27,038 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6333333333333333, 'avg_raw_dharma_score': 0.6916666666666668, 'avg_raw_helpfulness_score': 0.575, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6391666666666667}
  warnings.warn(
2025-05-11 03:21:32,029 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5125000000000001, 'avg_raw_dharma_score': 0.5416666666666666, 'avg_raw_helpfulness_score': 0.5916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5479166666666667}
2025-05-11 03:21:32,249 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.61125, 'avg_raw_dharma_score': 0.8249999999999998, 'avg_raw_helpfulness_score': 0.6166666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6983750000000001}
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 23721/24000 [9:37:48<40:24,  8.69s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 23722/24000 [9:37:48<29:03,  6.27s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 23723/24000 [9:37:49<21:08,  4.58s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 23724/24000 [9:37:50<15:37,  3.40s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 23725/24000 [9:37:50<11:46,  2.57s/it]                                                       {'loss': 0.1989, 'grad_norm': 8.5, 'learning_rate': 9.953532119681974e-10, 'kl': 2.024655067125956, 'clip_ratio/low_mean': 1.1409013532102107e-05, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.00038061964286801713, 'clip_ratio/high_max': 0.0007062274582373599, 'clip_ratio/region_mean': 0.00039202865640011926, 'num_tokens': 5237366.0, 'completions/mean_length': 363.91668701171875, 'completions/min_length': 90.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.29166666666666663, 'completions/mean_terminated_length': 302.9411926269531, 'completions/min_terminated_length': 90.0, 'completions/max_terminated_length': 485.0, 'rewards/combined_reward_trl/mean': 0.6231458783149719, 'rewards/combined_reward_trl/std': 0.2669133245944977, 'reward': 0.6231458783149719, 'reward_std': 0.23219403624534607, 'epoch': 7.91}
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 23725/24000 [9:37:50<11:46,  2.57s/it]wandb: WARNING Tried to log to step 23725 that is less than the current step 216255. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-05-11 03:22:24,079 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5929166666666666, 'avg_raw_dharma_score': 0.7083333333333334, 'avg_raw_helpfulness_score': 0.6833333333333335, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6662083333333334}
2025-05-11 03:22:24,573 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5258333333333334, 'avg_raw_dharma_score': 0.6833333333333332, 'avg_raw_helpfulness_score': 0.5666666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6010833333333333}
/home/kapil/argen-demo/argen-demo-venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
2025-05-11 03:23:15,976 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7583333333333333, 'avg_raw_dharma_score': 0.875, 'avg_raw_helpfulness_score': 0.775, 'avg_penalty': 0.0, 'avg_combined_reward': 0.8100000000000002}
2025-05-11 03:23:27,110 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7708333333333334, 'avg_raw_dharma_score': 0.8333333333333334, 'avg_raw_helpfulness_score': 0.7416666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7870833333333335}
2025-05-11 03:24:11,530 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6408333333333335, 'avg_raw_dharma_score': 0.8958333333333334, 'avg_raw_helpfulness_score': 0.65, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7455833333333333}
2025-05-11 03:24:16,192 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.51, 'avg_raw_dharma_score': 0.5333333333333333, 'avg_raw_helpfulness_score': 0.5583333333333333, 'avg_penalty': 0.0, 'avg_combined_reward': 0.5338333333333334}
2025-05-11 03:25:08,298 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6666666666666666, 'avg_raw_dharma_score': 0.8166666666666668, 'avg_raw_helpfulness_score': 0.7416666666666668, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7491666666666666}
2025-05-11 03:25:09,278 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.5013888888888888, 'avg_raw_dharma_score': 0.6916666666666668, 'avg_raw_helpfulness_score': 0.5916666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6045833333333333}
  warnings.warn(
2025-05-11 03:26:15,660 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.3675, 'avg_raw_dharma_score': 0.4583333333333333, 'avg_raw_helpfulness_score': 0.3916666666666666, 'avg_penalty': 0.0, 'avg_combined_reward': 0.41108333333333347}
2025-05-11 03:26:16,291 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.6583333333333333, 'avg_raw_dharma_score': 0.7416666666666667, 'avg_raw_helpfulness_score': 0.5833333333333334, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6691666666666666}
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 23921/24000 [9:42:32<11:21,  8.63s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 23922/24000 [9:42:32<08:05,  6.23s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 23923/24000 [9:42:33<05:50,  4.55s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 23924/24000 [9:42:34<04:16,  3.38s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 23925/24000 [9:42:34<03:11,  2.55s/it]                                                       {'loss': 0.2107, 'grad_norm': 11.125, 'learning_rate': 7.547978195698857e-11, 'kl': 2.191056173443794, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.00011515151592902839, 'clip_ratio/high_max': 0.00023030303185805678, 'clip_ratio/region_mean': 0.00011515151592902839, 'num_tokens': 5276644.0, 'completions/mean_length': 276.75, 'completions/min_length': 6.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.125, 'completions/mean_terminated_length': 243.1428680419922, 'completions/min_terminated_length': 6.0, 'completions/max_terminated_length': 463.0, 'rewards/combined_reward_trl/mean': 0.5401249527931213, 'rewards/combined_reward_trl/std': 0.32906630635261536, 'reward': 0.5401250123977661, 'reward_std': 0.29157668352127075, 'epoch': 7.97}
2025-05-11 03:27:08,301 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.47500000000000003, 'avg_raw_dharma_score': 0.8166666666666668, 'avg_raw_helpfulness_score': 0.5666666666666667, 'avg_penalty': 0.0, 'avg_combined_reward': 0.6391666666666667}
2025-05-11 03:27:08,695 - src.reward_functions.trl_rewards - INFO - Queued reward components for W&B: {'avg_raw_ahimsa_score': 0.7125, 'avg_raw_dharma_score': 0.8583333333333334, 'avg_raw_helpfulness_score': 0.7250000000000001, 'avg_penalty': 0.0, 'avg_combined_reward': 0.7745833333333333}
2025-05-11 03:27:48,945 - __main__ - INFO - Saving final trained model to /mnt/checkpoints/grpo_run_v2...
                                                       {'train_runtime': 35044.3512, 'train_samples_per_second': 0.068, 'train_steps_per_second': 0.685, 'train_loss': 0.11968179056203614, 'epoch': 8.0}
2025-05-11 03:27:48,946 - __main__ - INFO - GRPO training complete!
2025-05-11 03:27:48,947 - __main__ - INFO - Saving final trained model to /mnt/checkpoints/grpo_run_v2...
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:       avg_combined_reward ‚ñÅ
wandb:               avg_penalty ‚ñÅ
wandb:      avg_raw_ahimsa_score ‚ñÅ
wandb:      avg_raw_dharma_score ‚ñÅ
wandb: avg_raw_helpfulness_score ‚ñÅ
wandb:         train/global_step ‚ñÅ
wandb: 
wandb: Run summary:
wandb:       avg_combined_reward 0.63917
wandb:               avg_penalty 0
wandb:      avg_raw_ahimsa_score 0.475
wandb:      avg_raw_dharma_score 0.81667
wandb: avg_raw_helpfulness_score 0.56667
wandb:         train/global_step 0
wandb: 
wandb: üöÄ View run llama3-grpo-a100-spot-2 at: https://wandb.ai/principled-evolution/argen-grpo/runs/cu06fpof
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/principled-evolution/argen-grpo
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250510_174337-cu06fpof/logs
2025-05-11 03:27:54,422 - __main__ - INFO - GRPO training complete!
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                    avg_combined_reward ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñá‚ñÇ‚ñÖ‚ñá‚ñÅ‚ñÇ‚ñá‚ñá‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÑ‚ñÜ‚ñÜ‚ñÅ‚ñá
wandb:                                            avg_penalty ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                   avg_raw_ahimsa_score ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñà‚ñÜ‚ñá‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñÉ‚ñÜ‚ñÉ‚ñÖ‚ñÜ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÖ‚ñÇ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ
wandb:                                   avg_raw_dharma_score ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÅ‚ñà‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñÉ‚ñÅ‚ñá‚ñÇ‚ñá‚ñÑ‚ñÜ‚ñÉ‚ñà‚ñÖ‚ñÉ‚ñá‚ñÉ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb:                              avg_raw_helpfulness_score ‚ñÇ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñÇ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÅ‚ñÖ‚ñà‚ñÜ‚ñá‚ñÜ‚ñá‚ñÜ‚ñá‚ñÖ‚ñÇ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÜ‚ñá‚ñÜ
wandb: profiling/Time taken: GRPOTrainer._get_per_token_logps ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      profiling/Time taken: GRPOTrainer._prepare_inputs ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà
wandb:  profiling/Time taken: GRPOTrainer.combined_reward_trl ‚ñÇ‚ñÅ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñÑ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÖ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:         profiling/Time taken: GRPOTrainer.compute_loss ‚ñá‚ñÇ‚ñÅ‚ñá‚ñá‚ñÅ‚ñá‚ñÅ‚ñá‚ñá‚ñÅ‚ñá‚ñÉ‚ñá‚ñá‚ñÅ‚ñÖ‚ñà‚ñà‚ñÑ‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñÅ‚ñá‚ñà‚ñá‚ñÅ
wandb:                              train/clip_ratio/high_max ‚ñÉ‚ñÑ‚ñá‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñà‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                             train/clip_ratio/high_mean ‚ñá‚ñÉ‚ñÉ‚ñà‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñá‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                              train/clip_ratio/low_mean ‚ñá‚ñá‚ñÑ‚ñà‚ñÖ‚ñá‚ñÑ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                               train/clip_ratio/low_min ‚ñà‚ñÜ‚ñÉ‚ñÜ‚ñÜ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                           train/clip_ratio/region_mean ‚ñà‚ñà‚ñÖ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                        train/completions/clipped_ratio ‚ñá‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÉ‚ñÖ‚ñÅ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñá‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñá‚ñÜ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÜ‚ñÇ‚ñÉ
wandb:                           train/completions/max_length ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÉ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                train/completions/max_terminated_length ‚ñÜ‚ñÖ‚ñà‚ñÜ‚ñÑ‚ñà‚ñÉ‚ñá‚ñÖ‚ñà‚ñÜ‚ñÉ‚ñÜ‚ñá‚ñà‚ñÖ‚ñÖ‚ñÅ‚ñà‚ñá‚ñÖ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñà‚ñÉ‚ñÜ‚ñÑ‚ñÜ‚ñà‚ñÖ‚ñÜ‚ñá‚ñÑ‚ñÖ‚ñà‚ñá‚ñà‚ñÜ
wandb:                          train/completions/mean_length ‚ñÑ‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÜ‚ñÖ‚ñá
wandb:               train/completions/mean_terminated_length ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñà‚ñÖ‚ñÜ‚ñÖ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÇ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÅ‚ñÇ‚ñÇ
wandb:                           train/completions/min_length ‚ñÅ‚ñÑ‚ñÅ‚ñÖ‚ñÅ‚ñÖ‚ñÑ‚ñá‚ñÇ‚ñÅ‚ñà‚ñÑ‚ñÅ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÅ‚ñÑ‚ñÜ‚ñÑ
wandb:                train/completions/min_terminated_length ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñÇ‚ñá‚ñÑ‚ñÅ‚ñÇ‚ñá‚ñÑ‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñÅ‚ñÅ‚ñà‚ñá‚ñÅ‚ñÑ‚ñÑ‚ñÜ‚ñÇ‚ñá‚ñÅ‚ñÖ‚ñÑ‚ñá‚ñÉ‚ñÅ‚ñÇ‚ñÜ‚ñÇ‚ñÉ
wandb:                                            train/epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                                      train/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                        train/grad_norm ‚ñÅ‚ñÅ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñÖ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÖ
wandb:                                               train/kl ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñÇ‚ñÜ‚ñÖ‚ñÑ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñà‚ñÜ‚ñÉ‚ñÉ
wandb:                                    train/learning_rate ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             train/loss ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÖ‚ñÜ‚ñÑ‚ñá‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñÉ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÜ
wandb:                                       train/num_tokens ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                                           train/reward ‚ñÅ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñÜ‚ñÜ‚ñÇ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÜ
wandb:                                       train/reward_std ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÖ‚ñÇ‚ñÜ‚ñÉ‚ñÅ‚ñá‚ñá‚ñÇ‚ñÖ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÉ‚ñÑ‚ñá‚ñÅ‚ñá‚ñà‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÜ‚ñÖ‚ñà‚ñÅ‚ñÖ‚ñÜ‚ñÖ‚ñÜ
wandb:                 train/rewards/combined_reward_trl/mean ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñá‚ñÖ‚ñÖ‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÅ‚ñÜ‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÇ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ
wandb:                  train/rewards/combined_reward_trl/std ‚ñÜ‚ñÑ‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÉ‚ñÅ‚ñÖ‚ñÑ‚ñÇ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñà‚ñÑ‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ
wandb: 
wandb: Run summary:
wandb:                                    avg_combined_reward 0.77458
wandb:                                            avg_penalty 0
wandb:                                   avg_raw_ahimsa_score 0.7125
wandb:                                   avg_raw_dharma_score 0.85833
wandb:                              avg_raw_helpfulness_score 0.725
wandb: profiling/Time taken: GRPOTrainer._get_per_token_logps 0.02615
wandb:      profiling/Time taken: GRPOTrainer._prepare_inputs 0.0
wandb:  profiling/Time taken: GRPOTrainer.combined_reward_trl 10.10887
wandb:         profiling/Time taken: GRPOTrainer.compute_loss 0.04986
wandb:                                             total_flos 0
wandb:                              train/clip_ratio/high_max 0
wandb:                             train/clip_ratio/high_mean 0
wandb:                              train/clip_ratio/low_mean 0
wandb:                               train/clip_ratio/low_min 0
wandb:                           train/clip_ratio/region_mean 0
wandb:                        train/completions/clipped_ratio 0.08333
wandb:                           train/completions/max_length 512
wandb:                train/completions/max_terminated_length 496
wandb:                          train/completions/mean_length 275.75
wandb:               train/completions/mean_terminated_length 254.27274
wandb:                           train/completions/min_length 113
wandb:                train/completions/min_terminated_length 113
wandb:                                            train/epoch 8
wandb:                                      train/global_step 24000
wandb:                                        train/grad_norm 11.125
wandb:                                               train/kl 2.46653
wandb:                                    train/learning_rate 0.0
wandb:                                             train/loss 0.2899
wandb:                                       train/num_tokens 5284072.0
wandb:                                           train/reward 0.70688
wandb:                                       train/reward_std 0.19145
wandb:                 train/rewards/combined_reward_trl/mean 0.70688
wandb:                  train/rewards/combined_reward_trl/std 0.22575
wandb:                                             train_loss 0.11968
wandb:                                          train_runtime 35044.3512
wandb:                               train_samples_per_second 0.068
wandb:                                 train_steps_per_second 0.685
wandb: 
wandb: üöÄ View run llama3-grpo-a100-spot-2 at: https://wandb.ai/principled-evolution/argen-grpo/runs/5sbln6xw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/principled-evolution/argen-grpo
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250510_174337-5sbln6xw/logs
[rank0]:[W511 03:27:56.787594048 ProcessGroupNCCL.cpp:1476] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
