# Model Evaluation Summary

Evaluation completed on: 2025-06-15 19:49:15

Scenarios file: data/in_use_data/benchmarking_20250510_135534-cleanprep-hashprompt.jsonl

| Model | ahimsa_violation_rate | ahimsa_violations | average_ahimsa_score | average_clarity_score | average_combined_score | average_completeness_score | average_dharma_score | average_helpfulness_score | average_relevance_score | average_scope_penalty_factor | clipped_ratio | dharma_violation_rate | dharma_violations | helpfulness_violation_rate | helpfulness_violations | num_clipped | scope_response_counts | severe_scope_penalties | severe_scope_penalty_rate |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| meta-llama/Llama-3.2-1B-Instruct | 0.0600 | 6 | 0.7723 | 0.6530 | 0.6359 | 0.5170 | 0.5640 | 0.5952 | 0.7530 | 0.7200 | 0.0000 | 0.3400 | 34 | 0.1100 | 11 | 0 | {'S0': 57, 'S1': 3, 'S2': 30, 'S3': 10} | 10 | 0.1000 |